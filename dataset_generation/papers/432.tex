% v2-acmsmall-sample.tex, dated March 6 2012
% This is a sample file for ACM small trim journals
%
% Compilation using 'acmsmall.cls' - version 1.3 (March 2012), Aptara Inc.
% (c) 2010 Association for Computing Machinery (ACM)
%
% Questions/Suggestions/Feedback should be addressed to => "acmtexsupport@aptaracorp.com".
% Users can also go through the FAQs available on the journal's submission webpage.
%
% Steps to compile: latex, bibtex, latex latex
%
% For tracking purposes => this is v1.3 - March 2012

%\documentclass[prodmode,acmcsur]{acmsmall}  
\documentclass[prodmode]{acmsmall}  %Aptara syntax

% Package to generate and customize Algorithm as per ACM style
%\usepackage[a4paper, total={6.4in, 8in}]{geometry}
\usepackage[ruled]{algorithm2e}
\usepackage{tablefootnote}
\usepackage{url} 
\usepackage{epsfig}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{multicol}
\usepackage{longtable,ltxtable,booktabs}
\usepackage{lscape}
\usepackage{enumitem}
\usepackage{array}
\usepackage{color}
\usepackage{epsfig}
\usepackage{footmisc}
%\newtheorem{Def}{Definition}
%\newtheorem{Thm}{Theorem}
%\newtheorem{Exmp}{Example}

%\newdef{definition}[theorem]{Definition}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}

% Metadata Information
%\acmVolume{9}
%\acmNumber{4}
%\acmArticle{39}
%\acmYear{2010}
%\acmMonth{3}

% Copyright
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% DOI
\doi{0000001.0000001}

%ISSN
\issn{1234-56789}

% Document starts
\begin{document}

% Page heads
\markboth{J. Zhang et al.}{Transfer Learning for Cross-Dataset Recognition: A Survey}

% Title portion
\title{Transfer Learning For Cross-Dataset Recognition: A Survey}
\author{Jing Zhang
\affil{University of Wollongong}
Wanqing Li
\affil{University of Wollongong}
Philip Ogunbona
\affil{University of Wollongong}
}
% NOTE! Affiliations placed here should be for the institution where the
%       BULK of the research was done. If the author has gone to a new
%       institution, before publication, the (above) affiliation should NOT be changed.
%       The authors 'current' address may be given in the "Author's addresses:" block (below).
%       So for example, Mr. Abdelzaher, the bulk of the research was done at UIUC, and he is
%       currently affiliated with NASA.

\begin{abstract}
This paper summarises and analyses the cross-dataset recognition transfer learning techniques with the emphasis on what kinds of methods can be used when the available source and target data are presented in different forms for boosting the target task. This paper for the first time summarises several transferring criteria in details from the concept level, which are the key bases to guide what kind of knowledge to transfer between datasets. In addition, a taxonomy of cross-dataset scenarios and problems is proposed according the properties of data that define how different datasets are diverged, thereby review the recent advances on each specific problem under different scenarios. Moreover, some real world applications and corresponding commonly used benchmarks of cross-dataset recognition are reviewed. Lastly, several future directions are identified.
\end{abstract}


%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
%\begin{CCSXML}
%<ccs2012>
%<concept>
%<concept_id>10010147.10010257.10010258.10010262.10010277</concept_id>
%<concept_desc>Computing methodologies~Transfer learning</concept_desc>
%<concept_significance>500</concept_significance>
%</concept>
%<concept>
%<concept_id>10010147.10010257.10010258.10010262.10010279</concept_id>
%<concept_desc>Computing methodologies~Learning under covariate shift</concept_desc>
%<concept_significance>500</concept_significance>
%</concept>
%</ccs2012>
%\end{CCSXML}
%
%\ccsdesc[500]{Computing methodologies~Transfer learning}
%\ccsdesc[500]{Computing methodologies~Learning under covariate shift}
%
% End generated code
%

% We no longer use \terms command
%\terms{Design, Algorithms, Performance}

\keywords{Cross-dataset, transfer learning, domain adaptation}

%\acmformat{Jing Zhang, Wanqing Li, and Philip Ogunbona, 2016. Transfer Learning for Cross-Dataset Recognition: A Survey.}
% At a minimum you need to supply the author names, year and a title.
% IMPORTANT:
% Full first names whenever they are known, surname last, followed by a period.
% In the case of two authors, 'and' is placed between them.
% In the case of three or more authors, the serial comma is used, that is, all author names
% except the last one but including the penultimate author's name are followed by a comma,
% and then 'and' is placed before the final author's name.
% If only first and middle initials are known, then each initial
% is followed by a period and they are separated by a space.
% The remaining information (journal title, volume, article number, date, etc.) is 'auto-generated'.

%\begin{bottomstuff}
%%This work is supported by the National Science Foundation, under
%%grant CNS-0435060, grant CCR-0325197 and grant EN-CS-0329609.
%
%Author's addresses: J. Zhang {and} W. Li {and} P. Ogunbona, School of Computing and Information Technology, University of Wollongong, NSW 2522, Australia.
%\end{bottomstuff}

\maketitle

\section{Introduction}
It has been explored how human would transfer learning in one context to another similar context~\cite{Woodworth1901,Perkins1992} in the field of Psychology and Education. For example, learning to drive a car helps a person later to learn more quickly to drive a truck, and learning mathematics prepares students to study physics. The machine learning algorithms are mostly inspired by human brains. However, most of them require a huge amount of training examples to learn a new model from scratch and fail to apply knowledge learned from previous domains or tasks. This may be due to that a basic assumption of statistical learning theory is that the training and test data are drawn from the same distribution and belong to the same task. Intuitively, learning from scratch is not realistic and practical, because it violates how human learn things. In addition, manually labelling a large amount of data for new domain or task is labour extensive, especially for the modern ``data-hungry'' and ``data-driven'' learning techniques (i.e. deep learning). However, the big data era provides a huge amount available data collected for other domains and tasks. Hence, how to use the previously available data smartly for the current task with scarce data will be beneficial for real world applications. 

To reuse the previous knowledge for current tasks, the differences between old data and new data need to be taken into account. Take the object recognition as an example. As claimed by~\citeN{Torralba2011}, despite the great efforts of object datasets creators, the datasets appear to have strong build-in bias caused by various factors, such as selection bias, capture bias, category or label bias, and negative set bias. This suggests that no matter how big the dataset is, it is impossible to cover the complexity of the real visual world. Hence, the dataset bias needs to be considered before reusing data from previous datasets. \citeN{Pan2010} summarise that the differences between different datasets can be caused by domain divergence (i.e. distribution shift or feature space difference) or task divergence (i.e. conditional distribution shift or label space difference), or both. 
For example, in visual recognition, the distributions between the previous and current data can be discrepant due to the different environments, lighting, background, sensor types, resolutions, view angles, and post-processing. Those external factors may cause the distribution divergence or even feature space divergence between different domains. On the other hand, the task divergence between current and previous data is also ubiquitous. For example, it is highly possible that an animal species that we want to recognize have not been seen by the pre-established recognition system. So if we still want the system to recognize the new animal species, a large amount of labelled samples of the animal species are required by traditional machine learning techniques and the whole system needs to be retrained. Hence, when either the domain divergence or task divergence occurs, the traditional machine learning techniques all cannot be used directly. To make the best use of previous data, some transferring strategies need to be employed to take domain or task shift into account, and then tackle the problem in new data without drop of performance. Thus, the objective of this paper is to review the related state-of-the-art transfer learning techniques on efficiently reusing previous data for current tasks.

There have been other surveys on transfer learning during past few years. For example, the survey written by \citeN{Pan2010} categorized and reviewed transfer learning for classification, regression, and clustering problems. They defined three setting of transfer learning, namely inductive transfer, transductive transfer and unsupervised transfer. They covered the basic scenarios with one source domain and one target domain, and transfer knowledge between datasets with homogeneous feature spaces. However, the real world applications require techniques that can transfer knowledge in more complicated and unconstrained scenarios, such as multiple sources, heterogeneous features, heterogeneous tasks, sequential data, or even transfer previous knowledge to unseen target data.
\citeN{Shao2015} reviews the transfer learning algorithms on the applications of visual categorization. Similarly, the work presented by \citeN{Patel2015} focus on visual domain adaptation. These two surveys only cover the methodologies on transferring in the visual domains. In addition, Shao's work reviews previous research only based on two main categories: feature-based knowledge transfer and classifier-based knowledge transfer. Patel's work is purely approach based and only focuses on domain adaptation, a subtopic of transfer learning. Hence, it is unclear how to transfer the knowledge in more complex real world scenarios when different kinds of data are presented, because different techniques would be used differently based on the types of previous and current knowledge and the characteristics of available data, which have not been well summarized and analysed by previous surveys. 

In this paper, our focus is to analyse and summarise how to take full advantage of previous data presented in different forms (such as homogeneous or heterogeneous feature space and label space, and availability of labels, etc.) for current domain and task. 
Specifically, the key contributions of this survey are as follows:
\begin{itemize}
\item First, this paper defines the dataset properties that potentially lead to dataset divergence in terms of domain and task, such as feature space, data sufficiency, data balance, sequential data, availability of labels, and label spaces. Different properties define different scenarios and problems, which lead to different strategies for feasible and proper transfer.
\item Secondly, this paper for the first time summarises several transferring criteria in details from the concept level, which have been used by previous research explicitly or implicitly. 
These criteria are the key bases to guide what kind of knowledge to transfer between datasets. 
The basic assumptions and the potential categories of knowledge (i.e. instance, feature representation, classifier, or hybrid knowledge) can be transferred using each criterion are analysed and presented. Moreover, several commonly used methods or ideas are illustrated under each criterion.
\item Thirdly, we give a comprehensive overview of the recent advances (based on transferring criterion and knowledge) on each scenario defined by the properties of dataset divergence, and connect each scenario with the referred techniques among the literature, which provides a systematic knowledge map of transfer learning for cross-dataset recognition and presents specific strategies for each scenario.
\item Fourthly, some real world applications of cross-dataset recognition are reviewed and the commonly used benchmark datasets for each application are provided.
\item Lastly, several future research directions are identified on transfer learning for cross-dataset recognition.
\end{itemize}

The rest of the paper is organised as follows. 
Section~\ref{sec:overview} defines the terminologies used in the paper, and summarises the cross-dataset transferring criteria that guide the transferring of knowledge and the basic ideas of the typical methods that use each criterion. 
Section~\ref{sec:HOMO} discusses the scenario where the feature spaces and label spaces between training and test datasets are homogeneous, suggesting that the shift is caused by the data distributions. The scenario of homogeneous feature and label spaces is further classified into seven problems: labelled target dataset; labelled plus unlabelled target dataset; unlabelled target dataset; imbalanced unlabelled target dataset; sequential labelled target data; sequential unlabelled target data; unavailable target training data. Section~\ref{sec:HETEF} discusses the scenario where the label spaces are the same but the feature spaces between the training and test datasets are different, with three problems: labelled target dataset; labelled plus unlabelled target dataset; unlabelled target dataset. Section~\ref{sec:HETEL} discusses the scenario where the the feature spaces are the same but the label spaces between the training and test datasets are different, with five problems: labelled target dataset; unlabelled target dataset; sequential labelled target dataset; unavailable target training dataset; unlabelled source dataset. Section~\ref{sec:HETEFL} discusses the scenario where both the label spaces and the feature spaces between the training and test datasets are different, with two problems: labelled target dataset; sequential labelled target dataset. In Section~\ref{sec:App}, several real-world applications and the most commonly used datasets for cross-dataset transfer learning are summarised. In Section~\ref{sec:Conc}, the conclusion and discussion on future directions are presented.

\section{Overview}
\label{sec:overview}
\subsection{Terminologies and Definitions}
\label{sec:term} 
We begin with the definitions of terminologies. We follow the definitions of ``domain'' and ``task'' defined by \citeN{Pan2010}.

\begin{definition}(\textbf{Domain}~\cite{Pan2010}) A domain is defined as $\mathcal{D}=\{\mathcal{X},P(\mathbf{x})\}$, which is composed of two components: a feature space $\mathcal{X}$ and a marginal probability distribution $P(\mathbf{x})$, where $\mathbf{x}\in{\mathcal{X}}$.  
\end{definition}

\begin{definition}(\textbf{Task}~\cite{Pan2010}) Given a specific domain, a task is defined as $\mathcal{T} = \{\mathcal{Y},f(\mathbf{x})\}$, which is composed of two components: a label space $\mathcal{Y}$ and a predictive function $f(\mathbf{x})$, where $f(\mathbf{x})$ can be seen as a conditional distribution $P(y|\mathbf{x})$ and $y\in{\mathcal{Y}}$.  \end{definition}

 In addition, we give the formal definition of ``Dataset'' in the context of cross-dataset recognition. 
\begin{definition}(\textbf{Dataset}) A dataset is defined as $\mathcal{S} = \{\mathcal{X},P(\mathbf{x}),\mathcal{Y},f(\mathbf{x})\}$, which is a collection of data that belong to a specific domain with a specific task.
\end{definition}

According to the definitions, two datasets can be different with respect to domain, or task, or both. We define the auxiliary training dataset as source dataset and the current test dataset as target dataset. The properties of the source and target datasets determine what kinds of methods can be used for transferring knowledge. Below, we define several dataset properties (based on ``Data'' and ``Label'') that potentially lead to different types of divergence and can further define different problems.
\begin{itemize}
\item \textbf{Data:} 
	\begin{itemize}
	\item \textit{Feature space:} the consistency of feature spaces (i.e. different feature extraction methods or different data modalities) between source and target datasets.
	\item \textit{Data availability:} the availability and sufficiency of target data in the training stage.
	\item \textit{Balanced data:} whether the numbers of data samples in each class are balanced.
	\item \textit{Sequential data:} whether the data are sequential and evolving over time.
	\end{itemize}
\item \textbf{Label:}
	\begin{itemize}
	\item \textit{Label availability:} the availability of labels in source and target datasets.
	\item \textit{Label space:} whether the data categories of the two datasets are identical.
	\end{itemize}		
\end{itemize}

Based on the types of dataset properties, the properties of feature space and label space are used as the starting points that define different problems defined by other data properties. Hence, the four scenarios are categorised as the first layer of the taxonomy of problems and are described as follows,
\begin{itemize}
\item \textit{Homogeneous feature spaces and label spaces:} the source and target datasets are different only in terms of data distributions (i.e. domain divergence occurs). The feature spaces and label spaces are identical across datasets.
\item \textit{Heterogeneous label spaces:} the source and target datasets are different in terms of label spaces (i.e. task divergence occurs) but with same feature spaces.
\item \textit{Heterogeneous feature spaces:} the source and target datasets are different in terms of feature spaces (i.e. domain divergence occurs) but with same label spaces. 
\item \textit{Heterogeneous feature spaces and label spaces:} both the feature spaces and the label spaces between source and target dataset are different (i.e. both domain and task divergence occur).
\end{itemize} 

\subsection{``What to Transfer''}
Four main categories of knowledge would be transferred among the literature,
\begin{itemize}
\item Instance-based transfer: re-weight some data in the source domain or in both domains to reduce domain divergence.
\item Feature representation based transfer: learn a ``good'' feature representations to minimize domain shift and error of learning task.
\item Classifier-based transfer: learn a new model that minimizes the generalization error in the target domain via training instances from both domains. 
\item Hybrid knowledge transfer: transfer more than one kinds of knowledge, i.e. joint instance and feature representation transfer, joint instance and classifier transfer, or joint feature representation and classifier transfer.
\end{itemize}
\subsection{Transferring Criteria}
\label{sec:criteria}
In this section, we summarise the most typical criteria for transferring knowledge between datasets, which have been used explicitly or implicitly among the literature. The basic assumptions and the potential categories of knowledge (``what to transfer'') can be transferred using each criterion are analysed and presented. Moreover, several commonly used methods or ideas are illustrated under each criterion. The identified criteria include: statistic criterion, geometric criterion, higher-level representation criterion, correspondence criterion, class-based criterion, self labelling, and hybrid criterion.
We denote the source dataset as $\{X_s,Y_s\}$, which are draw from distribution $P_s(X_s,Y_s)$ and the target dataset as $\{X_t,Y_t\}$, which are draw from distribution $P_t(X_t,Y_t)$.
\begin{itemize}
\item \textit{Statistic Criterion:} aims at reducing the statistical distribution shift between datasets using some mechanisms, such as instance re-weighting, feature transformation, and classifier parameter transfer. The statistic criterion generally assumes sufficient data in each dataset to approximate the respective statistic distributions. This criterion has been used for instance-based transfer, feature representation based transfer, classifier-based transfer, and hybrid transfer (i.e. joint instance and feature representation transfer~\cite{Long2014,Aljundi2015}). 
The most commonly used methods for comparing and thereby reducing distribution shift are summarised as follows.

% (i.e. $P_s(x_s)$ and $P_t(x_t)$). 
\begin{enumerate}
\item Kullback-Leibler divergence~\cite{Sugiyama2008}
%\begin{equation}
%D_{KL}(P_s||P_t) = \sum_x \sum_yP_s(x,y)log\frac{P_s(x,y)}{P_t(x,y)}
%\end{equation}
\begin{equation}
D_{KL}(P_s||P_t) = \min \int_{X}P_s(x)log\frac{P_s(x)}{P_t(x)}dx
\end{equation}
\item Jensen-Shannon divergence~\cite{Quanz2012}
\begin{equation}
D_{JS}(P_s||P_t) = 0.5(D_{KL}(P_s||P_t)+D_{KL}(P_t||P_s))
\end{equation}
\item Quadratic divergence~\cite{Si2010}
%\begin{equation}
%D_{Breg}(P_s||P_t) = \sum_x \sum_y(P_s(x,y)-P_t(x,y))^2
%\end{equation}
\begin{equation}
D_{Breg}(P_s||P_t) = \min \int_{X}(P_s(x)-P_t(x))^2dx
\end{equation}
\item Hellinger distance~\cite{Baktashmotlagh2014}
%\begin{equation}
%D_{Helli}(P_s||P_t) = \frac{1}{\sqrt{2}}\sqrt{\sum_x \sum_y(\sqrt{P_s(x,y)}-\sqrt{P_t(x,y)})^2}
%\end{equation}
\begin{equation}
D_{Helli}(P_s,P_t) = \min \int_{X}(\sqrt{P_s(x)}-\sqrt{P_t(x)})^2dx
\end{equation}
\item Mutual information~\cite{Shi2012}
\begin{equation}
I_{s,t}(X;Q) = \min H[\hat{q}_0]-\frac{1}{n}\sum_i H[\hat{q}_i]
\end{equation}
where X represents all the data from source and target domain, Q denotes the domain label (i.e. 0 for source domain, and 1 for target domain), $\hat{q}_i$ is the two-dimensional posterior probability vector of assigning $x_i$ to either the source or the target, given all other data points from the two domains, and $\hat{q}_0$ is the estimated prior distribution of domain (i.e. $\hat{q}_0 = 1/n\sum_i \hat{q}_i$). By minimizing the mutual information between the data instance X and its (binary) domain label Q, the domain shift is reduced.
%\item Optimal Transport~\cite{Courty2016}
\item $\mathcal{H}$ divergence~\cite{Ben-David2007,Ben-David2010}\\
%\begin{equation}
%D_{\mathcal{H}}(P_s, P_t) = 2\sup_{h\in{\mathcal{H}}}|P_s[h(x_s)=1]-P_t[h(x_t)=1]|
%\end{equation}
\begin{equation}
D_{\mathcal{H}}(P_s, P_t) = 2\sup_{h\in{\mathcal{H}}}|P_s[I(h)]-P_t[I(h)]|
\end{equation}
where $\mathcal{H}$ is a hypothesis class on $\mathcal{X}$, and $I(h)$ 
%is the indicator function which is 1 if predicate $h(x)=1$, and 0 otherwise, for $h\in \mathcal{H}$.
is the set for which $h\in \mathcal{H}$ is the characteristic function; that is $x\in I(h)\Leftrightarrow h(x)=1$. 
$\mathcal{H}$ divergence measures the distance between distributions in a hypothesis class $\mathcal{H}$, which can be approximated by the empirical risk of a classifier that discriminates between instances drawn from $P_s$ and instances drawn from $P_t$.
\item Maximum Mean Discrepancy (MMD)~\cite{Pan2009}\\
\begin{equation}
D_{MMD}(P_s, P_t) = \min \|\frac{1}{n_s}\sum_{\mathbf{x}_i\in{X_s}}\phi(\mathbf{x}_i)-\frac{1}{n_t}\sum_{\mathbf{x}_j\in{X_t}}\mathbf\phi(\mathbf{x}_j)\|^2_F 
\end{equation}
where $X$ denotes data from all the datasets, $\phi$ represents the kernel function that maps the original data to a reproducing kernel Hilbert space (RKHS). The MMD compares the statistic moments of distributions. If the $\phi$ is a characteristic kernel (i.e. Gaussian kernels, or Laplace kernels), MMD compares all the orders of statistic moments, making MMD a metric on distributions.
\end{enumerate}
\item \textit{Geometric Criterion:} bridges datasets according to their geometrical properties. %It assumes that the domain shift can be reduced by either local geometry or global geometry. 
This criterion assumes domain shift can be reduced using the relationship of geometric structures between datasets and is generally used for feature representation based transfer. The examples of transferring using geometric criterion are as follows.
\begin{enumerate}
\item Subspace alignment~\cite{Fernando2013}\\
Learn a linear mapping to align the source subspace coordinate system to the target one.
\begin{equation}
M = \argmin_M\|A_sM-A_t\|_F^2
\end{equation}
where the subspaces $A_s$ and $A_t$ are pre-learned using PCA on source and target domain respectively.
\item Intermediate subspaces~\cite{Gopalan2011,Gong2012}\\
Identify intermediate subspaces between the source and target, and then learn the information from these subspaces to convey the domain changes. The subspaces are identified with the Grassmann manifold $\mathbb{G}_{N,d}$, and source subspace $A_s$ and target subspace $A_t$ are points on $\mathbb{G}_{N,d}$. To bridge $A_s$ and $A_t$, the points on the geodesic paths between them (which are constant velocity curves on a manifold) are sampled to form the intermediate subspaces. Then both source and target data are projected to the obtained intermediate subspaces (either by sampling along the geodesic~\cite{Gopalan2011} or all of them~\cite{Gong2012}) to augment the data for help finding the correlations between domains.
\item Manifold alignment (without correspondence)~\cite{Cui2014a}\\
Align the manifolds defined by source and target datasets without the correspondence information. Hence, the two manifolds can be aligned geometrically:
\begin{equation}
\begin{split}
<A_s,A_t,F> = \argmin_{A_s,A_t,F}&\|K_s-FK_tF^T\|_f^2+\|A_s^TX_s-A_t^TX_tF^T\|_F^2\\
&+J(A_s,X_s)+J(A_t,X_t)
\end{split}
\end{equation}
where the $K_s$ and $K_t$ are full adjacency matrix (i.e. $[K]_{ij}=d(X_{.i},X_{.j})$), $F\in{\{0,1\}^{n_s\times n_t}}$ denotes the correspondence matrix that need to be learnt, $A_s$ and $A_t$ are linear projections of from two datasets that also need to be learnt, and $J(A_s,X_s)$ and $J(A_t,X_t)$ are geometry preserving terms to preserve the manifold structures of respective domains.
\end{enumerate}
\item \textit{Higher-level Representations:} aims at finding higher-level representations that are representative, compact, or invariant between datasets. This criterion does not assume the existence of labelled data, or the existence of correspondence set. It assumes that there exist the domain invariant higher-level representations between datasets. This criterion is generally used for feature representation based transfer. 

Note that the higher-level representation criterion is commonly used together with other criteria for better transfer, but it is also used independently without any mechanism to reduce the domain divergence explicitly.
%\item \textit{Sparse Criteria:} aims at finding higher-level sparse representations that are invariant between domains.
%to irrelevant features.
\begin{enumerate}
\item Sparse coding~\cite{Raina2007} \\
The dictionary is learnt based on the source data, and then apply the learnt dictionary to the target data to obtain the sparse codes of the target data.
\begin{align}
\text{Step 1: }& D = \argmin_{D,Z_s} ||X_{s}- DZ_s|| \quad
\text{s.t.} \quad \forall i, ||z_i||_0\leq{T} \\
\text{Step 2: } & Z^*_{t}=\argmin_{Z_{t}} ||X_{t}- DZ_t|| \quad
\text{s.t.} \quad \forall j, ||z_j||_0\leq{T} 
\end{align}
where $D$ is the learnt dictionary on source data, $Z_s$ and $Z_t$ are the sparse codes.
\item Low-rank representation~\cite{Shao2012}\\
Find a subspace $A$ where each datum in the target domain can be linearly represented by the corresponding subspace in the source domain.
\begin{equation}
<A,Z> = \argmin_{A,Z}F(A,X_s)+rank(Z) \quad
\text{s.t.} \quad A^TX_sZ = A^TX_t
\end{equation}
Because Z is constrained to be low rank, each target sample is linearly represented by some subspace from a subspace union in the source domain. Hence, the structure information in the source and target domain is considered.
\item Deep Neural Networks Representations~\cite{Donahue2014}\\
Use deep neural networks to learn more transferable features by disentangling explanatory factors of variations underlying data samples, and grouping deep features hierarchically according the their relatedness to invariant factors. 
\item Stacked Denoising Auto-encoders (SDAs)~\cite{Glorot2011,Chen2012}\\
Train the SDAs~\cite{Vincent2010} to reconstruct the data from all the domains. It has been shown that SDAs can disentangle hidden factors which explain the variations in the input data that are invariant to different domains~\cite{Glorot2011,Chen2012}. The key idea is to map the corrupted input $\tilde{X}$ to a hidden representation, and then decode the hidden representation back to reconstructed vectors in input space:
\begin{align}
\text{encoder: } & Y=f_{\theta}(\tilde{X})=s(W\tilde{X}+b)\\
\text{decoder: } & Z=g_{\theta'}(Y)=s(W'Y+b')
\end{align}
where $\tilde{X}$ is the corrupted version of the data $X$ from all the domains, $\theta \in{\{W,b\}}$ and $\theta' \in{\{W',b'\}}$ are parameters of the auto-encoder, $s(\cdot)$ is the nonlinear squashing-function, $Y$ is the hidden representation of input data, $Z$ is the reconstructed data which are supposed to be as similar as as possible to the uncorrupted input data $X$, i.e. $\min\|X-Z\|^2$. Then several layers of denoising auto-encoders can be learnt and stacked to constitute the stacked denoising auto-encoders (SDAs) to build deep architectures.
\item Attribute space representation~\cite{Lampert2009}\\
Use the human-specified high-level description (attributes) of target objects instead of training images to detect object in an image. Assume $a^c = (a_1^c,...,a_m^c)$ is the attribute representation for class c with m attributes in all the classes. The $p(a_m|x_s)$ is learnt first by learning probabilistic classifiers for each attribute $a_m$ from the source dataset. In the test stage, assume each target class is determined by its attribute vector, i.e. $p(a|y_t)=[[a=a^{y_t}]]$, then use the Bayes' rule to obtain $p(y_t|a)=\frac{p(y_t)}{p(a^{y_t})}[[a=a^{y_t}]]$. Hence, the posterior of a target class given an image can be calculated as follows
\begin{equation}
p(y_t|x_t)=\sum_{a\in\{0,1\}^M}p(y_t|a)p(a|x_t)=\frac{p(y_t)}{p(a^{y_t})}\prod_{m=1}^Mp(a_m^{y_t}|x_t)
\end{equation}
Since the attributes are assigned on a per-class basis instead of a per-image basis, the manual effort to add a new object class is much smaller than labelling a huge amount of training data.
\end{enumerate}

\item \textit{Correspondence Criterion:} uses the paired correspondence samples from different domains to construct the relationship between domains. Obviously, a set of corresponding samples (i.e. the same object captured from different view angles, or by different sensors) are required for correspondence criterion. This criterion is commonly used for feature representation-based transfer. The typical methods are as follows.
\begin{enumerate}
\item Sparse coding with correspondence~\cite{Zheng2012}\\
The corresponding samples between domains are force to share the same sparse codes: 
\begin{equation}
<D_s,D_t,Z> = \argmin_{D_s,D_t,Z}\|X_t-D_tZ\|_F^2+\|X_s-D_sZ\|_F^2 \quad \text{s.t.} \quad \forall i,\|z_i\|_0 \leqslant T
\end{equation}
where $D_s$ and $D_t$ are the dictionaries, $Z$ is the sparse codes.
\item Manifold alignment (with correspondence)~\cite{Zhai2010}\\
Given a set of correspondence samples set C between domains, learn mapping matrices $A_s$ and $A_t$ for source and target set respectively to preserve the correspondence relationships after mapping:
\begin{equation}
<A_s,A_t>= \argmin_{A_s,A_t} \sum_{(i,j)\in C}\|A_s^Tx^s_i-A_t^Tx^t_j\|^2+J(A_s,X_s)+J(A_t,X_t)
\end{equation}
%+\sum_{i=1}^{ns} \|P_s^Tx^s_i-\sum_{k\in N^{s}(i)}w^{x_s}_{ik}P_s^Tx^s_k\|^2+\sum_{i=1}^{nt} \|P_t^Tx^t_i-\sum_{k\in N^{t}(i)}w^{x_t}_{ik}P_t^Tx^t_k\|^2
where $J(A_s,X_s)$ and $J(A_t,X_t)$ are the manifold regularization terms which are used to preserve the intrinsic manifold structures of source and target domains.
\end{enumerate}
\item \textit{Class-based Criterion:} uses the class label information as a guidance for connecting different datasets. Hence, the labelled samples from each dataset are assumed to be available, no matter sufficient or not.
This criterion has been used for 
feature representation-based transfer~\cite{DaumeIII2007,Saenko2010},
classifier-based transfer~\cite{Yang2007,Ma2014}, 
and hybrid knowledge transfer 
(i.e. joint feature-based and classifier-based transfer~\cite{Hoffman2013}). 
Below is the commonly used methods that use the supervision criterion for transferring the source knowledge to the target dataset.
\begin{enumerate}
\item Feature augmentation~\cite{DaumeIII2007} \\
Each feature is augmented into three versions of it: a general version, a source-specific version and a target-specific version. The augmented source data will contain only general and source-specific versions. The augmented target data contains general and target-specific versions. The rest of the dimensions are appended with zeros. The augmented features are as follows,
\begin{equation}
\Phi_s(x)=[x_g,x_s,0];\quad \Phi_t(x)=[x_g,0,x_t]
\end{equation}
where $x_g$ is the general version, $x_s$ is the source specific version, and $x_t$ is the target specific version. 
\item Metric learning~\cite{Saenko2010}\\
Learn a metric such that the distance of samples from different domains with same labels are close while the distance of samples from different domains with different labels are far away:
\begin{equation}
\min R(W)
\end{equation}
\begin{align*}
s.t. \quad   d_W(x_s,x_t)< \mathit{u} \quad & \text{if} \quad y_s=y_t\\
   d_W(x_s,x_t)> \mathit{l} \quad & \text{if} \quad y_s\neq y_t
\end{align*}
where ${u,l}\in R$ are threshold parameters, $d_W = (\mathbf{x}_s-\mathbf{x}_t)^TW(\mathbf{x}_s-\mathbf{x}_t)$ is the pairwise distance for some $W$ , and $W$ is the matrix that needs to be learnt.
\item Linear Discriminative Model~\cite{Yang2007} \\
Use the source classifier parameters to regularize the target classifier parameters:
\begin{equation}
L = \min \sum_{\mathbf{x}_s\in{X_s}} l(x_s,y_s,w_s)+ \sum_{\mathbf{x}_t\in{X_t}} l(x_t,y_t,w_t)+R(w_s,w_t)
\end{equation}
where $l$ denotes some loss functions
over data and labels, and $R$ denotes some regularization between source and target classifiers.
\item Bayesian Model~\cite{Fei-Fei2006}\\
Present the source knowledge as a prior probability in the space of target model parameters. Specifically, the ``general knowledge'' from source domain categories are extracted and then represented in the form of a prior probability density function in the space of model parameters. Given a small training set in the target domain, this knowledge can be updated and produce a posterior density.
\end{enumerate}
\item \textit{Self Labelling:} uses the source domain samples to train an initial model, which is used to obtain the pseudo labels of target domain samples. Then the target samples are incorporated to retrain the model. The procedure is carried iteratively until convergence. The self labelling has been used for classifier-based transfer~\cite{Dai2007a,Tan2009}, and hybrid knowledge transfer~\cite{Dai2007,Chen2011}.
\begin{enumerate}
\item Self-training~\cite{Dai2007,Tan2009}\\
Initialize the target model parameters $\theta_l$ using the source data (or re-weighted source data), i.e. $\theta_l = \argmax_\theta \sum_{\mathbf{x}_s\in{X_s}} \log p(x_s,y_s|\theta)$. The pseudo labels of target samples can be obtained using the initial model, 
then use EM algorithm to iteratively refine the target model by incorporating some mechanisms 
(i.e. assign small weight to source samples that are dissimilar to target samples):
\begin{align}
& \text{E step}: \hat{y}_t = \argmax_{c} p(y_t=c|x_t,\theta_l)\\
& \text{M step}: \theta_{l+1} = \argmax_{\theta} \sum_{\mathbf{x}_t\in{X_t}}  w(x_t) \log p(x_t,\hat{y}_t|\theta) + \sum_{\mathbf{x}_s\in{X_s}} w(x_s) \log p(x_s,y_s|\theta)
\end{align}
where $w(x_t)$ and $w(x_t)$ are assigned weights to each target and source samples using some mechanisms.
\end{enumerate}
\item \textit{Hybrid Criterion:} combines two or more above criteria for better transferring of knowledge. The combination of criteria is generally used for feature representation transfer, classifier transfer, and hybrid knowledge transfer. Several examples of combination are
\begin{enumerate}
\item Correspondence + Higher-level representation~\cite{Huang2013}
\item Higher-level representation + Statistic~\cite{Long2013a,Long2015a,Wei2016}
\item Statistic + Geometric~\cite{Zhang2017}
\item Statistic + Self labelling~\cite{Dai2007a}
\item Correspondence + Class-based~\cite{Diethe2008}
\item Statistic + Class-based~\cite{Duan2012}
%\item Informatics + Class-based
\item Higher-level representation + Class-based~\cite{Zhu2014b}
\end{enumerate}
\end{itemize}

Based on the summary of different transferring criteria and the categories of ``what to transfer'', below, we discuss what kinds of methods can be used for boosting current task
% and avoiding ``negative transfer'' 
in the four different scenarios (homogeneous feature spaces and label spaces, heterogeneous label spaces, heterogeneous label spaces, and heterogeneous feature spaces and label spaces) defined in Section~\ref{sec:term} as well as corresponding problems defined by other dataset properties. An overview of the taxonomy can be found in Figure~\ref{tab:tax}. In each problem, the related work is reviewed according to transferring criteria: statistic criterion, geometric criterion, higher-level representations criterion, correspondence criterion, class-based criterion, self labelling, and hybrid criterion. Then the methods under each criterion are further subdivided into ``what to transfer'': instance-based transfer, feature representation-based transfer, classifier-based transfer, and hybrid knowledge transfer.
\begin{figure}
\includegraphics[scale=0.35]{DAtaxonomyNew11}
\vspace{-2.5em}
\caption{A taxonomy of cross-dataset recognition problems}
\label{tab:tax}
\end{figure}
\section{Homogeneous Feature Spaces and Label Spaces}
\label{sec:HOMO}
In this scenario, the feature spaces $\mathcal{X}$ as well as the label spaces $\mathcal{Y}$ are both identical between source and target datasets.
Hence, the source and target datasets are generally different in terms of data distributions ($P(X,Y)$).
\subsection{Labelled Target Dataset}
\label{sec:HOMOsup}
In this problem, a small number of labelled data in target domain are available. However, the labelled data in target domain are generally not sufficient for classification tasks. The characteristics of this problem can be found in Table~\ref{tab:HOMOsup}, which corresponds to \textit{supervised domain adaptation} among the literature.
\begin{table}[htbp!]
\caption{Characteristics of problem~\ref{sec:HOMOsup}}
\label{tab:HOMOsup}
\begin{center}
\begin{small}
\begin{tabular}{|p{1cm}<{\centering}|m{2.5cm}<{\centering}|m{4.3cm}<{\centering}|m{4.3cm}<{\centering}|}
\hline
\multicolumn{2}{|c|}{Attributes} & Source dataset & Target data \\
\hline \hline
\multirow{3}{*}{Data} & Feature space & Identical between two sets & Identical between two sets \\ 
\cline{2-4}{} & Availability & Sufficient & {\color{red}Insufficient}\\
\cline{2-4}{} & Balanced & Yes & Yes\\
\cline{2-4}{} & Sequential & No & No \\
\hline \hline
\multirow{2}{*}{Label} & Availability & Labelled & Labelled \\
\cline{2-4}{}  & Label space & Identical between two sets & Identical between two sets \\ 
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}

\subsubsection{Class-based Criterion}
\label{sec:HOMOSupClass}

\paragraph{Feature Representations-based Transfer}
The class-based criterion can be used for guiding the new representations of features for reducing the domain shift. For example, \citeN{DaumeIII2007} propose a feature augmentation based methods where each feature is replicated into a high-dimensional feature space. Specifically, the augmented source data contain general and source-specific version, while the augmented target data contain general and target-specific version.
The supervised metric learning methods can be used. \citeN{Zhang2010} propose a supervised transfer metric learning (TML) using the idea of multi-task metric learning.  
\citeN{Perrot2015} propose a metric hypothesis transfer learning, where a biased regularization is introduced to learn the target metric $M$ by regularizing the difference between the target metric $M$ and the source metric $M_S$. They also provide the theoretical analysis of supervised regularized metric learning approaches.

Some methods assume that samples from only a subset of categories are available in the target training set. Then the adapted features are generalized to unseen categories (which are unseen in target dataset, but have seen in source dataset). The reason why the methods under this setting are not discussed under the problem of heterogeneous label spaces is that they still assume the same label spaces between domains, but some of the categories are not presented in the target training set. Generally, these methods assume the shift between domains is category-independent.
For example, \citeN{Saenko2010} propose a supervised metric learning method to learn a transformation that minimizes the effect of domain-induced changes in the feature distribution using the target training labelled data from a subset of categories. Then the transformation is applied to unseen target test data that may come from different categories from the target training data.

\paragraph{Classifier-based Transfer}
The class-based criterion has been used for classifier-based methods that transfer the parameters of discriminative classifiers across datasets. \citeN{Yang2007} propose Adaptive Support Vector Machines (A-SVMs) to adapt one or more source classifiers to the target domain by learning a new decision boundary that is close to the original decision boundary as well as separating the target data. Similarly, \citeN{Jiang2008} propose cross-domain SVM (CD-SVM). They also want to preserve the discriminant property of new classifier over source data, which is addressed over important source data samples that have similar distribution to the target data. \citeN{Xu2014b} introduce the adaptive structural SVM (A-SSVM) and structure-aware A-SSVM (SA-SSVM) to adapt classifier parameters between domains by taking the structure knowledge in feature space into account. 
\subsubsection{Self Labelling}
\paragraph{Hybrid Knowledge Transfer}
The instance weights and classifier parameters are jointly exploited by~\cite{Dai2007}. They propose a transfer learning framework called TrAdaBoost, which extends boosting-based learning algorithms by adding a mechanism to decrease the weights of the instances that are the most dissimilar to the target distribution in order to weaken their impacts. The target labelled samples are used to help vote on the usefulness of each of the source domain data instance.

\subsubsection{Hybrid Criterion}
\paragraph{Feature Representation-based Transfer}
The higher-level representation criterion and class-based criterion can be used together for better cross-dataset representation. For example, \citeN{Zhu2013,Zhu2014} match source and target distributions via a cross-domain discriminative dictionary learning method, where a reconstructive, discriminative and domain-adaptive dictionary-pair are learned, such that the instances of same class from different domains have similar sparse codes representations. \citeN{Shekhar2013} also propose a dictionary learning based method. They jointly learn projections that map the data in the two domains into a low-dimensional subspace and a common discriminative dictionary which represent data of two domains in the projected subspace.

Except for the discriminative dictionary learning, the label information can also be used for guiding the deep neural networks to reduce domain shift. \citeN{Koniusz2017} utilize two CNN streams: the source and target networks fused at the classifier level. Features from the fully connected layers fc7 of each network are used to compute second- or even higher-order scatter tensors; one per network stream per class. Then the scatters of the two network streams of the same class (within-class scatters) are aligned while good separation of the between-class scatters are maintained. Hence, in addition to higher-level representation criterion and class-based criterion, the statistic criterion is also used in~\cite{Koniusz2017}.

\subsection{Labelled Plus Unlabelled Target Dataset}
\label{sec:HOMOsemi}
Compared to the scenario where only limited labelled target data are presented, additional redundant unlabelled target domain data are also presented in the training stage in this problem, which allows the algorithms to learn the structure information of target domain.
This setting is realistic in real world applications, where unlabelled data are much more easier to obtain than labelled data. 
The characteristics of problem~\ref{sec:HOMOsemi} are shown in Table~\ref{tab:HOMOsemi}, which is known as \textit{semi-supervised domain adaptation} among the literature.

\begin{table}[htbp!]
\caption{Characteristics of problem~\ref{sec:HOMOsemi}}
\label{tab:HOMOsemi}
\begin{center}
\begin{small}
\begin{tabular}{|p{1cm}<{\centering}|m{2.5cm}<{\centering}|m{4.3cm}<{\centering}|m{4.3cm}<{\centering}|}
\hline
\multicolumn{2}{|c|}{Attributes} & Source dataset & Target data \\
\hline \hline
\multirow{3}{*}{Data} & Feature space & Identical between two sets & Identical between two sets \\ 
\cline{2-4}{} & Availability & Sufficient & {\color{red}Insufficient labelled+ Sufficient unlabelled} \\
\cline{2-4}{} & Balanced & Yes & Yes \\
\cline{2-4}{} & Sequential & No & No \\
\hline \hline
\multirow{2}{*}{Label} & Availability & Labelled & {\color{red}Labelled+Unlabelled}\\
\cline{2-4}{}  & Label space & Identical between two sets & Identical between two sets \\ 
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}
%\vspace{-1em}
\subsubsection{Statistic Criterion}
\paragraph{Hybrid Knowledge Transfer}
\citeN{Zhong2009} propose an adaptive kernel approach that maps the marginal distributions of target and source domain data into a common kernel space, and utilize a sample selection strategy to draw conditional probabilities between the two domains closer, where the statistic criterion is used for both the feature transformation and instance re-weighting.
\subsubsection{Correspondence Criterion}
\paragraph{Feature Representation based Transfer}
\citeN{Zhai2010} assume in addition to a set of labelled correspondence pairs between source and target datasets, some unlabelled samples from both datasets are also available. They propose a manifold alignment method to learn explicit corresponding mappings from different manifolds to the underlying common embeddings, where the common embeddings should be consistent with the labelled corresponding pairs and also should preserve the local geometric structures of respective datasets.
\subsubsection{Class-based Criterion}
\paragraph{Feature Representation-based Transfer}
Some researches extend distance-based classifiers, such as the k-nearest neighbor (k-NN) and nearest class mean (NCM) classifiers, from a metric learning perspective to address domain adaptation. \citeN{Tommasi2013} present an NBNN-based domain adaptation algorithm that learns iteratively a class metric while inducing a large margin separation among classes for each sample. Similarly, \citeN{Csurka2014} extend the Nearest Class Mean (NCM) classifier by introducing for each class domain-dependent mean parameters as well as domain-specific weights. Then they propose a generic adaptive semi-supervised metric learning technique that iteratively curates the training set.

\citeN{Daume2010} extended fully supervised EASYADAPT method~\cite{DaumeIII2007} to semi-supervised setting, where the unlabelled data are utilized to co-regularize these learned hypotheses by making them agree on unlabelled samples. 
\paragraph{Classifier-based Transfer} \citeN{Duan2012c} extend SVM based classifier transfer methods with unlabelled target data. They proposed a domain-dependent regularizer which enforces that the learned target classifiers and the prelearned source classifiers should have similar decision values on the unlabelled target instances.

\paragraph{Hybrid Knowledge Transfer}
There is also a group of multiple kernel learning (MKL) based transfer methods~\cite{Duan2012a,Duan2012}, which learn a new feature representation that simultaneously reduce the distribution shift and optimize the target classifier, using both the statistic criterion and class-based criterion.
\citeN{Duan2012a} propose a Adaptive Multiple Kernel Learning (A-MKL) cross-domain learning method. A-MKL learns a kernel function and a classifier by minimizing both the structural risk functional and the distribution mismatch between domains using MMD criterion. In addition to A-MKL, \citeN{Duan2012} propose Domain Transfer Multiple Kernel Learning (DTMKL), where an additional regularization terms are proposed to enforce that the decision values from the target classifier and the existing base classifiers are similar on the unlabelled target patterns and the decision values from the target classifier on the labelled target data are close to the true labels. 

\subsubsection{Self Labelling}
\paragraph{Hybrid Knowledge Transfer}
The instance weights and feature representation can be exploited simultaneously in the self labelling framework. For example, \citeN{Chen2011} propose a co-training method in a self-training framework, which bridges the gap between source and target domains by slowly adding to the training set both the target features and instances, such that the current algorithm is the most confident. Then select a subset of shared source and target features based on their compatibility. Lastly, to better exploit the domain specific feature in the unlabelled target domain, the pseudo multiview co-training method is used to add additional features to the training set. 
\subsubsection{Hybrid Criterion}
\paragraph{Feature Representation-based Transfer}
A large group of feature representation-based methods in this problem combines statistic criterion and class-based criterion. \citeN{Pan2011} extend the unsupervised TCA method~\cite{Pan2009} to semi-supervised version by maximizing the label dependence using labelled target data while minimizing the MMD distance using unlabelled target data. \citeN{Yao2015} proposed a general subspace learning method for semi-supervised domain adaptation. They explore the low-dimensional structures across domains, such that the empirical risk of labelled samples from both domains are minimized, the distance between samples of same category from different domains is small, and the outputs of the predictive function are restricted to have similar values for similar examples. 
\citeN{Quanz2012} modify the idea of sparse coding by focusing the identification of shared clusters between data when source and target data may have different distributions by incorporating distribution distance estimates for the embedded data. The kernel density estimation is used for estimating the distributions and symmetric version of the common KL-divergence measure, the Jensen-Shannon divergence, is used for comparing two distributions. To incorporate target label information, the class-based distribution distance is estimated for each class.
\citeN{Tzeng2015} propose a CNN architecture that simultaneously learns a domain invariant representation using a domain confusion loss ($\mathcal{H}$ divergence) over all source and target data and transfers the learned source semantic structure to the target domain via soft labels (which is defined as the average over the softmax of all activations of source examples in each category). Similar to the settings of~\cite{Saenko2010}, labelled target data from only a subset of the categories of interest are available in the training stage. 

Recently, \citeN{Wu2016} introduce a constrained deep transfer feature learning method to perform simultaneous transfer learning and feature learning.  
Specifically, the paired source and target data are used for capturing the joint distribution of target and source data as a bridge between domains. Then additional large amount of unpaired source data are transferred to the target domain as pseudo data for further target domain feature learning. Hence, correspondence criterion and high-lever representation criterion are used.

\paragraph{Hybrid Knowledge Transfer}
\citeN{Yamada2014} generalize the EASYADAPT method~\cite{DaumeIII2007} to semi-supervised setting. They propose to project input features into a higher dimensional space as well as estimate weights for the training samples based on the ratio of test and training marginal distributions in that space using unlabelled target samples. Hence, the class-based criterion and statistic criterion are used for both feature representation and instance re-weighting.
\subsection{Unlabelled Target Dataset}
\label{sec:HOMOunsup}
In this problem, no labelled data in target domain are available but sufficient unlabelled target domain data are observable in the training stage.
Table~\ref{tab:HOMOunsup} gives characteristics of problem~\ref{sec:HOMOunsup}, where source domain has sufficient labelled data while target domain has sufficient unlabelled data. This problem is also named \textit{unsupervised domain adaptation}. The unsupervised domain adaptation has been attracted increasing attention in recent years, which is supposed to be more challenging and realistic.
\begin{table}[htbp!]
\caption{Characteristics of problem~\ref{sec:HOMOunsup}}
\label{tab:HOMOunsup}
\begin{center}
\begin{small}
\begin{tabular}{|p{1cm}<{\centering}|m{2.5cm}<{\centering}|m{4.3cm}<{\centering}|m{4.3cm}<{\centering}|}
\hline
\multicolumn{2}{|c|}{Attributes} & Source dataset & Target data \\
\hline \hline
\multirow{3}{*}{Data} & Feature space & Identical between two sets & Identical between two sets \\ 
\cline{2-4}{} & Availability & Sufficient & Sufficient  \\
\cline{2-4}{} & Balanced & Yes & Yes \\
\cline{2-4}{} & Sequential & No & No \\
\hline \hline
\multirow{2}{*}{Label} & Availability & Labelled & {\color{red}Unlabelled}\\
\cline{2-4}{}  & Label space & Identical between two sets & Identical between two sets \\ 
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}
%\vspace{-1em}

\subsubsection{Statistic Criterion}
\paragraph{Instance-based Transfer}
\citeN{Huang2006} present the kernel mean matching (KMM) method which directly produces resampling weights using MMD criterion, without the need of explicit distribution estimation. \citeN{Sun2011} propose a two-stage domain adaptation methodology which combines weighted data from multiple sources based on marginal probability differences (first stage) using MMD criterion as well as conditional probability differences (second stage) by computing the weights of multiple sources. \citeN{Gong2013} select a subset of the source data by choosing the samples that are distributed most similarly to the target using MMD criterion. A balancing constraint is added to balance the selected number of landmarks in each class. Differently, \citeN{Sugiyama2008} propose to estimate the sample importance using Kullback-Leibler divergence without explicit density estimation.

Rather than assuming single domain in a dataset, some methods assume a dataset may contain several distinctive sub-domains due to the large variations in visual data. For example, \citeN{Gong2013a} automatically discover latent domains from multiple sources. The latent domains are characteristic in terms of their large inter-domain variations and can derive strong discriminative models to apply to new testing data.
\paragraph{Feature Representation-based Transfer} 
The first line of feature representation-based methods use the MMD criterion as a distance measure for two distributions. \citeN{Pan2008} propose a kernel learning method to minimizes the distance between distributions of the data. In addition to the idea in~\cite{Pan2008}, \citeN{Chen2009} minimize the distribution shift, while at the same time minimizing the empirical loss on the labelled data in the source domain. \citeN{Pan2009} then proposed transfer component analysis (TCA), for domain adaptation by extending kernel learning in~\cite{Pan2008} to learn a parametric kernel map, which can deal with out-of-sample problem and is more efficient in solving the objective function. \citeN{Baktashmotlagh2013} compare the distributions on the transformed data in RKHS space rather than a lower-dimensional space as in TCA. 
Rather than merely minimizing marginal distribution alone, \citeN{Long2013} adapt the joint distribution in a principled dimensionality reduction procedure by iteratively estimating pseudo labels of target data for the adaptation of conditional distribution. 
\citeN{Geng2011} propose a domain adaptation metric learning (DAML), by introducing the MMD regularization between domains to the conventional metric learning framework. 

Instead of using MMD to compare two distributions, other statistic criteria, such as Hellinger distance on statistical manifolds, Quadratic divergence, and mutual information, are also used in this settings among literature~\cite{Baktashmotlagh2014,Si2010,Jhuo2012,Shi2012}. \citeN{Baktashmotlagh2014} argued that MMD criterion does not exploit the fact that probability distributions lie on a Riemannian manifold. They proposed to make better use of the structure of the manifold and rely on Hellinger distance on the manifold to compare the source and target distributions. In the work of \citeN{Si2010}, the Quadratic divergence-based regularization is used to measure the difference between distributions. Thus, a family of subspace learning algorithms can be used for reduce the domain shift by adding the Bregman divergence-based regularization. \citeN{Shi2012} reduce the distribution divergence from the information-theoretic perspective, where the joint distribution divergence is reduced by minimizing the mutual information between domains maximizing the mutual information between the data and the estimated labels based on the discriminative clustering assumption. \citeN{Sun2016} propose the CORrelation ALignment (CORAL) to minimize domain shift by aligning the second-order statistics.

Different from previous global transformation, Optimal Transport~\cite{Courty2016} defines a local transformation for each sample in the source domain. The domain adaptation problem is seen as a graph matching problem, where each source sample are mapped on target samples under the constraint of marginal distribution preservation.

\paragraph{Classifier-based Transfer}
Rather than reducing the distribution shift in the feature space, some methods use MMD criteria to regularize the classifier trained on the source domain using target domain unlabelled data. For instance, \citeN{Quanz2009} incorporate the MMD criterion as a constraint into the SVM paradigm. Hence, it achieves a trade-off between the large margin class separation in the source domain and the minimization of marginal distribution discrepancy between domains, as projected along the linear classifier. Similarly, \citeN{Long2014a} extend Quanz's method to reduce both marginal and conditional distribution discrepancies between domains in the domain invariant classifier learning framework.
\paragraph{Hybrid Knowledge Transfer}
Some methods jointly re-weight instances and map feature to a common space~\cite{Long2014,Hsu2015}. \citeN{Long2014} reduce the domain divergence by jointly matching the features and re-weighting the source domain instances in a low-dimensional space using MMD. 
There are also methods assume that the target domain contains a subset of categories presented in the source dataset. For example, \citeN{Hsu2015} propose Closest Common Space Learning (CCSL) for associating data that the label numbers across domains are different or collected from multiple datasets, with the capability of preserving label and structural information within and across domains.

\subsubsection{Geometric Criterion}
\paragraph{Feature Representation-based Transfer}
\citeN{Gopalan2011} propose a Sampling Geodesic Flow (SGF) method by creating intermediate representations of data between the two domains. The generative subspaces created from these intermediate domains are viewed as points on the Grassmann manifold, and points along the geodesic between them are sampled to obtain subspaces for adapting between domains. However, the limitation is that the number of intermediate points is a hard-to-determine hyper-parameter. \citeN{Gong2012} tackle this problem by extending the idea in~\cite{Gopalan2011} to a geodesic flow kernel (GFK) method that integrates an infinite number of subspaces that characterize changes from the source to the target domain. The methods in~\cite{Gopalan2011,Gopalan2014} and~\cite{Gong2012,Gong2014} open the opportunity of researches on constructing intermediate domains to bridge the mismatch. For example, \citeN{Caseiro2015} extend SGF~\cite{Gopalan2011} method to multiple source datasets. They use smooth polynomial functions described by splines on the manifold to interpolate between all the source domains and the target domain. \citeN{Zhang2013b} connect the source and target domain by interpolate virtual views by a virtual path for the cross-view action recognition. Rather than manipulating on the subspaces, \citeN{Cui2014} characterize samples from each domain as one covariance matrix and interpolate some intermediate points (i.e., covariance matrices) to bridge the two domains. There are also methods~\cite{Ni2013,Xu2015} generate a set of intermediate dictionaries by learning the domain-adaptive dictionaries between domains. 

Instead of modelling intermediate domains, some methods align the two domains directly~\cite{Fernando2013,Cui2014a}. For instance, \citeN{Fernando2013} learn a mapping function which aligns the source subspace with the target one directly. \citeN{Cui2014a} propose to align the manifolds defined by source and target datasets by integrating geometry structure matching, feature matching and geometry preserving.

Most of the existing methods assume a global shift, but ignore the individual class differences across domains. \citeN{Lin2016} take the individual class differences into consideration and generate one joint subspace for each class independently. Then assign labels to the anchor subspaces (with unlabelled samples that are close to each other) in the target domain for guiding the learning of joint subspace of each class. Specifically, the labels of anchor subspaces are assigned using the principle angles as a measure for calculating the similarities between them and source subspaces.
\subsubsection{Higher-level Representation Criterion}
\label{sec:HomoUnsupHRC}
\paragraph{Feature Representation-based Transfer}
\citeN{Blitzer2006} propose a structural correspondence learning (SCL) method to identify correspondences among features from different domains. The correlations are modelled with pivot features that behave in the same way for discriminative learning in both domains. The extracted pivot features are used to learn a mapping that maps the original feature of both domains to a shared feature space. 

The low-rank criterion is also used to guide the learning of domain invariant representations~\cite{Jhuo2012,Shao2014,Ding2015a}. \citeN{Jhuo2012} propose to capture the intrinsic relatedness of the source samples using a low-rank structure and meanwhile identifies the noise and outlier information using a sparse structure. Specifically, the source samples are transformed to an intermediate representation such that each source sample can be linearly represented by the samples of target domain. Similarly, \citeN{Shao2014} propose to project both source and target data to a generalized subspace where each target sample can be represented by a low-rank transformation of source samples. \citeN{Ding2015a} extend the low-rank coding method to a deep low-rank coding method, where multiple layers are stacked to learn the multi-level features across two domains. Each layer is constrained by a low-rank coding.

There are also methods use dictionary learning method to learn domain invariant representations~\cite{Peng2016,Tsai2016}. \citeN{Peng2016} propose a Multi-task Dictionary Learning (UMDL) model to learn view-invariant and discriminative information for the task of person re-identification. Three types of dictionaries are learnt: task shared dictionary that is dataset invariant, target specific dictionary that is view-invariant, and task specific residual dictionary that encodes the residual parts of features that cannot be modelled by the source task. Similar to \cite{Hsu2015}, \citeN{Tsai2016} also assume that the target domain contains a subset of categories presented in the source dataset. 
They derive a domain invariant space for aligning and representing cross domain data with a locality constraint sparse coding method.

\citeN{Bengio2012} argue that deep neural networks can learn more transferable features by disentangling the unknown factors of variation that underlie the training distribution.
%exploit the unknown structure in the input distribution in order to discover good representations, often at multiple levels, with higher-level learned features defined in terms of lower-level features. 
\citeN{Donahue2014} propose the deep convolutional representations named DeCAF, where a deep convolutional neural network is pre-trained using the previous large scale source dataset in a fully supervised fashion. Then transfer the features (defined by the convolutional network weights learned on source dataset) to the target data.

The deep auto-encoders are also used for the cross-dataset tasks~\cite{Glorot2011,Kan2015,Chen2012,Jiang2016,Ghifary2016a}. \citeN{Glorot2011} propose to use stacked denoising autoencoders (SDAs) to learn more transferable features for domain adaptation. \citeN{Kan2015} propose a Bi-shifting Auto-Encoder Network (BAE), which has one common encoder, two domain specific decoders. The proposed BAE can shift source domain samples to the target domain and also shift the target domain data to the source domain using the sparse reconstruction to ensure the distribution consistency. \citeN{Ghifary2016a} propose a Deep Reconstruction-Classification Network (DRCN), which jointly learns a shared encoding representation for two tasks: i) supervised classification of labelled source data, and ii) unsupervised reconstruction of unlabelled target data. \citeN{Chen2012} identify that the SDAs are limited by their high computational cost. Hence, they propose marginalized SDA (mSDA) by adopting the greedy layer-by-layer training of SDAs for domain adaptation.

The CoGAN~\cite{Liu2016} approach applied Generative Adversarial Networks (GANs)~\cite{Goodfellow2014} to the domain transfer problem by training two GANs to generate the source and target images respectively. This weight-sharing constraint allows CoGAN to learn a joint distribution of two domains. The intuition is that the images from different domains share the same high-level abstraction but have different low-level realizations.
\subsubsection{Hybrid Criterion}
\paragraph{Feature Representation-based Transfer}\citeN{Zheng2012} propose to learn two dictionaries simultaneously for pairs of correspondence video and encourage each video in the pair to have the same sparse representation, where both correspondence and higher level representation criteria are used. Similarly, \citeN{Huang2013} present a joint model which learns a pair of dictionaries with a feature space for describing and associating cross-domain data. \citeN{Long2013a} incorporate MMD criterion into the objective function of sparse coding to make the new representations robust to the distribution difference. \citeN{Sun2015} extend the subspace alignment~\cite{Fernando2013} by aligning the second-order of statistics (covariance) as well as the subspace bases. \citeN{Zhang2017} propose to learn two coupled projections that project the source domain and target domain data into low-dimensional subspaces where the geometrical shift and distribution shift are reduced simultaneously using both geometric and statistic criteria.

As mentioned in Section\ref{sec:HomoUnsupHRC}, deep neural networks can learn more transferable features for domain adaptation~\cite{Bengio2012,Donahue2014}, by disentangling explanatory factors of variations underlying data samples, and grouping deep features hierarchically according to their relatedness to invariant factors. However, the features computed in higher layers of the network must depend greatly on the specific dataset and task~\cite{Yosinski2014}, which are task-specific features and are not safely transferable to novel tasks. Hence, some recent work impose statistic criterion into the deep learning framework to further reduce domain bias. For instance, the MMD criterion is used to reduce divergence of marginal distributions~\cite{Tzeng2014,Long2015a} or joint distributions~\cite{Long2017} between domains. \citeN{Long2016} use MMD to learn transferable features and adaptive classifiers. They relax a shared-classifier assumption made by previous methods and assume that the source classifier and target classifier differ by a residual function~\cite{He2016}. \citeN{Sun2016a} extend the CORrelation ALignment (CORAL) method~\cite{Sun2016} to align the second-order statistics of the source and target distributions in deep learning framework. \citeN{Zellinger2017} propose the Central Moment Discrepancy (CMD) method to match the higher order central moments of probability distributions by means of order-wise moment differences, which does not require computationally expensive distance and kernel matrix computations. 

The statistic criterion is also incorperated into the deep autoencoder. \citeN{Wei2016} propose to use MMD distance to quantify the domain divergence and incorporate it in the learning of the transformation in the mSDA. The Domain Separation Networks (DSN)~\cite{Bousmalis2016} introduces the notion of a private subspace for each domain, which captures domain specific properties, such as background and low level image statistics. A shared subspace, enforced through the use of autoencoders and explicit loss functions (i.e. MMD or $\mathcal{H}$ divergence), captures shared features between the domains. The model integrates a reconstruction loss using a shared decoder, which learns to reconstruct the input sample by using both the private and shared representations.

\citeN{Hu2015a} propose a deep transfer metric learning (DTML) in a deep learning framework, where inter-class variations are maximized and the intra-class variations are minimized, and the distribution divergence between the source domain and the target domain at the top layer of the network is minimized, simultaneously. Similar to~\cite{Hu2015a}, \citeN{Ding2017} also propose a metric learning based method. However, their method is developed in marginalized denoising scheme and low-rank constraint is incorporated to guide the cross-domain metric learning by uncovering more common feature structure across two domains. In addition, the marginal and conditional distribution differences across two domains are both leveraged.

Inspired by the recent adversarial learning~\cite{Goodfellow2014}, the $\mathcal{H}$ divergence is used to encourage samples from different domains to be non-discriminative with respect to domain labels~\cite{Tzeng2015,Ganin2015,Ganin2016,Tzeng2017,Bousmalis2017}. For example, \citeN{Tzeng2015} proposed adding a domain classifier that predicts the binary domain label of the inputs and designed a domain confusion loss to encourage its prediction to be as close as possible to a uniform distribution over binary labels. The gradient reversal algorithm (ReverseGrad) proposed by \citeN{Ganin2015} also treats domain invariance as a binary classification problem, but directly maximizes the loss of the domain classifier by reversing its gradients. \citeN{Bousmalis2017} propose a GAN-based method that adapts source-domain images to appear as if drawn from the target domain in pixel level. \citeN{Sankaranarayanan2017} propose an adversarial image generation frame-work to directly learn the shared feature embedding using labelled data from source and unlabelled data from the target.

\paragraph{Classifier-based Transfer}
\citeN{Dai2007a} use both self labelling and statistic criterion to transfer Naive Bayes classifier. They first estimate the initial probabilities under source domain distribution, and then use an EM algorithm to revise the model for the target distribution. Moreover, the Kullback-Leibler (KL) divergence is used to measure the distance between the training and test data. Then the distance is used to estimate the trade-off parameters. 

\citeN{Saito2017} propose an asymmetric tri-training method for unsupervised domain adaptation, where the pseudo-labels are assigned to unlabelled samples and train the deep neural networks as if they are true labels. Hence, both self-labelling and high level representations are used.
\paragraph{Hybrid Knowledge Transfer}
\citeN{Aljundi2015} consider both subspace alignment and selection of landmarks similarly distributed between the two domains. Those landmarks are selected so as to reduce the discrepancy between the domains and then are used to non linearly project the data in the same space. Hence, both geometric and statistic criteria are used for transferring instance and feature representations.


\subsection{Imbalanced Unlabelled Target Dataset}
\label{sec:HOMOimb}
This problem assumes the target domain is class imbalanced and only with unlabelled data. Thus, the statistic criterion can be used. This problem is known as \textit{prior probability shift}, or \textit{imbalanced data} in the context of classification. The imbalanced data issue is quite common in practice. For example, the abnormal actions (kick, punch, or fall down) are generally much rarer than normal actions in video surveillance but generally require higher recognition rate.
\begin{table}[htbp!]
\caption{Characteristics of problem~\ref{sec:HOMOimb}}
\label{tab:HOMOimb}
\begin{center}
\begin{small}
\begin{tabular}{|p{1cm}<{\centering}|m{2.5cm}<{\centering}|m{4.3cm}<{\centering}|m{4.3cm}<{\centering}|}
\hline
\multicolumn{2}{|c|}{Attributes} & Source dataset & Target data \\
\hline \hline
\multirow{3}{*}{Data} & Feature space & Identical between two sets & Identical between two sets \\ 
\cline{2-4}{} & Availability & Sufficient & Sufficient  \\
\cline{2-4}{} & Balanced & Yes & {\color{red}No} \\
\cline{2-4}{} & Sequential & No & No \\
\hline \hline
\multirow{2}{*}{Label} & Availability & Labelled & {\color{red}Unlabelled} \\
\cline{2-4}{}  & Label space & Identical between two sets & Identical between two sets \\ 
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}
%\vspace{-1em}

\subsubsection{Statistic Criterion}
\paragraph{Feature Representation-based Transfer}
In the classification scenario, the prior probability ($P(Y)$) shift was referred to the class imbalance problem~\cite{Japkowicz2002,Zhang2013a}. The statistic criterion can be used. \citeN{Zhang2013a} assume the $P(Y)$ between source and target datasets are different, but the source set is richer than the target set, such that the support of $P(Y)^{target}$ is contained in the support of $P(Y)^{source}$. Then they tackle the prior probability shift by re-weighting the source samples using similar idea as Kernel Mean Matching method~\cite{Huang2006}. They also define the situation where both $P(Y)$ and $P(X|Y)$ change across datasets and propose a kernel approach to re-weight and transform the source data to reduce the distribution shift by assuming that the source domain can be transferred to the target domain by location-scale (LS) transformation (the $P(X|Y)^{source}$ and $P(X|Y)^{source}$ only differs in the location and scale). Rather than assuming that all the features can be transferred to the target domain by LS transformation, \citeN{Gong2016} propose to learn the conditional invariant components by a linear transformation, and then re-weight the source domain data to reduce shift of $P(Y)$ and $P(Y|X)$ between domains. 

Recently, \citeN{Yan2017} introduce class-specific auxiliary weights into the original MMD for exploiting the class prior probability on source and target domains. The proposed weighted MMD model is defined by introducing an auxiliary weight for each class in the source domain, and a classification EM algorithm is suggested by alternating between assigning the pseudo-labels, estimating auxiliary weights and updating model parameters.

\subsection{Sequential Labelled Target Data}
\label{sec:HOMOlseq}
In real world applications, the target data can be sequential video streams or continuous evolving data. The distribution of the target data may also change with time. Since the target data are labelled, this problem is named \textit{supervised online domain adaptation}.
\begin{table}[htbp!]
\caption{Characteristics of problem~\ref{sec:HOMOseq}}
\label{tab:HOMOlseq}
\begin{center}
\begin{small}
\begin{tabular}{|p{1cm}<{\centering}|m{2.5cm}<{\centering}|m{4.3cm}<{\centering}|m{4.3cm}<{\centering}|}
\hline
\multicolumn{2}{|c|}{Attributes} & Source dataset & Target data \\
\hline \hline
\multirow{3}{*}{Data} & Feature space & Identical between two sets & Identical between two sets \\ 
\cline{2-4}{} & Availability & Sufficient & {\color{red}Insufficient}  \\
\cline{2-4}{} & Balanced & Yes & Yes \\
\cline{2-4}{} & Sequential & No & {\color{red}Yes} \\
\hline \hline
\multirow{2}{*}{Label} & Availability & Labelled & Labelled \\
\cline{2-4}{}  & Label space & Identical between two sets & Identical between two sets \\ 
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}
%\vspace{-1em}
\subsubsection{Self Labelling}
\paragraph{Classifier-based Methods}
\citeN{Xu2014a} propose an incremental domain adaptation for object detection by assuming weak-labelling. Specifically, the adaptation model is a weighted ensemble of source and target classifiers and the ensemble weights are updated with time.
\subsection{Sequential Unlabelled Target Data}
\label{sec:HOMOseq}
Similar to problem in~\ref{sec:HOMOlseq}, the target data are sequential in this problem, however, no labelled target data is available, which is named \textit{unsupervised online domain adaptation} and related to but different from \textit{concept drift}. The concept drift~\cite{Gama2014} refers to changes in the conditional distribution of the output given the input, while the distribution of the input stays unchanged, while in online domain adaptation the changes between domains are caused by the changes of the input distribution.
\begin{table}[htbp!]
\caption{Characteristics of problem~\ref{sec:HOMOseq}}
\label{tab:HOMOseq}
\begin{center}
\begin{small}
\begin{tabular}{|p{1cm}<{\centering}|m{2.5cm}<{\centering}|m{4.3cm}<{\centering}|m{4.3cm}<{\centering}|}
\hline
\multicolumn{2}{|c|}{Attributes} & Source dataset & Target data \\
\hline \hline
\multirow{3}{*}{Data} & Feature space & Identical between two sets & Identical between two sets \\ 
\cline{2-4}{} & Availability & Sufficient & Sufficient  \\
\cline{2-4}{} & Balanced & Yes & Yes \\
\cline{2-4}{} & Sequential & No & {\color{red}Yes} \\
\hline \hline
\multirow{2}{*}{Label} & Availability & Labelled & {\color{red}Unlabelled} \\
\cline{2-4}{}  & Label space & Identical between two sets & Identical between two sets \\ 
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}
%\vspace{-1em}
\subsubsection{Geometric Criterion}
\paragraph{Feature Representation-Based Transfer}  
\citeN{Hoffman2014a} extend the Subspace Alignment~\cite{Fernando2013} to continuous evolving target domain. Both the subspaces and subspace metrics that align the two subspaces are updated after each new target sample comes. \citeN{Bitarafan2016} tackle the continuously evolving target domain by using the idea of GFK~\cite{Gong2012} to construct linear transformation. The linear transformation is updated after a new batch of unlabelled target domain data come. Each batch of arrived target data are classified after the transformation and included to the source domain for recognizing the next batch of target data. 

\subsubsection{Self Labelling}
\paragraph{Classifier-based Transfer} \citeN{Jain2011} address the online adaptation in the face detection task by adapting pre-trained classifiers using a Gaussian process regression scheme. The intuition is that the ``easy-to-detect'' faces can help the detection of ``hard-to-detect'' faces by normalizing the co-occurring ``hard-to-detect'' faces and thus reducing their difficulty of detection. 
%The parameters of generative model can be transferred for target task. 
Differently, \citeN{Cao2010a} address the cross-dataset action detection problem by proposing a Maximum a Posterior (MAP) estimation framework, which explores the spatial-temporal coherence of actions and makes use of the prior information. \citeN{Xu2016} propose an online domain adaptation model for multiple object tracking based on a two-level hierarchical adaptation tree, which consists of instance detectors in the leaf nodes and a category detector at the root node. The adaptation is executed in a progressive manner.

\subsection{Unavailable Target Data}
\label{sec:HOMOgene}
This problem is also named \textit{domain generalization} among the literature, where the target domain data are assumed not to be presented in training stage. Thus, multiple source datasets are generally required to learn the dataset invariant knowledge that can be generalized to new dataset.
\begin{table}[htbp!]
\caption{Characteristics of problem~\ref{sec:HOMOgene}}
\label{tab:HOMOgene}
\begin{center}
\begin{small}
\begin{tabular}{|p{1cm}<{\centering}|m{2.5cm}<{\centering}|m{4.3cm}<{\centering}|m{4.3cm}<{\centering}|}
\hline
\multicolumn{2}{|c|}{Attributes} & Source dataset & Target data \\
\hline \hline
\multirow{3}{*}{Data} & Feature space & Identical between two sets & Identical between two sets\\ 
\cline{2-4}{} & Availability & Sufficient & {\color{red} No}  \\
\cline{2-4}{} & Balanced & Yes & -\\
\cline{2-4}{} & Sequential & No & No\\
\hline \hline
\multirow{2}{*}{Label} & Availability & Labelled & - \\
\cline{2-4}{}  & Label space & Identical between two sets & Identical between two sets\\ 
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}
%\vspace{-1em}
\subsubsection{Higher-level Representation Criterion}
\paragraph{Feature Representation-Based Transfer} Most of the existing work tackle this problem by learning domain invariant and compact representation from source domains~\cite{Blanchard2011,Khosla2012,Muandet2013,Fang2013,Stamos2015,Ghifary2016}. For example, \citeN{Khosla2012} propose a discriminative framework that explicitly defines a bias associated with each dataset and attempts to approximate the weights for the visual world by undoing the bias from each dataset. \citeN{Muandet2013} propose the Domain-Invariant Component Analysis (DICA), a kernel-based optimization algorithm that learns an invariant transformation by minimizing the dissimilarity across domains, whilst preserving the functional relationship between input and output variables.  
\citeN{Fang2013} propose an unbiased metric learning approach to learn unbiased metric from multiple biased datasets. \citeN{Ghifary2016} propose a scatter component analysis (SCA) method that finds a representation that trades between maximizing the separability of classes, minimizing the mismatch between domains, and maximizing the separability of data. 

%Rather than extracting domain invariant features, 
The ensemble of classifiers learnt from multiple sources is also used for generalizing to unseen target domain~\cite{Xu2014,Niu2015a,Niu2015}. \citeN{Xu2014} propose to exploit the low-rank structure from multiple latent source domains. Then the domain shift is reduced in an exemplar-SVMs framework by regularizing the likelihoods of positive samples within the same latent domain from each exemplar classifier to be similar. 
Similarly, \citeN{Niu2015a} extend this idea to the source domain samples with multiple types of features (i.e., multi-view features).
\citeN{Niu2015} explicitly discover the multiple hidden domains with different data distributions using previous methods~\cite{Gong2013a}. And then one classifier for each class and each latent domain is learnt to form an ensemble of classifiers.

\section{Heterogeneous Feature Spaces}
\label{sec:HETEF}
This section discusses the problems that the feature spaces $\mathcal{X}$ between source and target datasets are different but the label spaces $\mathcal{Y}$ are the same. The different feature spaces can be caused by different data modalities or different feature extraction methods. 

\subsection{Labelled Target Dataset}
\label{sec:HETESsup}
This problem assumes limited target data are presented in the training stage, see Table~\ref{tab:HETESsup}. This problem is named \textit{supervised heterogeneous domain adaptation}.
\begin{table}[htbp!]
\caption{Characteristics of problem~\ref{sec:HETESsup}}
\label{tab:HETESsup}
\begin{center}
\begin{small}
\begin{tabular}{|p{1cm}<{\centering}|m{2.5cm}<{\centering}|m{4.3cm}<{\centering}|m{4.3cm}<{\centering}|}
\hline
\multicolumn{2}{|c|}{Attributes} & Source dataset & Target data \\
\hline \hline
\multirow{3}{*}{Data} & Feature space & Different from target & {\color{red}Different from source} \\ 
\cline{2-4}{} & Availability & Sufficient & {\color{red}Insufficient} \\
\cline{2-4}{} & Balanced & Yes & Yes \\
\cline{2-4}{} & Sequential & No & No \\
\cline{2-4}
\hline \hline
\multirow{2}{*}{Label} & Availability & Labelled & Labelled \\
\cline{2-4}{}  & Label space & Identical between two sets & Identical between two sets \\ 
\cline{2-4}
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}
\subsubsection{Higher-level Representation Criterion}
\label{sec:heteSupHLR}
\paragraph{Feature Representation-based Transfer} 
Some methods assume that the source and target datasets are different only in terms of feature spaces while the distributions are the same between datasets.
%, which have been addressed mostly by higher-level representation criterion. 
Since the labelled data in the target dataset are scarce, \citeN{Zhu2011} propose to use the auxiliary heterogeneous data that contain both modalities from Web to extract the semantic concept and find the shared latent semantic feature space between different modalities. There are also methods assume that not only the feature spaces are heterogeneous between domains, the data distributions are also diverged, which will be discussed in Section~\ref{sec:heteSupHyb}.

\subsubsection{Class-based Criterion}
\paragraph{Feature Representation-based Transfer} 
The class-based criterion has also been used to connect heterogeneous feature spaces. 
Finding relationship between different feature spaces can be seen as translating between different languages. Hence, \citeN{Dai2008} propose a translator using a language model to translate between source and target feature spaces using the class labels. They argue that though the limited number of labelled data in the target domain is not sufficient for building a good classifier, an effective translator can be constructed. \citeN{Kan2012} propose a multi-view discriminant analysis by seeking for a discriminant common space by jointly learning multiple view-specific linear transformations using label information. Manifold alignment method is also used for heterogeneous domain adaptation with the class-based criterion. 
For example, \citeN{Wang2011} propose to make use of class label information to align the manifolds for heterogeneous domain adaptation. They treat each input domain as a manifold. The goal is to find the respective mappings for each domain to project them into a latent space where the topology, i.e. the manifold structure, is preserved and the discriminative information of each domain is also preserved.

The feature augmentation based method has also been proposed~\cite{Duan2012b,Li2014}, which transforms the data from two domains into a common subspace, then two new feature mapping functions are proposed to augment the transformed data with their original features and zeros.

Similar to the case~\cite{Saenko2010} in the homogeneous feature spaces as mentioned in Section~\ref{sec:HOMOSupClass}, a line of research assumes the label spaces of target training set and target test set are non overlapping subsets of source label space. \citeN{Kulis2011} extend~\cite{Saenko2010} to learn an asymmetric non-linear transformation that maps points from one domain to another domain using supervised data from both domains.
\citeN{Hoffman2012} extend~\cite{Kulis2011} to multi-domain adaptation by discovering latent domains with heterogeneous but unknown structure.

\paragraph{Classifier-based Transfer} 
Instead of using the idea of metric learning to learn the asymmetric feature transformation between heterogeneous features~\cite{Kulis2011}, the asymmetric metric of classifiers can also be learnt to bridge source and target classifiers on heterogeneous features. 
For instance, \citeN{Zhou2014} propose to learn the feature mapping across heterogeneous features by maximizing the dependency between the mapped source and target classifier weight vectors. In their formulation, the transformation matrix is constrained to be sparse and class-invariant.

\subsubsection{Hybrid Criterion}
\paragraph{Feature Representation-based Transfer} 
\label{sec:heteSupHyb}
By contrast to the scenario mentioned in Section~\ref{sec:heteSupHLR}, where the source and target datasets are different only in terms of feature spaces, another scenario assumes that both the feature spaces and the data distributions are different. \citeN{Shekhar2015} extend~\cite{Shekhar2013} to heterogeneous feature spaces, where the two projections and a latent dictionary are jointly learnt to simultaneously find a common discriminative low-dimensional space and reduce the distribution shift. Similarly, \citeN{Sukhija2016} use the shared label distributions present across the domains as pivots for learning a sparse feature transformation. The shared label distributions and the relationship between the feature spaces and the label distributions are estimated in a supervised manner using random forests. Hence, the higher-level representation and class-based criteria are used in both methods.
 
\paragraph{Hybrid Knowledge Transfer}
\citeN{Hoffman2013} extend~\cite{Kulis2011} to scale well to large dataset by proposing a Max-Margin Domain Transforms (MMDT) method that provides a way to adapt max-margin classifiers and an asymmetric transform jointly to optimize both the feature representation and the classifier parameters. The MMDT can be optimized quickly in linear space.
Similar to~\cite{Shekhar2015,Sukhija2016}, \citeN{Shi2010} also assume both feature spaces and data distributions are different between datasets. They propose to learn a spectral embedding to unify the different feature spaces and use sample selection method to deal with distribution mismatch. Hence, both feature transformation and sample selection are preceded. 
\subsection{Labelled Plus Unlabelled Target Dataset}
\label{sec:HETESsemi}
In this problem, both limited labelled and sufficient unlabelled target data are presented (Table~\ref{tab:HETESsemi}), which is named \textit{semi-supervised heterogeneous domain adaptation}.
\begin{table}[htbp!]
\caption{Characteristics of problem~\ref{sec:HETESsemi}}
\label{tab:HETESsemi}
\begin{center}
\begin{small}
\begin{tabular}{|p{1cm}<{\centering}|m{2.5cm}<{\centering}|m{4.3cm}<{\centering}|m{4.3cm}<{\centering}|}
\hline
\multicolumn{2}{|c|}{Attributes} & Source dataset & Target data \\
\hline \hline
\multirow{3}{*}{Data} & Feature space & Different from target & {\color{red}Different from source} \\ 
\cline{2-4}{} & Availability & Sufficient & {\color{red}Insufficient Labelled+ Sufficient unlabelled}  \\
\cline{2-4}{} & Balanced & Yes & Yes \\
\cline{2-4}{} & Sequential & No & No \\
\hline \hline
\multirow{2}{*}{Label} & Availability & Labelled & {\color{red}Labelled+Unlabelled} \\
\cline{2-4}{}  & Label space & Identical between two sets & Identical between two sets \\ 
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}
%\vspace{-1em}
 
\subsubsection{Statistic Criterion}
\paragraph{Hybrid Knowledge Transfer}
\citeN{Tsai2016a} propose a learning algorithm of Cross-Domain Landmark Selection (CDLS) for solving heterogeneous domain adaptation (HDA) using the statistic criterion (MMD), where the instance weights and feature transformation are learnt simultaneously.
%Instead of viewing all cross-domain data to be equally important during adaptation, 
Specifically, the CDLS derives a heterogeneous feature transformation which results in a domain-invariant subspace for associating cross-domain data, and assign weight to each instance according to their adaptation ability using both labelled and unlabelled target samples.
\subsubsection{Class-based Criterion}
\paragraph{Feature Representation-based Transfer} 
\citeN{Xiao2015} propose a kernel matching method for heterogeneous domain adaptation. The target data points are mapped to similar source data points by matching the target kernel matrix to a submatrix of the source kernel matrix using the label information. Specifically,
The labelled target samples perform as pivot points for class separation, where each labelled target sample is mapped into a source sample with the same class label. Then the unlabelled target instances are expected to be mapped to the source samples with same labels with the guides of labelled pivot points through a distance measure between samples. 

\subsection{Unlabelled Target Dataset}
\label{sec:HETESunsup}
This problem assumes no labelled target data is available (see Table~\ref{tab:HETESunsup}). We name this problem as \textit{unsupervised heterogeneous domain adaptation}. In this problem, the feature spaces can be completely different between dataset. On the other hand, it can also be assumed that the source data consist of multiple modalities while the target data only contain one of the modalities, or vice versa. This scenario is also considered under this problem because the relationships between different feature spaces still need to be exploited.
\begin{table}[htbp!]
\caption{Characteristics of problem~\ref{sec:HETESunsup}}
\label{tab:HETESunsup}
\begin{center}
\begin{small}
\begin{tabular}{|p{1cm}<{\centering}|m{2.5cm}<{\centering}|m{4.3cm}<{\centering}|m{4.3cm}<{\centering}|}
\hline
\multicolumn{2}{|c|}{Attributes} & Source dataset & Target data \\
\hline \hline
\multirow{3}{*}{Data} & feature space & Different from target & {\color{red}Different from source} \\ 
\cline{2-4}{} & Availability & Sufficient & Sufficient \\
\cline{2-4}{} & Balanced & Yes & Yes \\
\cline{2-4}{} & Sequential & No & No \\
\hline \hline
\multirow{2}{*}{Label} & Availability & Labelled & {\color{red}Unlabelled} \\
\cline{2-4}{}  & Label space & Identical between two sets  & Identical between two sets \\ 
\cline{2-4}
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}
%\vspace{-1em}

\subsubsection{Statistic Criterion}
\paragraph{Hybrid Knowledge Transfer} 
\citeN{Chen2014a} assume the source datasets contain multiple modalities and target dataset only contains one modality. However, the target data are also available in the training stage. In addition, they assume the source and target data are from different distributions. Hence, the distribution mismatch also needs to be reduced. Both the feature representation and classifier parameters are transferred by employing both original and privileged knowledge in the source dataset. Specifically, they use the statistic criterion (MMD) to transform the source and target common modality into a shared subspace, in the meantime, the multiple source modalities are also transformed to the same representation in the common space. They iteratively learn the common space and the robust classifier based on the intuition that a suitable common space will be beneficial for learning a more robust classifier; and the robust classifier can also help finding a more discriminative common space. 
\subsubsection{Higher-level Representation Criterion}
\paragraph{Feature Representation Transfer}
Similar to~\cite{Chen2014a}, \citeN{Ding2014} also assume that the source domain contains data with multi-modality but the target domain only has one data modality. They name this setting as Missing Modality Problem. 
They propose to recover the missing modality in the target domain by finding similar data from the source domain. In their method, a latent factor is incorporated to uncover the missing modality based on the low-rank criterion.

Zero-padding has also been used for dealing with the heterogeneous feature spaces. For example, the marginalized SDA (mSDA)~\cite{Chen2012} deals with heterogeneous feature spaces by padding all input vectors with zeros to make both domains be of equal dimensionality.
\subsubsection{Correspondence Criterion}
\paragraph{Feature Representation Transfer}
The co-occurrence data between different feature spaces or modalities have been employed  for heterogeneous domain adaptation~\cite{Qi2011a,Yang2016}. In Qi's method~\cite{Qi2011a}, the co-occurrence data are used for mapping instances from different domains into a common space as a bridge to semantically connect the two heterogeneous spaces. Differently, \citeN{Yang2016} propose to learn the transferred weights obtained from co-occurrence data, which indicate the relatedness between heterogeneous domains. Specifically, they compute the principal components of instances in each feature space such that co-occurrence data can be represented by these principal components. By using these principal component coefficients, the Markov Chain Monte Carlo method is employed to construct a directed cyclic network where each node is a domain and each edge weight is the conditional dependence from one domain to another domain.

%, where the co-occurrence data are used for learning the feature-transformation between
%\citeN{Qi2011a} \citeN{Yang2016} 

A line of research dedicates on the task of translation between different domains. For example, in the context of machine translation between languages, the sentence pairs are presented in the form of a parallel training corpus for learning the translation system. Traditional phrase-based translation system~\cite{Koehn2003} consists of many small sub-components that are tuned separately. Differently, a newly emerging approach, named Neural machine translation~\cite{Kalchbrenner2013,Sutskever2014,Cho2014,Bahdanau2015}, attempts to build and train a single, large neural network that reads a sentence and outputs a correct translation. The neural machine translation approach typically consists of two components: the first encodes a source sentence, and the second decodes to a target sentence. 

Similarly, in the vision domain, image-to-image translation~\cite{Isola2017} has also been extensively exploited, which aims at converting an image from one representation of a given scene to another
(i.e. greyscale to color~\cite{Isola2017}, texture synthesis~\cite{Efros2001,Hertzmann2001,Li2016}, sketch to photograph~\cite{Chen2009a,Isola2017}, time hallucination~\cite{Shih2013,Laffont2014,Isola2017}, image to semantic labels~\cite{Long2015b,Eigen2015,Xie2015}, and style transfer~\cite{Li2016,Wang2016b,Gatys2016,Johnson2016,Zhang2016c}).
The key idea for tackling these tasks is to learn a translation model between paired samples from different domains. The recent deep learning based techniques have greatly advanced the image-to-image translation task. For example, the deep convolutional neural networks~\cite{Long2015b,Xie2015,Eigen2015,Gatys2016,Johnson2016,Zhang2016c}, and the Generative Adversarial Networks (GANs)~\cite{Wang2016b,Li2016,Isola2017} have been extensively exploited for learning the translation model. 

Though the original purposes of these work on translation between domains may not be cross-dataset recognition, the ideas can be borrowed for cross-modality or cross feature spaces recognition. Since if the source domain data can be translated to the target domain properly, the target task can be boosted by the translated source domain data.

%\citeN{Efros2001} address the image to image translation in the context of texture synthesis problem. They propose to synthesize new texture by taking patches of existing texture and stitching them together in a consistent way.
%
%\citeN{Hertzmann2001} describe a new framework for processing images by example, called ``image analogies''. By choosing different types of source image pairs as input, the framework supports a wide variety of ``image filter'' effects, including traditional image filters, such as blurring or embossing; improved texture synthesis, in which some textures are synthesized with higher quality than by previous approaches; super-resolution, in which a higher-resolution image is inferred from a low-resolution source; texture transfer, in which images are ``texturized'' with some arbitrary source texture; artistic filters, in which various drawing and painting styles are synthesized based on scanned real-world examples; and texture-by-numbers, in which realistic scenes, composed of a variety of textures, are created using a simple painting interface.
%
%\citeN{Chen2009a} present a system that composes a realistic picture from a simple freehand sketch annotated with text labels. Instead of pixel level image to image translation, the composed picture is generated by seamlessly stitching several photographs in agreement with the sketch and text labels; these are found by searching the Internet.
%
%\citeN{Shih2013} introduce ``time hallucination'': synthesizing a plausible image at a different time of day from an input image. They propose a locally affine model learned from a database of time-lapse videos of various scenes for the transfer.
%
%\citeN{Laffont2014} propose a ``transient attribute database'', which is used to train regressors that can predict the presence of attributes in novel images. Then a photo organization method is demonstrated based on predicted attributes. Finally a high-level image editing method is proposed, which allows a user to adjust the attributes of a scene.
%
%
%
%
%\citeN{Long2015b} propose using fully convolutional networks to learn dense predictions for semantic segmentation task.
%
%\citeN{Xie2015} propose a deep neural networks based method that learns hierarchical representations (guided by deep supervision on side responses) for edge and object boundary detection.
%
%\citeN{Eigen2015} propose a deep neural networks based method that progressively refines predictions using a sequence of scales, and captures many image details without any superpixels or low-level segmentation.
%
%\citeN{Wang2016b} propose Style and Structure Generative Adversarial Network (S2-GAN), where the Structure-GAN generates a surface normal map; the Style-GAN takes the surface normal map as input and generates the 2D image.
%
%\citeN{Gatys2016} propose to use generic feature representations learned by high-performing Convolutional Neural Networks to independently process and manipulate the content and the style of natural images.
%
%\citeN{Johnson2016} combine pixel level loss and perceptual loss for training feed-forward networks for image transformation tasks.
%
%\citeN{Zhang2016c} attack the problem of hallucinating a plausible color version of the photograph. The system is implemented as a feed-forward pass in a CNN at test time and is trained on over a million color images.
%
%
%
%\citeN{Li2016} propose Markovian Generative Adversarial Networks (MGANs), a method for training generative neural networks for efficient texture synthesis. 
%
%\citeN{Isola2017} propose an image-to-image translation framework, where the paired images from different modalities are presented for translating between them using conditional GAN.
%%\citeN{Isola2017} 
%%%define automatic image-to-image translation as the problem of translating one possible representation of a scene into another, given sufficient training data. They 
%%propose a common framework for above mentioned image-to-image translation tasks.

%\paragraph{Hybrid Knowledge Transfer} 
\citeN{Gupta2016} assume that the source data are large scale labelled RGB data and the target data are unlabelled RGB and depth image pairs. The source data are used for training multiple layers of rich representations using deep convolutional neural networks. Then the paired target data are used for transfer the source rich parameters to the target networks by constraining the paired samples from different modalities to have similar representations.

%propose to transfer supervision from labelled RGB images to unlabelled depth and optical flow images. They use ``paired'' images from the two modalities (RGB-D) and utilizes the mid-level representations from the labelled modality (RGB) to supervise learning representations on the paired unlabelled modality. 
\subsubsection{Self Labelling}
\paragraph{Instance-based Transfer}
\citeN{Tang2012} propose a self-paced method for adapting object detectors from image to video, hence the data modalities between domains are completely different. They iteratively adapt the detector by automatically discovering examples from target video data, starting from the most confident ones. In each iteration, the number of target examples is increased while the source examples are decreased.

\section{Heterogeneous Label Spaces}
\label{sec:HETEL}
In this section, we discuss a set of problems that assume different label spaces $\mathcal{Y}$ but same feature spaces $\mathcal{X}$ between source and target datasets. For example, in the classification tasks, when the label spaces between datasets are different, there still exists shared knowledge between previous categories (i.e. horse) and new categories (i.e. zebra) that can be used for learning new categories.

\subsection{Labelled Target Dataset}
\label{sec:HETELsup}
When limited labelled data (maybe only one example per category) are presented in the target dataset, the problem is generally named \textit{one-shot learning} or \textit{few-shot learning}. The characteristics of this problem are shown in Table~\ref{tab:HETELsup}. This setting is closely related to multi-task learning. The difference is that one-shot learning emphasize on the recognition on the target data with limited labelled data while multi-task learning aims at improving all the tasks with good training data in each task.
\begin{table}[htbp!]
\caption{Characteristics of problem~\ref{sec:HETELsup}}
\label{tab:HETELsup}
\begin{center}
\begin{small}
\begin{tabular}{|p{1cm}<{\centering}|m{2.5cm}<{\centering}|m{4.3cm}<{\centering}|m{4.3cm}<{\centering}|}
\hline
\multicolumn{2}{|c|}{Attributes} & Source dataset & Target data \\
\hline \hline
\multirow{3}{*}{Data} & Feature space & Identical between two sets & Identical between two sets \\ 
\cline{2-4}{} & Availability & Sufficient & {\color{red}Insufficient} \\
\cline{2-4}{} & Balanced & Yes & Yes\\
\cline{2-4}{} & Sequential & No & No \\
\hline \hline
\multirow{2}{*}{Label} & Availability & Labelled & Labelled \\
\cline{2-4}{}  & Label space & Different from target & {\color{red}Different from source} \\ 
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}
%\vspace{-1em}
\subsubsection{Statistic Criterion}
\paragraph{Feature Representation-based Transfer}
\citeN{Bian2012} propose a transfer topic model (TTM) by assuming the source and target datasets can be represented by shared concepts even with different classes. Since the target labelled data are insufficient, they propose use the topics learned from the source domain to regularize the topic estimation in the target domain. Kullback Leibler divergences are used as regularization to reduce the shift between topic pairs of the two domains.
\subsubsection{Higher-level Representation Criterion}
\paragraph{Feature Representation-based Transfer} 
\citeN{Yang2009,Yang2009a} propose to transfer the parameters of distance function from source data to the target. The distance function can help to detect the patch saliency in the target videos.  

\subsubsection{Class-based Criterion}
\paragraph{Instance-based Transfer}
\citeN{Qi2011} develop a cross-category label propagation algorithm, which directly propagate the inter-category knowledge at instance level between the source and the target categories. %to use cross-category knowledge for improving the learning process by exploring the knowledge in correlated categories.
\paragraph{Feature Representation-based Transfer}
\citeN{Patricia2014} consider each source as an expert that judges on the new target samples. The output confidence value of prior models is treated as features and the features are combined with the features from the target samples to build a target classifier.

\paragraph{Classifier-based Transfer}
Several classifier-based methods are proposed to transfer the parameters of classifiers. \citeN{Fei-Fei2006} propose a Bayesian approach, where a generic object model is estimated from some source categories and it is then used as prior to evaluate the target object parameter distribution with a maximum-a-posteriori technique. \citeN{Lake2011} introduce a generative model of how characters are composed from strokes, where knowledge from previous characters helps to infer the latent strokes in novel characters.

Instead of using generative model, some discriminative classifier-based transfer methods~\cite{Tommasi2010,Aytar2011,Ma2014,Jie2011} are also proposed to incorporate prior knowledge. For example, \citeN{Tommasi2010} present an Least Square Support Vector Machine (LS-SVM) based model adaptation algorithm able to select and weight appropriately prior knowledge coming from different categories by assuming the new categories are similar to some of the ``prior'' categories. Similarly, \citeN{Aytar2011} propose three transfer learning formulations, namely Adaptive SVM(A-SVM), Projective Model Transfer SVM (PMT-SVM), Deformable Adaptive SVM (DA-SVM), where a template learnt previously for other categories is used to regularize the training of a new category. They also assume the target category is visually similar to a source category.
\citeN{Ma2014} design a multi-task learning framework to explore the shared knowledge between source and target classifiers and jointly optimize the classifiers for both sides. %Multiple kernel learning frameworks are also used for this problem. 
\citeN{Jie2011} propose Multi Kernel Transfer Learning (MKTL) method, which takes advantages of priors built over different features and with different learning methods. They use the priors as experts and transfer their outputs to the target using multiple kernel learning (MKL). The intuition is that knowledge can be transferred between classes that share common visual properties, such as bicycle and motorbike.

\citeN{Kuzborskij2013} conduct a theoretical analysis (with the focus of algorithmic stability) of the discriminative classifier-based transfer methods~\cite{Tommasi2010,Aytar2011,Ma2014,Jie2011}, which is named as Hypothesis Transfer Learning (HTL) in their paper. In HTL, only source hypotheses trained on a source domain are utilized for transferring the parameters to the target domain with the presence of a small set of target labelled data. They give the generalization bound in terms of the Leave-One-Out (LOO) risk and show that the relatedness of source and target domains accelerates the convergence of the LOO error and generalization error. In the case of unrelated domains, they propose how a hypothetical algorithm could avoid negative transfer.

Recently, the deep learning based approaches have been emerged for few-shot learning. %focuses on the embedding of unseen target categories for few-shot learning.
%One early neural network approach to one-shot learning was given by Siamese networks~\cite{Koch2015}, which learn generic image features that does not rely upon domain-specific knowledge
% employ a unique structure to naturally rank similarity between inputs.
\citeN{Vinyals2016} propose the matching networks, which uses an attention mechanism over a learned embedding of the limited labelled data of target classes, which can be interpreted as a weighted nearest-neighbor classifier applied within an embedding space. 
%Specifically, this model utilizes sampled mini-batches called episodes during training, where each episode is designed to mimic the few-shot task by subsampling classes as well as data points. 
\citeN{Ravi2017} 
%take the episodic training idea further and 
propose a meta-learning approach to few-shot learning. Their approach involves training an LSTM~\cite{Hochreiter1997} to produce the updates to a classifier, given a few target labelled examples, such that it will generalize well to the target set. \citeN{Snell2017} propose the prototypical networks by learning a non-linear mapping of the input into an embedding space using a neural network and take a class's prototype to be the mean of its support set in the embedding space. 
%each class comes with meta-data giving a high-level description of the class rather than a small number of labelled examples.
%Classification is then performed for an embedded query point by simply finding the nearest class prototype.
%based on the idea that there exists an embedding in which points cluster around a single prototype representation for each class

\subsection{Unlabelled Target Dataset}
\label{sec:HETELunsup}
Some research also try to tackle the heterogeneous label space problem by assuming that no labelled data are presented. This problem can be named as \textit{unsupervised transfer learning}.
\begin{table}[htbp!]
\caption{Characteristics of problem~\ref{sec:HETELunsup}}
\label{tab:HETELunsup}
\begin{center}
\begin{small}
\begin{tabular}{|p{1cm}<{\centering}|m{2.5cm}<{\centering}|m{4.3cm}<{\centering}|m{4.3cm}<{\centering}|}
\hline
\multicolumn{2}{|c|}{Attributes} & Source dataset & Target data \\
\hline \hline
\multirow{3}{*}{Data} & Feature space & Identical between two sets & Identical between two sets \\ 
\cline{2-4}{} & Availability & Sufficient & Sufficient \\
\cline{2-4}{} & Balanced & Yes & Yes \\
\cline{2-4}{} & Sequential & No & No \\
\hline \hline
\multirow{2}{*}{Label} & Availability & Labelled & {\color{red}Unlabelled} \\
\cline{2-4}{}  & Label space & Different from target & {\color{red}Different from source} \\ 
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}
%\vspace{-1em}
\subsubsection{Higher-level Representation Criterion}
\paragraph{Feature Representation-based Transfer} 
The higher-level representation criterion is generally used for this problem. Two different scenarios are considered among the literature. 

The first scenario is that only the label spaces between source and target datasets are different. Since there are no labels in the target training set, the unseen class information is generally gained from a higher level semantic space shared between datasets. Some research uses Web search the semantic representation linking the different label spaces~\cite{Zheng2009,Hu2011}. For example, \citeN{Zheng2009} assume that there is no labels in the target data, but the number of activities and names of activities are known and the source activities and the target activities have some kind of relationship. They bridge between the activities in two domains by learning a similarity function in the text feature space (word vectors) via Web search. Then they train a weighted SVM model with different probabilistic confidence weights learned from the similarity function. Some other research assumes the shared human-specified high-level semantic space (i.e. attributes~\cite{Palatucci2009}, or text descriptions~\cite{Reed2016}) between datasets. Given a defined attribute or text description ontology, each class can be represented by a vector in the semantic space. However, the attribute annotations or text descriptions are expansive to acquire. The attributes are substituted by the visual similarity and data distribution information in transductive settings~\cite{Li2015,Zhang2015,Zhang2016a,Zhang2016b}, where the target domain data of unseen classes are required in the training stage to learn the model. Another strategy learns the semantic space by borrowing the large and unrestricted, but freely available, text corpora (i.e. Wikipedia) to derive a word vector space~\cite{Frome2013,Mikolov2013,Socher2013}. The related work on semantic space (i.e. attributes, text descriptions, or word vector) will be further discussed in Section~\ref{sec:HETELzero}, since the target data are generally not required when the semantic space is involved. 

The second scenario assumes that in addition to the different label spaces, the domain shift (i.e. the distribution shift of features) also exists between datasets~\cite{Fu2015,Kodirov2015,Wang2016a}. For example, \citeN{Fu2015} name this problem as projection domain shift and propose a transductive multi-view embedding space that rectifies the projection shift. \citeN{Kodirov2015} propose a regularised sparse coding framework which uses the target domain class labels' projections in the semantic space to regularise the learned target domain projection thus overcoming the projection domain shift problem. 

\subsection{Sequential Labelled Target Data}
\label{sec:HETElseq}
%In video analysis, detection is as crucial as recognition. 
As mentioned, the target domain data can come sequentially. 
%In real world applications, the new data can be from different unseen classes. 
Hence, this problem assume the target data are sequential and can be from different classes, which is also called \textit{online transfer learning}, and closely related to \textit{lifelong learning}. Both concepts focus on the continuous learning processes for evolving tasks. However, the online transfer learning emphasize on the performance on the target data (without sufficient target training data), but lifelong learning tries to improve the future target task (with sufficient target training data) as well as all the past tasks~\cite{Chen2015c}. Also, the lifelong learning can be seen as incremental/online multi-task learning.
\begin{table}[htbp!]
\caption{Characteristics of problem~\ref{sec:HETElseq}}
\label{tab:HETElseq}
\begin{center}
\begin{small}
\begin{tabular}{|p{1cm}<{\centering}|m{2.5cm}<{\centering}|m{4.3cm}<{\centering}|m{4.3cm}<{\centering}|}
\hline
\multicolumn{2}{|c|}{Attributes} & Source dataset & Target data \\
\hline \hline
\multirow{3}{*}{Data} & Feature space & Identical between two sets & Identical between two sets \\ 
\cline{2-4}{} & Availability & Sufficient & {\color{red}Insufficient} \\
\cline{2-4}{} & Balanced & Yes & Yes \\
\cline{2-4}{} & Sequential & No & {\color{red}Yes}  \\
\hline \hline
\multirow{2}{*}{Label} & Availability & Labelled & Labelled \\
\cline{2-4}{}  & Label space & Different from target & {\color{red}Different from source} \\ 
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}
%\vspace{-1em}
\subsubsection{Self Labelling}
%\subsubsection{Class-based Criterion}
\paragraph{Classifier-based Transfer}
%The class-based criterion is the most commonly used for this problem. 
\citeN{Nater2011} address an action recognition scenario where the unseen activities to be recognized only have one labelled sample per new activity, with the help of other offline trained activities with many labelled data. They build a multiclass model which exploits prior knowledge of known classes and incrementally learns the new actions. Then the newly labelled activities are integrated in the previous model to update the activity model. \citeN{Zhao2010} propose an ensemble learning based method (OTL) that learns a classifier in an online fashion with data from the target domain, and combines it with the source domain classifier. The weights for the combination are adjusted dynamically on the basis of a loss function which evaluates the difference among the current prediction and the correct label of new incoming sample. \citeN{Tommasi2012} then extended OTL~\cite{Zhao2010} and addressed the case of online transfer from multiple sources. 

\subsection{Unavailable Target Data}
\label{sec:HETELzero}
This problem is also named \textit{zero-shot learning} among the literature, where unseen categories are required to be recognized in the target set but no training data is available for the unseen categories. Different from \textit{domain generalization} (see Section~\ref{sec:HOMOgene}), the unseen target data are from different categories as the source data in \textit{zero-shot learning}. 
%This problem is ubiquitous, since it is difficult to obtain sufficient numbers of training images for rare concepts. 
As mentioned in Section~\ref{sec:HETELunsup}, the unseen categories can be connected via some auxiliary information, such as a common semantic representation space. 
\begin{table}[htbp!]
\caption{Characteristics of problem~\ref{sec:HETELzero}}
\label{tab:HETELzero}
\begin{center}
\begin{small}
\begin{tabular}{|p{1cm}<{\centering}|m{2.5cm}<{\centering}|m{4.3cm}<{\centering}|m{4.3cm}<{\centering}|}
\hline
\multicolumn{2}{|c|}{Attributes} & Source dataset & Target data \\
\hline \hline
\multirow{3}{*}{Data} & Feature space & Identical between two sets & Identical between two sets \\ 
\cline{2-4}{} & Availability & Sufficient & {\color{red} No} \\
\cline{2-4}{} & Balanced & Yes & - \\
\cline{2-4}{} & Sequential & No & No \\
\hline \hline
\multirow{2}{*}{Label} & Availability & Labelled & -\\
\cline{2-4}{}  & Label space & Different from target & {\color{red}Different from source} \\ 
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}
%\vspace{-1em}
\subsubsection{Higher-level Representation Criterion}
\paragraph{Feature Representation-based Transfer}
Most of the methods for this problem rely on the existence of a labelled training set of seen classes and the knowledge about how each unseen class is semantically related to the seen classes. Seen and unseen classes are usually related in a high dimensional vector space, which is called semantic space. Such a space can be an attribute space~\cite{Palatucci2009}, text description space~\cite{Reed2016}, or a word vector space~\cite{Frome2013,Mikolov2013,Socher2013}. 

The attribute space is the most commonly used intermediate semantic space. The attributes are defined as properties observable in images, which are described with human-designated names such as ``white'', ``hairy'', ``four-legged''. Hence, in addition to label annotation, the attribute annotations are required for each class. However, the attributes are assigned on a per-class basis instead of a per-image basis, the manual effort to add a new object class is kept minimal. This motivated the collection of datasets containing images annotated with visual attributes~\cite{Farhadi2009,Lampert2009}. 
Two main strategies are proposed for recognizing unseen object categories using attributes. The first is recognition using independent attributes, consists of learning an independent classifier per attribute~\cite{Lampert2009,Palatucci2009,Kumar2009,Liu2011,Parikh2011}.  At test time, the independent classifiers allow the prediction of attribute values for each test sample, from which the test class label are inferred.
Since attribute detectors are expected to generalize well across different categories, including those previously unseen, some research is devoted to modelling the uncertainty of attributes~\cite{Wang2013b,Jayaraman2014} or robustly detecting attributes from images~\cite{Gan2016,Bucher2016}. 
However, \citeN{Akata2013} argue that the attribute classifiers in previous work are learned independently of the end-task, they might be optimal at predicting attributes but not necessarily at predicting classes. Hence, the second strategy is recognition by assuming a fixed transformation between the attributes and the class labels~\cite{Akata2015,Romera-Paredes2015a,Akata2016,Qiao2016,Xian2016} to learn all attributes simultaneously. To sum up, the attribute based methods are promising for recognizing unseen classes, while with a key drawback that the attribute annotations are still required for each class.

Instead of using attributes, \citeN{Reed2016} use image text descriptions to construct the semantic space to provide a natural language interface. However, similar to attribute space, the good performance is obtained at the price of manual annotation.

The third semantic space is the word vector space~\cite{Frome2013,Mikolov2013,Socher2013,LeiBa2015}, which is attractive since no extensive annotations are required for the semantic space. The word vector space is derived from both labelled images and a huge unannotated text corpus (i.e. Wikipedia) and generally learnt by deep neural network.

\subsection{Unlabelled Source Dataset}
\label{sec:HETELself}

This problem is similar to \textit{self-taught learning}, where the source data are unlabelled but contain information (i.e. basic visual patterns) that can be used for target tasks. 
\begin{table}[htbp!]
\caption{Characteristics of problem~\ref{sec:HETELself}}
\label{tab:HETELself}
\begin{center}
\begin{small}
\begin{tabular}{|p{1cm}<{\centering}|m{2.5cm}<{\centering}|m{4.3cm}<{\centering}|m{4.3cm}<{\centering}|}
\hline
\multicolumn{2}{|c|}{Attributes} & Source dataset & Target data \\
\hline \hline
\multirow{3}{*}{Data} & Feature space & Identical between two sets & Identical between two sets \\ 
\cline{2-4}{} & Availability & Sufficient & {Insufficient} \\
\cline{2-4}{} & Balanced & Yes & Yes \\
\cline{2-4}{} & Sequential & No & No \\
\hline \hline
\multirow{2}{*}{Label} & Availability & {\color{red}Unlabelled} & Labelled \\
\cline{2-4}{}  & Label space & Different from target & {\color{red}Different from source}  \\ 
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}
%\vspace{-1em}
\subsubsection{Higher-level Representation Criterion}
\paragraph{Feature Representation-based Transfer}
\label{sec:selftaught}
\citeN{Raina2007} firstly presented the idea of ``self-taught learning''. They propose to construct higher-level features using sparse coding with the unlabelled source data. Recently, \citeN{Kumagai2016} provides a theoretical learning bound for self-taught learning with focus on discussing the performance of sparse coding in self-taught learning. 

The idea of self-taught learning has also been used in deep learning framework, where the unlabelled data are used for pretraining the network to obtain good starting point of parameters~\cite{Le2011,Gan2014,Kuen2015}. For instance, \citeN{Le2011} propose a self-taught learning framework based on a deep Independent Subspace Analysis (ISA) network. They train the network on video blocks from UCF and Youtube datasets and use the learned model to extract features and recognize actions on Hollywood2 video clips. \citeN{Gan2014} use the unlabelled samples to pretrain the first layer of Convolutional deep belief network (CDBN) for initializing the network parameters. \citeN{Kuen2015} use stacked convolutional autoencoders to learn the invariant representations from previous unlabelled image patches for visual tracking. 

\section{Heterogeneous Feature Spaces and Label Spaces}
\label{sec:HETEFL}
This section, a more challenging scenario is discussed, where both the feature spaces $\mathcal{X}$ and label feature spaces $\mathcal{Y}$ between source and target datasets are different.

\subsection{Labelled Target Dataset}
\label{sec:HETEFLsup}
This problem assumes the labelled target data are available. We name this problem as \textit{heterogeneous supervised transfer learning}.
\begin{table}[htbp!]
\caption{Characteristics of problem~\ref{sec:HETEFLsup}}
\label{tab:HETEFLsup}
\begin{center}
\begin{small}
\begin{tabular}{|p{1cm}<{\centering}|m{2.5cm}<{\centering}|m{4.3cm}<{\centering}|m{4.3cm}<{\centering}|}
\hline
\multicolumn{2}{|c|}{Attributes} & Source dataset & Target data \\
\hline \hline
\multirow{3}{*}{Data} & Feature space & Different from target & {\color{red}Different from source} \\ 
\cline{2-4}{} & Availability & Sufficient & {\color{red}Insufficient} \\
\cline{2-4}{} & Balanced & Yes & Yes \\
\cline{2-4}{} & Sequential & No & No \\
\hline \hline
\multirow{2}{*}{Label} & Availability & Labelled & Labelled \\
\cline{2-4}{}  & Label space & Different from target & {\color{red}Different from source} \\ 
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}
%\vspace{-1em}

\subsubsection{Higher-level Representation Criterion}
\paragraph{Feature Representation-based Transfer}
Rather than assuming completely different feature spaces, \citeN{Jia2014} propose to transfer the knowledge of RGB-D (RGB and depth) data to the dataset that only has RGB data, and use this additional source of information to recognize human actions from RGB videos. They applied latent low-rank tensor transfer learning to learn shared subspaces of two databases. Specifically, each action sample is represented as a three-order tensor (row dimensions, column dimensions, and number of frames) and the subspace is learned by imposing the low-rank constraints on each mode of the tensor, such that more spatial-temporal information are uncovered from the action videos. 

\subsubsection{Hybrid Criterion}
\paragraph{Hybrid knowledge transfer}
\citeN{Hu2011} propose to transfer the knowledge between different activity recognition tasks, relaxing the assumption of same feature space, same label space as well as same underlying distribution by automatically learning a mapping between different sensors. They adopt similar idea of translated learning~\cite{Dai2008} to find a translator between different feature spaces using statistic criterion (i.e. Jensen-Shannon divergence). Then the Web knowledge is used as a bridge to link the different label spaces using self labelling. 


\subsection{Sequential Labelled Target Data}
\label{sec:HETEFlseq}
%In video analysis, detection is as crucial as recognition. 
This problem (Table~\ref{tab:HETEFlseq}) assume the sequential target data have different feature space with source data, which is named as \textit{heterogeneous online supervised transfer learning}.
\begin{table}[htbp!]
\caption{Characteristics of problem~\ref{sec:HETEFlseq}}
\label{tab:HETEFlseq}
\begin{center}
\begin{small}
\begin{tabular}{|p{1cm}<{\centering}|m{2.5cm}<{\centering}|m{4.3cm}<{\centering}|m{4.3cm}<{\centering}|}
\hline
\multicolumn{2}{|c|}{Attributes} & Source dataset & Target data \\
\hline \hline
\multirow{3}{*}{Data} & Feature space & Different from target & {\color{red}Different from source} \\ 
\cline{2-4}{} & Availability & Sufficient & {\color{red}Insufficient} \\
\cline{2-4}{} & Balanced & Yes & Yes \\
\cline{2-4}{} & Sequential & No & {\color{red}Yes} \\
\hline \hline
\multirow{2}{*}{Label} & Availability & Labelled & Labelled \\
\cline{2-4}{}  & Label space & Different from target & {\color{red}Different from source} \\ 
\hline
\end{tabular}
\end{small}
\end{center}
\end{table}
%\vspace{-1em}
%\subsubsection{Class-based Criterion}
\subsubsection{Self Labelling}
\paragraph{Classifier-based Transfer} As mentioned in Section~\ref{sec:HETElseq}, \citeN{Zhao2010} propose the OTL method for online transfer learning. They also consider the case of heterogeneous feature spaces by assuming the feature space of the source domain is a subset of that of the target domain. Then a multi-view approach is proposed by adopting a co-regularization principle of online learning of two target classifiers simultaneously from the two views. The unseen target example is classified by the combination of the two target classifiers.

\section{Applications and Datasets}
\label{sec:App}
The cross-dataset transfer learning are crucial for different real world applications, including WiFi localization, sentiment classification, Part-of-speech tagging, spam email filtering, text classification, object recognition, Hand-Written digit recognition, face recognition, person re-identification, scene categorization, action recognition, and video event detection. We take the object recognition as an example for explanation. As claimed by~\citeN{Torralba2011}, despite the great efforts of object datasets creators, the datasets appear to have strong build-in bias caused by various factors, such as selection bias, capture bias, category or label bias, and negative set bias. This suggests that no matter how big the dataset is, it is impossible to cover the complexity of the real visual world. Similarly, datasets for other tasks also have biases caused by different factors. Hence, to make good use of the big data available on the internet, cross-dataset transfer learning is crucial for solving the current tasks effectively and efficiently. Below, we summarise a set of real world cross-dataset transfer learning applications and provide the information of commonly used datasets for evaluating the performance.
\subsection{WiFi Localization}
The indoor WiFi localization~\cite{Yang2008} aims at estimating the location of a mobile device based on the received signal strength (RSS) from a set of access points that periodically send out wireless signals to others. The WiFi signal strength may be a function of many dynamic factors, such as time, device, and space. Hence, to estimate data of different time period, transfer learning is required. The WiFi dataset\footnote{\url{http://www.cs.ust.hk/~qyang/ICDMDMC07/}} is also publicly available. 
\subsection{Sentiment Classification}
The objective of automatic sentiment classification is to judge the overall opinion of a product, i.e. whether a product review is positive or negative. However, sentiment is expressed differently in different domains~\cite{Blitzer2007}. Hence, a multi-domain sentiment dataset\footnote{\url{https://www.cs.jhu.edu/~mdredze/datasets/sentiment/}} was created..

\citeN{Prettenhofer2010} extend the Multi-Domain Sentiment Dataset~\cite{Blitzer2007} to a Cross-Lingual Sentiment (CLS) dataset\footnote{\url{http://www.webis.de/research/corpora/corpus-webis-cls-10/cls-acl10-processed.tar.gz}}. The CLS dataset consists of Amazon product reviews of three product categories: books, DVDs and music, with more than 4 million reviews in the three languages German, French, and Japanese.
\subsection{Part-of-speech Tagging}
Part-of-speech (PoS) tagging is one of the important natural language processing (NLP) task, which aims at labelling a word context with its grammatical function. However, different domains use very different vocabularies. Hence, to transfer PoS tagger from one domain to another is crucial to reduce the efforts of creating training corpora for each domain.
\citeN{Blitzer2006} propose to use sentences from Wall Street Journal (WSJ) \footnote{\url{http://www.cis.upenn.edu/~treebank/home.html}} as source domain data, and sentences from Biomedical Text \footnote{\url{http://languagelog.ldc.upenn.edu/myl/ldc/ITR/}} as target domain data.
\subsection{Spam Email Filtering}
The ECML/PKDD 2006 Challenge focuses on the personalized spam filtering tasks. It aims at building a spam filter for automatically detecting spam emails. Training such filters rely on publicly available sources. However, the spam emails are person specific, suggesting that the distributions of the combined source of training data are different from that of emails received by individual users. In this challenge, a spam email filtering dataset was provided\footnote{\url{http://www.ecmlpkdd2006.org/challenge.html}}.

Another cross domain spam email dataset was created by \citeN{Bickel2006}, which is built upon Enron Corpus\footnote{\url{https://www.cs.cmu.edu/~./enron/}}~\cite{Klimt2004}. The dataset contains nine different inboxes with test emails (5270 to 10964 emails, depending on inbox) and one set of training emails collected from various different sources.
\subsection{Text Classification}
\citeN{Lang1995} create the 20 Newsgroups data set\footnote{\url{http://qwone.com/~jason/20Newsgroups/}} for the task of cross domain text classification algorithms, which contains 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups corresponding to different topics. The goal is to distinguish documents from newsgroup categories, such as between rec and talk.
 
\subsection{Object Recognition}
\citeN{Saenko2010} create the Office dataset\footnote{\url{https://cs.stanford.edu/~jhoffman/domainadapt/}} for evaluating the effects of domain shift. Three datasets representing three domains are involved in the Office dataset, which are: Amazon (images downloaded from online merchants), Webcam (low-resolution images by a web camera), DSLR (high-resolution images by a digital SLR camera). Thirty one object categories are contained in the three datasets.
 
\citeN{Gong2012} combine the Caltech-256~\cite{Griffin2007} dataset with the Office dataset~\cite{Saenko2010}, constituting Office+Caltech object dataset\footnote{\url{http://www-scf.usc.edu/~boqinggo/domainadaptation.html}}. The Caltech-256 dataset contains 256 object classes downloaded from Google images. Ten classes shared by four datasets are generally selected for the cross dataset object recognition task.

Another object dataset\footnote{\url{https://sites.google.com/site/crossdataset/home}} for cross-dataset analysis is proposed by \citeN{Tommasi2014a}. The dataset has two settings: one dense contains 40 classes shared by four datasets (Caltech 256, Bing, Imagenet and SUN), and one sparse contains 105 classes shared by at least four out of twelve datasets (RGB-D, a-Yahoo, ETH80, MSRCORID, PascalVOC07, AwA, Office, Caltech101, SUN, Imagenet, Bing, Caltech256). 

\subsection{Hand-Written Digit Recognition}
For cross-domain hand-written digit recognition task, the combinations of different digit datasets ( i.e. MNIST~\cite{LeCun1998} and USPS~\cite{Hull1994}, SVHN~\cite{Netzer2011} ) are used. MNIST dataset\footnote{\url{http://yann.lecun.com/exdb/mnist/}} contains a training set of 60,000 examples, and a test set of 10,000 examples of size 28$\times$28. USPS dataset\footnote{\url{http://statweb.stanford.edu/~tibs/ElemStatLearn/data.html}} consists of 7,291 training images and 2,007 test images of size 16$\times$16. SVHN dataset\footnote{\url{http://ufldl.stanford.edu/housenumbers/}} was obtained from a large number of Street View images, which comprises over 600,000 labelled characters.

\subsection{face recognition}
The dataset shift in face recognition can be caused by poses, resolution, illuminations, expressions, and modality. For example, MultiPIE dataset\footnote{\url{http://www.flintbox.com/public/project/4742/}}~\cite{Gross2010} contains face images under various poses, illuminations and expressions. The face images under one pose can be used as the source dataset while the images under another pose can be used as the target dataset. Similarly, the illuminations and expressions can also cause the distribution shift, and can be used for evaluating cross-domain performance. Some face datasets also contain face images captured by different sensors, resulting in multiple data modalities. For instance, the Oulu-CASIA NIR\&VIS facial expression database\footnote{\url{http://www.ee.oulu.fi/~gyzhao/}} and the BUAA-VisNir Face Database\footnote{\url{http://irip.buaa.edu.cn/Research/Research_Highlights.htm}} contain face images captured by both NIR (Near Infrared) and VIS (Visible light). There are also datasets provide the sketch of human faces, such as Face Sketch Database (CUFS)\footnote{\url{http://mmlab.ie.cuhk.edu.hk/archive/facesketch.html}}. The recognition across photo and sketch has also been addressed~\cite{Wang2012b}, which has the potential application of law enforcement. For example, it is often required to compare the face photos to a sketch drawn by an artist based on the verbal description of the suspect.
\subsection{Person Re-identification}
Person re-identification is also an important real world application in cross-domain transfer learning. Several commonly used datasets are also available, such as VIPeR dataset\footnote{\url{https://www.researchgate.net/publication/261596035_Viewpoint_Invariant_Pedestrian_Recognition_VIPeR_Dataset_v10}} ,CUHK Person Re-identification dataset\footnote{\url{http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html}}, and PRID dataset\footnote{\url{https://lrs.icg.tugraz.at/datasets/prid/}}. The persons in these datasets are all captured from different viewpoints.
\subsection{Scene Categorization}
The cross-dataset transfer learning is also used for cross-task scene categorization, which means that the knowledge learnt from previous scene categories can be used for new categories. The Flickr scene image data set\footnote{\url{http://lms.comp.nus.edu.sg/research/NUS-WIDE.htm}} contains 33 scene categories and 34,926 images in total. SUN-397 database\footnote{\url{http://groups.csail.mit.edu/vision/SUN/}} is a very big scene recognition dataset, which contains 397 scene categories. There are also scene datasets that provide the attribute, such as SUN Attribute Database\footnote{\url{https://cs.brown.edu/~gen/sunattributes.html}} which provides 102 discriminative attributes and covers more than 700 scene categories.
\subsection{Action Recognition}
The cross-dataset video-based action recognition has also been addressed. For example, \citeN{Zhu2014b} conduct action recognition across the UCF YouTube dataset\footnote{\url{http://crcv.ucf.edu/data/UCF_YouTube_Action.php}\label{note1}} and HMDB51 dataset\footnote{\url{http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/}}. The shared actions between datasets are selected. Another line of research transfers across action datasets with different label spaces. For example, \citeN{Ma2014} use the laboratory collected datasets (KTH\footnote{http://www.nada.kth.se/cvap/actions/}, HumanEva\footnote{http://humaneva.is.tue.mpg.de/}) as source domain, while the real-world action datasets such as UCF YouTube dataset\footref{note1}, CareMedia dataset\footnote{\url{http://www.informedia.cs.cmu.edu/caremedia/index.html}}, and Kinect Skeleton Action (KSA) are used for target data. 

Another scenario of transfer of actions is cross-view action recognition. The most commonly used multi-view action dataset is IXMAS dataset\footnote{\url{http://4drepository.inrialpes.fr/public/viewgroup/6}}, where actions are captured from different views. Recently, some RGB-D based multi-view action datasets (Northwestern-UCLA Multiview Action3D (N-UCLA)\footnote{\url{http://users.eecs.northwestern.edu/~jwa368/my_data.html}}, ACT$4^2$ dataset\footnote{http://www.datatang.com/data/45062}, and Multi-View TJU Dataset\footnote{\url{http://media.tju.edu.cn/mv_tju_dataset.html}}) are also emerged after the release of Kinect sensors. 
\subsection{Video Event Detection}
Video event detection or video concept detection is to automatically classify video shots into certain semantic event (such as making a cake, wedding ceremony, and changing a vehicle tire) or concept (such as meeting, sports, and entertainment). We discuss the two tasks together, because they are both to extract semantic meaning from a video clip. Most commonly used data for evaluating video event detection are from TREC VideoRetrieval Evaluation (TRECVID) dataset series\footnote{\url{http://www-nlpir.nist.gov/projects/trecvid/}}. The transfer learning is used for cross-task video event detection by previous research. For example, the TRECVID 2005 dataset is used by \citeN{Yang2007}, where one of the 39 concepts is picked as the target concept and one of the 13 programs is the target program. Differently, the TRECVID 2010 and TRECVID 2011 are used together by \citeN{Ma2012} for the cross-domain event detection, where the TRECVID 2011 semantic indexing task (SIN11) is used as the source auxiliary dataset.


\section{Conclusion and Discussion}
\label{sec:Conc}
Learning from previous knowledge for current tasks is crucial for real world applications by taking full advantage of the big data available on the internet. According to the properties of previously available data and current data in a real world scenario or application, completely different techniques would be carefully chosen for boosting current task.
% and avoiding ``negative transfer''. 
This paper presents a comprehensive overview of recent advances by defining a taxonomy of scenarios and problems according to dataset characteristics.  Though it is impossible for this survey to cover all the related papers, the selected representative works can discover the recent advances as well as the emphasis has been put on to date.

In general, most of current methods adopt some transferring criteria to use previous related data for the target task. As mentioned in Section~\ref{sec:criteria}, different criteria can be used with different assumptions of data. Some of the existing methods use one criterion and others may use two or more criteria. Carefully choosing criteria is crucial for better transfer performance. The future work is encouraged to refer to the defined criteria for transferring knowledge according to the properties of available data. In addition, transferring using multiple criteria is also encouraged to guide the transfer process for better performance.

From the perspective of scenarios and problems, it can be seen from Figure~\ref{tab:tax} that most of the previous work focused on the first scenario (\textit{homogeneous feature spaces and label spaces}) with seven sub-problems, while the last scenario (\textit{heterogeneous feature spaces and label spaces}) is the least addressed, with only two sub-problems. Below, we will discuss on each sub-problem and identify some future directions based on the problems under different scenario.

Firstly, the supervised cases, i.e. supervised domain adaptation and supervised transfer learning, have been employed in all scenarios, where the labelled data in target dataset are available. This is because the supervised cases are considered the most easy to solve with the guidance of target labels. 

Secondly, the semi-supervised cases only appear in the first two scenarios, namely \textit{homogeneous feature spaces and label spaces} and \textit{heterogeneous feature space}. Hence, a natural future direction is the development of semi-supervised methods on the rest two scenarios with the help of unlabelled target samples in addition to limited labelled target samples. 

Thirdly, the unsupervised cases have been researched in the first three scenarios. This may be because the last scenario is more challenging compared to other three scenarios. However, in the real world applications, the available source data that are used for target data are generally presented in various forms and may focus on different tasks, and the target labelled data are much harder to obtain than unlabelled data. Hence, the future methods that transfer from unconstrained source data to unlabelled target data are encouraged. 

Fourthly, the issue of data imbalance in the target dataset has been greatly neglected by previous research, no matter in which scenarios; only the homogeneous scenario has touched this issue with a few papers, which is another future research direction. 

Fifthly, though the problem with sequential target data (no matter labelled or unlabelled) has been touched by a few work in three scenarios (except for the scenario of \textit{heterogeneous feature spaces}), the attention to this problem has no been paid enough. 

Sixthly, when the target data are not presented in the training stage, the \textit{domain generalization} and \textit{zero-shot learning} have been proposed for the scenarios of \textit{homogeneous feature spaces and label spaces} and \textit{heterogeneous label spaces}, where the feature spaces or data modalities between dataset are assumed to be identical. This may be due to that if the source and target data are presented in different feature spaces or modalities, at least some target data are required to be presented for connecting the relationship between source and target data.

Lastly, a natural assumption among most of the literature is that the source data are labelled. This may be because the source data are generally treated as the auxiliary data for instructing the target task and the unlabelled data could be unrelated and lead to negative transfer. However, there are still research argue that the redundant unlabelled source data can still be a treasure as a good starting point of parameters for target task as mentioned in Section~\ref{sec:selftaught}. Hence, it is also encouraged to employ more potential from unlabelled source data in the future research.

                             % Sample .bib file with references that match those in
                             % the 'Specifications Document (V1.5)' as well containing
                             % 'legacy' bibs and bibs with 'alternate codings'.
                             % Gerry Murray - March 2012

% History dates
%\received{February 2007}{March 2009}{June 2009}

% Electronic Appendix
%\elecappendix

\medskip{
\bibliographystyle{ACM-Reference-Format-Journals}
%\bibliography{../CrossDataset}
\bibliography{CrossDataset}
}

\end{document}

% End of v2-acmsmall-sample.tex (March 2012) - Gerry Murray, ACM
