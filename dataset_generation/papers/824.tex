%!TEX root = ./deeptracker.tex
% !TeX spellcheck = en_US
\documentclass[format=acmsmall, review=false, screen=true]{acmart}

\usepackage{booktabs} % For formal tables

\usepackage[ruled,linesnumbered]{algorithm2e} % For algorithms
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}


% Metadata Information
% \acmJournal{TIST}
% \acmVolume{0}
% \acmNumber{0}
% \acmArticle{0}
% \acmYear{0}
% \acmMonth{0}
\acmJournal{TIST} \acmYear{0} \acmVolume{0} \acmNumber{0} \acmArticle{0} \acmMonth{0} \acmPrice{0}
\copyrightyear{2018}
%\acmArticleSeq{9}

% Copyright
\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% DOI
%\acmDOI{10.1145/3200489}

% Paper history
\received{n/a}
\received[revised]{n/a}
\received[accepted]{n/a}


% Dongyu's packages
%\usepackage[T1]{fontenc}
%\usepackage{lmodern}
\usepackage{paralist}

% Dongyu's commands
\newcommand{\name}{{DeepTracker}\xspace}
\newcommand{\ea}{{$\mathrm{E}_a$}\xspace}
\newcommand{\eb}{{$\mathrm{E}_b$}\xspace}
\newcommand{\ec}{{$\mathrm{E}_c$}\xspace}

%\newcommand{\ti}{\textcolor[rgb]{0,0,0}}
\newcommand{\ti}{\textcolor[rgb]{0,0,0}}
\newcommand{\tii}{\textcolor[rgb]{0,0,0}}
\newcommand{\dy}{\textcolor[rgb]{0,0,0}}
%\newcommand{\dy}{\textcolor[rgb]{1,0.1,0}}
\newcommand{\td}{\textcolor[rgb]{0,0,0}}

\makeatletter
\newcommand\footnoteref[1]{\protected@xdef\@thefnmark{\ref{#1}}\@footnotemark}
\makeatother

% Document starts
\begin{document}
	% Title portion. Note the short title for running heads 
	\title{\name: Visualizing the Training Process of Convolutional Neural Networks}  
	\author{Dongyu Liu}
	%\orcid{1234-5678-9012-3456}
	\affiliation{%
		\institution{Hong Kong University of Science and Technology}
		\streetaddress{Clear Water Bay}
		\city{Hong Kong}
		%\state{China}
		%\postcode{23185}
		\country{China}}
	\author{Weiwei Cui}
	\affiliation{%
		\institution{Microsoft Research Asia}
	}
	\author{Kai Jin}
	\affiliation{%
		\institution{Microsoft Research Asia}
	}
	\author{Yuxiao Guo}
	\affiliation{%
		\institution{Microsoft Research Asia}
	}
	\author{Huamin Qu}
	\affiliation{%
		\institution{Hong Kong University of Science and Technology}
	}
	
	%!TEX root = ../deeptracker.tex% !TeX spellcheck = en_US\begin{abstract}
%Deep convolutional neural networks (CNNs) have led to a revolutionary breakthrough for image classification. 
%However, in practice, training a high-quality CNN is often a complicated and confusing trial-and-error procedure, due to the lack of efficient tools for in-depth analyses on the large amount of data dumped in a network training process. 
%Existing work has mainly focused on showing what features a well-trained CNN has learned and how the high-level statistical information of network parameters has changed over time; however, few attempts have been made to conduct a detailed analysis of the training process.
%For better understanding how a CNN is trained, this paper presents a comprehensive visualization system called \name.
Deep convolutional neural networks (CNNs) have achieved remarkable success in various fields. 
However, training an excellent CNN is practically a trial-and-error process that consumes a tremendous amount of time and computer resources.
To accelerate the training process and reduce the number of trials, experts need to understand what has occurred in the training process and why the resulting CNN behaves as such.
However, current popular training platforms, such as TensorFlow, only provide very little and general information, such as training/validation errors, which is far from enough to serve this purpose.
To bridge this gap and help domain experts with their training tasks in a practical environment, we propose a visual analytics system, \name, to facilitate the exploration of the rich dynamics of CNN training processes and to identify the unusual patterns that are hidden behind the huge amount of training log.
%To bridge this gap and help domain experts with their training tasks, we propose \name, a visual analytic system, to expose the rich dynamic of CNN training processes and help experts discover patterns that are hidden inside the highly nonlinear parts of the CNNs.
Specifically, we combine a hierarchical index mechanism and a set of hierarchical small multiples to help experts explore the entire training log from different levels of detail. We also introduce a novel cube-style visualization to reveal the complex correlations among multiple types of heterogeneous training data including neuron weights, validation images, and training iterations.
%We propose a set of visualizations to show the evolvement of network parameters and image classification results and track the critical time periods, images, neurons.
%In particular, we introduce a graph-based hierarchical small multiple technique and heatmap-glyph oriented method to show the evolutions of two types of data from different perspectives. 
%We also propose a matrix-based view and a 3D time cube to facilitate the co-analysis between the two heterogeneous data.
Three case studies are conducted to demonstrate how \name provides its users with valuable knowledge in an industry-level CNN training process, namely in our case, training ResNet-50 on the ImageNet dataset. We show that our method can be easily applied to other state-of-the-art "very deep" CNN models.
%By conducting experiments on ImageNet, one of the largest labeled image datasets used in practice, we demonstrate how \name provides its users with valuable knowledge about CNN trainings.
%We propose a set of visualizations to show the evolvement of network parameters and image classification results and track the critical time periods, images, neurons.
%In particular, we introduce a graph-based hierarchical small multiple technique and heatmap-glyph oriented method to show the evolutions of two types of data from different perspectives. We also propose a matrix-based view and a 3D time cube to facilitate the co-analysis between the two heterogeneous data.
%By conducting experiments on one of the largest labeled image datasets (ImageNet) that often used in practice, we demonstrate how visualization can offer users highly valuable feedback during the training process of CNNs.
\end{abstract}


%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
\begin{CCSXML}
	<ccs2012>
	<concept>
	<concept_id>10003120.10003145</concept_id>
	<concept_desc>Human-centered computing~Visualization</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	<concept>
	<concept_id>10003120.10003145.10003147</concept_id>
	<concept_desc>Human-centered computing~Visualization application domains</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	<concept>
	<concept_id>10003120.10003145.10003147.10010365</concept_id>
	<concept_desc>Human-centered computing~Visual analytics</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	<concept>
	<concept_id>10003120</concept_id>
	<concept_desc>Human-centered computing</concept_desc>
	<concept_significance>300</concept_significance>
	</concept>
	</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Human-centered computing~Visualization}
\ccsdesc[500]{Human-centered computing~Visualization application domains}
\ccsdesc[500]{Human-centered computing~Visual analytics}
\ccsdesc[300]{Human-centered computing~}

%
% End generated code
%


\keywords{deep learning, training process, multiple time series,
	visual analytics, correlation analysis}



%
%  Authors' addresses: G.~Zhou, Computer Science Department, College of
%  William and Mary, 104 Jameson Rd, Williamsburg, PA 23185, US;
%  V.~B\'eranger, Inria Paris-Rocquencourt, Rocquencourt, France;
%  A.~Patel, Rajiv Gandhi University, Rono-Hills, Doimukh, Arunachal
%  Pradesh, India; H.~Chan, Tsinghua University, 30 Shuangqing Rd,
%  Haidian Qu, Beijing Shi, China; T.~Yan, Eaton Innovation Center,
%  Prague, Czech Republic; T.~He, C.~Huang, J.~A.~Stankovic University
%  of Virginia, School of Engineering Charlottesville, VA 22903, USA;
%  T. F. Abdelzaher, (Current address) NASA Ames Research Center,
%  Moffett Field, California 94035.}


\maketitle

% The default list of authors is too long for headers}
%\renewcommand{\shortauthors}{G. Zhou et al.}

%!TEX root = ./deeptracker.tex% !TeX spellcheck = en_US%!TEX root = ../deeptracker.tex% !TeX spellcheck = en_US\section{Introduction}\label{sec:introduction}

Deep convolutional neural networks (CNNs) have achieved huge success in solving problems related to computer vision, such as image classification~\cite{krizhevsky2012imagenet, simonyan2014very}, object detection~\cite{girshick2014rich}, semantic segmentation~\cite{long2015fully}.
However, in practice, training a high-quality CNN is often a complicated, confusing, and tedious trial-and-error procedure~\cite{bengio2012practical}.
For a large CNN, one complete training trial may take a couple of weeks.
However, domain experts often have to repeat this process several times with slightly different settings to obtain a satisfying network, which may take several weeks or even months.
To accelerate this process, experts have to understand the training processes further to check whether they are on the right track, find latent mistakes, and make proper adjustments in the next trial.
%\ww{why, what kind of informed decisions? how the tool can help? what is the goal of the tool? basically, explain why need to know how cnn is trained...., how it can help, then the logic can connect to "unfortunately something"}\ti{
Visualizing the concealed rich training dynamics (e.g., the changes of loss/accuracy and weights/gradients/activations over time) is of vital importance to the understanding of CNN training process.
%Unfortunately, CNNs are usually regarded as a ``black box'', owing to a large number of interacting and non-linear parts~\cite{bengio2013representation}.
Unfortunately, CNNs usually contain a large number of interacting and non-linear parts~\cite{bengio2013representation} and recently become wider and deeper~\cite{simonyan2014very, szegedy2015going, he2016deep, szegedy2016inception}. Both of these bring considerable difficulties for experts in reasoning about CNN training behaviors.
% and figuring out optimization directions
}%Most of the current training platforms only provide experts with high-level statistical information regarding the training process, such as training/validation errors.%Although such information may be enough to determine whether the resulting network is well trained, it also conceals the rich dynamics of the internal changes in the network.%In the early age of CNNs when network structures were small and simple, this concealment was not considered a severe issue since experts could easily make inferences based on their experiences.%However, after CNNs recently became much more complex and deep~\cite{simonyan2014very, szegedy2015going, he2016deep, szegedy2016inception}, experts have begun to face considerable difficulties in reasoning about CNN training behaviors, thereby requiring the development of a tool that can reveal additional details about CNN training processes.%The rich dynamics of the internal changes in the network are concealed.%As CNNs recently become much more complex and deep~\cite{simonyan2014very, szegedy2015going, he2016deep, szegedy2016inception}, such concealment begins to bring considerable difficulties for experts in reasoning about CNN training behaviors. %\ti{However, as CNNs recently become larger and larger~\cite{simonyan2014very, szegedy2015going, he2016deep, szegedy2016inception}, such concealment begins to bring considerable difficulties for experts in reasoning about CNN training behaviors and figuring out optimization directions.}%thus causing a huge difficulty for experts to intuitively and quantitatively understand how a CNN is trained.%Thus, it is in a very urgent to develop an informative and intuitive visual analytics system to reveal more details about the CNN training process.%\ww{citation needed, only provide, then so what? the logic is not finished here.}%\ww{is cnn or dnn? is cnn blackbox or training process is blackbox}%\ww{exactly, need to explain why need to understand this beforehand, check previous comments}%\ww{The first several sentences are good, the rest are weird, basically.}\ti{
Many previous studies investigate what features have been learned by a CNN in one (e.g., usually the last one) or several representative snapshots during the training process~\cite{erhan2009visualizing, zeiler2014visualizing, springenberg2014striving, dosovitskiy2015inverting, mahendran2015understanding, zeng2017cnncomparator, liu2017towards, rauber2017visualizing, alsallakh2018convolutional, Pezzotti2018DeepEyes, kahng2018activis}.
However, little research focuses on visualizing the overall training dynamics.
One recent work~\cite{liu2018analyzing} visualizes the training process of deep neural networks, but it is not tailored for CNNs and not scalable enough to analyze the CNNs that are not only wide but also deep.}\ti{Besides, tools like TensorBoard, Nvidia Digits, and Deeplearning4j\footnote{TensorBoard: \url{https://www.tensorflow.org/get_started/summaries_and_tensorboard}; Nvidia Digits: \url{https://developer.nvidia.com/digits}; Deeplearning4j: \url{https://deeplearning4j.org/visualization}} are able to show some high-level training dynamics, such as loss and the mean of weights in a layer. However, these tools can neither handle industry-level training (i.e., training a large CNN on a very large dataset) nor answer complex questions. 
For example, how the model's performance on each class of images changes over time? How the changes of parameters impact the classification results for each class? Given so many layers or image classes, which of them are worth paying more attention to and what is the best manner to support comparative analysis?
}\ti{With these concerns, we are in urgent need of a scalable visualization solution to conducting more advanced analytical tasks.}%Many studies have been conducted to help experts investigate what features have been learned by a specific CNN~\cite{erhan2009visualizing, zeiler2014visualizing, springenberg2014striving, dosovitskiy2015inverting, mahendran2015understanding, zeng2017cnncomparator, liu2017towards, rauber2017visualizing, alsallakh2018convolutional, liu2018analyzing, Pezzotti2018DeepEyes, kahng2018activis} and how a CNN processes input images~\cite{wongsuphasawat2018visualizing}.%However, these techniques are not tailored for analyzing CNN training processes.%.\ww{again, to say this, you need to make it very clear in the first para, that the training is important. but this version looks like you are talking about cnn is hard in general}%Moreover, there is little work that focuses on visualizing network training processes. %\ww{evolution is ambigious, either you make it clear at the begining, or use taining instead.}%Some existing online tools, such as Playground\footnote{\url{http://playground.tensorflow.org}} and ConvNetJS\footnote{\url{http://cs.stanford.edu/people/karpathy/convnetjs/}}, are more like tutorial tools for learning the basic ideas of neural networks. They are not designed to be used in practice.%In terms of the capability of characterizing training processes, other tools, such as TensorBoard\footnote{\url{https://www.tensorflow.org/get_started/summaries_and_tensorboard}}, Nvidia Digits\footnote{\url{https://developer.nvidia.com/digits}}, and Deeplearning4j\footnote{\url{https://deeplearning4j.org/visualization}}, only use simple charts (e.g., line charts and histogram charts) to show basic statistical information about network training.%Some online tools, such as Playground and ConvNetJS\footnote{Playground: \url{http://playground.tensorflow.org}; ConvNetJS: \url{http://cs.stanford.edu/people/karpathy/convnetjs/}}, are more like tutorial tools for learning the basic concepts of neural networks.%However, little research focuses on visualizing network training processes. Existing work~\cite{liu2018analyzing, chung2016revacnn} is neither designed for CNN training nor supporting industry-level training.%Some training platforms (e.g., TensorBoard, Nvidia Digits, and Deeplearning4j\footnote{TensorBoard: \url{https://www.tensorflow.org/get_started/summaries_and_tensorboard}; Nvidia Digits: \url{https://developer.nvidia.com/digits}; Deeplearning4j: \url{https://deeplearning4j.org/visualization}}), in terms of the capability of characterizing CNN training process, only provide simple charts to show basic statistical information over training.%These tools may perform well in the past, but they are considered inadequate nowadays as CNNs increase both in size and depth.%For example, facing dozens or hundreds of layers, experts are dazed to select a proper layer to watch. They are in desperate need for a better manner to show the information from different levels of detail. %Experts may also desire to compare the statistical information among multiple layers to more effectively diagnose the network structures and settings (e.g., hyper-parameters, initialization methods, and gradient update approaches).%Unfortunately, previous tools cannot meet these demands well.%Furthermore, there is still much useful information hidden inside CNNs, which may help experts reason about and improve CNN performances.%For instance, during a CNN training process, experts can be intrigued by a mass of questions, such as, %how the error rates for each class evolve over the entire training process,%which image classes are easy/hard for classification,%how the changes in network parameters relate to the model's performance on each class.%does a specified class have significant training intervals that have great impact on the model's performance on this class?%Motivated by these questions, we attempt to design a tool to enable experts to explore training logs from different levels and perspectives, assisting them in further understanding CNN training processes and accelerating the trial-and-error procedure.%For instance, when training a CNN on the ImageNet dataset~\cite{russakovsky2015imagenet}, which contains $1,000$ classes of labeled images, experts are interested in many questions: How does the performance (i.e., error rate) of each class evolve over the entire training process? Which image classes are easy/hard for classification? Does a specified class have significant training intervals that have great impact on the model's performance on this class? How do the changes in network parameters relate to the model's performance on each class?}%The experts shall strongly desire a tool that can allow them to explore the layer-related information in different levels of detail. Previous tools, however, cannot meet this demand well. %to be allow compare the evolving trend of parameters among multiple layers of a CNN. %, which consists of multiple layers of learnable parameters.%However, this task become challenging if only basic charts are used.% it is challenging for experts to carry out complicated tasks like comparing%\ww{why? what tasks? just say, they perform well when graph is small, but the trend is bigger and deeper, so they become more ambigious or hard to interpret}%\ww{need examples here, what kind of information?. we need to give a scope of what exact problems that we are targeting at this problem. saying something like this. In a typical imagenet training, there are 1000 valication classes, do they have similar performances (i.e., error rates)? Or there are good and bad images in them. There are usually over 1M iterations, are they equally important? Or they are particular iterations that significant changes are made to the network, and what are those changes? How those changes affect the errors and loses? etc. The purpose here is to set the expection of the reader, and raise questions to intrigue them. VERY IMPORTANT}%Thus, it is in an very urgent need to develop a tool, which can show network training information from different perspective and levels of details, to inform the experts whether a CNN evolves on a right track and guide them right directions to modify the network in time. % when some mistakes occurs.

To this end, we have to deal with two major challenges.
First, the system needs to handle the large-scale training log data.
Typically, millions of CNN parameters and tens of thousands of validation images are involved in a training process.
%For example, as regards ImageNet, there are $50,000$ validation images in $1,000$ classes.
In addition, the training is an iteration-based process that usually requires a million iterations to complete, which makes things worse, because the parameters and classification results need to be recorded for every few iterations.
In our experiments (Sec.~\ref{sec:dataprocessing}), a sampled training log may easily exceed a couple of terabytes per training.
%Facing the data at such scale, not only an effective data storage and index mechanism but also a scalable visualization technique is required to help users efficiently organize and explore the whole log at different levels of detail.
To allow an interactive exploration of the data at such scale, it requires not only an effective data storage and index mechanism but also a scalable visualization technique.
Second, the log information is heterogeneous.
The full log contains structure (e.g., neural network), numeric (e.g., neuron weights), image (e.g., validation dataset), and nominal data (e.g., classification results).
Given that significant insights are often hidden underneath the complex relationships among these data, our system also needs to present all these types of data intuitively and assist experts in their analysis tasks.
%, such as identifying critical iterations or finding correlations between the network parameters and image classification results.%The training history consists of network structures, temporal%(2) creating an intuitive visualization to facilitate the correlation analysis between heterogeneous data, namely, the statistical data of network parameters and the image classification results.}%\ww{The second point is too brief. The training history is not only large, but also heterogeneous. We have time dimension, neural network with nested structures, different types of layers, train+validation iterations. to organize them in a intuitive manner is not easy. there maybe temporal patterns, such as important iterations, and correlation patterns, such as filter and images. Pay attention not to talk technically, since we have not covered the background yet}%\ww{we extract simple flip features, does not sound impressive, saying something like we need a highly highly scalable and lod metod to visually encode such information.}%%\ww{I think one thing is special about this data. It is a highly dynamic process, too detailed features (image level, iteration level) are not important, since the those features may purely happen by accidient, so how to extract features at different aggregation level and ignore noise?}%To tackle the two challenges, we present \name, an interactive visual analytics system, to reveal the network training information from different perspective and at different levels of details.%with so many layers and iterations, how can we identify the important time period and compare the difference between layers in a effective and intuitive manner? Moreover, other dimension information, such as the variation of each class of images classification results over the time, is also useful for users to understand the network training process. How can we combine these useful heterogeneous data together to help users gain a better insights from the network evolving process?%\ww{largely ok, but mediocre, not exciting, same below.}%show the layer parameters information intuitively and elegantly when the depth of a CNN becomes deeper and deeper? Besides, other dimension information, such as the variation of each class of images classification results over the time, is also useful for users to understand the network evolution process. How can we combine these heterogeneous data together to help users gain a better insights from the network evolving process?

To address these challenges, we use a downsampling method to store the raw data, and then preprocess and organize these data in a hierarchical manner.
We also design several efficient index mechanisms to support real-time interactions.
To help experts identify the iterations of interest quickly, we propose an application-specific anomaly detection method.
\ti{We also integrate many filtering and aggregation approaches to reduce the amount of presenting information and ensure preserving the noteworthy information.}
For visualization, we design a set of hierarchical small multiples that is combined with a network structure layout to facilitate an effective exploration of the entire training log from different levels of detail.
To reveal the complex correlations among neuron weights, validation images, and training iterations, we further introduce a cube-style visualization.
The cube integrates the small multiples and a matrix-based correlation view, thereby allowing experts to effectively slice and dice the data from different perspectives.

%We also integrate pixel-based visualization into the tree view to enable experts to easily switch between aggregated and detailed representations.%In addition, we novelly present a 1D heatmap-glyph-based small multiple visualization to enable experts effective exploration and discerning different evolution patterns of each class classification result.%\dy{For the second challenge, we introduce a cube-style valization to support analyzing and intepretign correlations between neuron weights, validation images, and training iterations. In particular, we align the aforementioned two types of small multiples along the faces of a 3D-cube (say front face for tree-based small multiples and top face for heatmap-glyph-based small multiples), then one additional right face is used to encode the correlation information between classes and layers.}%We ensure that the two types of small multiple share the same timeline to allow users to easily conduct co-analysis between them.%\ww{still too brief, explain more when things are more clear.}
The main contributions of this paper are summarized as follows:
\begin{compactitem}
	\item A systematic characterization of the problem of visualizing the rich dynamics in CNN training processes, and a thorough discussion and summary of the design requirements and space.
	%We identify several information that are critical and useful for understanding the training process and propose a tailored data organization and index method.}
	\item A visual analytics system that integrates a tailored large data storage and index mechanism, an anomaly iteration detection algorithm, and a set of well-designed visualization techniques.
		%to help experts gain insight into CNN trainings so that it would be easier to understand, debug, and optimize the trial-and-error process.}%enabling users to get better understanding for the training process first one to summarize the data produced during training process
	\item A couple of new visualization and interaction techniques including hierarchical small multiples, grid-based correlation view, and cube-style visualization.
	%to empower experts to explore the major patterns of network parameters and image classification results over the training process and to conduct correlation analysis between these two types of data.}
\end{compactitem}%The rest of this paper is structured as follows. We start with a literature review in Section~\ref{sec:relatedwork}. Then we characterize the problems and analyze requirements of system~\ref{sec:background}. Section~\ref{sec:model} sheds light on the data preprocessing and optimization model description, followed by the overview of our system in Section~\ref{sec:system}. Subsequently in Section~\ref{sec:evaluation}, we presents two case studies using a real dataset, expert interviews, and a user study. After that, we have a discussion of our work and finally we end with a conclusion.% 提出自己的观点常用句式：% We aim to//This paper reports on//This paper provides results//This paper extends the method//This paper focus on……The purpose of this paper is to……Furthermore, Moreover, In addition, we will also discuss……%!TEX root = ../deeptracker.tex% !TeX spellcheck = en_US\section{Background}\label{sec:background}%In this section, we briefly introduce the basic concepts which may be referred to in the subsequent discussion of CNNs.%\vspace{-2mm}\begin{figure}[htb]
	\centering
	\includegraphics[width=0.8\columnwidth]{resources/cnn}
	\vspace{-4mm}
	\caption{Illustration of a CNN architecture that contains three types of layers (i.e., CONV layer, POOL layer, and FC layer) and transforms an image volume into a class score vector.}
	\label{fig:cnn}
	\vspace{0mm}
\end{figure}%CNNs are a special type of artificial neural networks that have been proven very effective in tasks like object detection~\cite{girshick2014rich} and image classification~\cite{krizhevsky2012imagenet}. 
A typical CNN can be viewed as a sequence of layers (Fig.~\ref{fig:cnn}) that transforms an image volume (e.g., a $224\times224$ image with three color channels of R, G, and B) into an output volume (e.g., a vector of size $1,000$ indicating the probability for an input image to belong to $1,000$ predefined classes)~\cite{lecun2015deep}. There are three main types of layers to build a CNN architecture, namely, \textit{convolutional layer} (CONV layer), \textit{pooling layer} (POOL layer), and \textit{fully-connected layer} (FC layer).

A CONV layer comprises numerous neurons that are connected to a local region in the previous layer's output volume through weighted edges, many of which share the same weights through a parameter sharing scheme. 
The weights in each neuron compose a \textit{filter}, the basic unit for detecting  \textit{visual features} in the input image, such as a blotch of color or the shape of an area. 
The output of each neuron is computed via a dot product operation between the weights and inputs from the previous layer, and is then optionally applied via an elementwise activation function (e.g., ReLU, $max(0, x)$). 
A POOL layer is usually inserted between successive CONV layers to reduce the volume of input through a downsampling operation, thereby reducing the amount of parameters and computation in the network. 
The only difference between FC layer and CONV layer is that, in contrast to the neurons in CONV layer that are locally connected and have shared parameters, the neurons in FC layers have full connections to the previous layer's output volume. In addition, the output of the last FC layer is fed to a classifier (e.g., Softmax), computing the scores for all predefined classes, where each score represents the probability that an input image belongs to the corresponding class.

%To empower the learning capability of a CNN, a popular method is to increase the depth of CNNs~\cite{}. Some leading results utilizing ``very deep'' models ~\cite{} have been attained on the ImageNet dataset ~\cite{}. As shown in Fig. 2, such very deep CNNs have a natural hierarchical structure, that is, big conv layer consists of a sequence of same small conv layer.

To obtain an effective CNN, the weight parameters in the CONV and FC layers need to be trained using gradient descent methods~\cite{bottou1991stochastic} to ensure the consistency between the predicted class labels and the predefined class for each training image.
Specifically, a training process involves two separate datasets, namely, the training set $\mathit{D_t}$ and the validation set $\mathit{D_v}$. 
To start the training, the parameters of weighted layers are usually initialized via Gaussian distribution~\cite{glorot2010understanding}, and $\mathit{D_t}$ is partitioned into non-overlapping batches.
For each iteration, one batch of images in $\mathit{D_t}$ is fed to the network. 
Afterward, the output classification results are compared with the ground truth (i.e., the known labels of the fed images) to compute the \textit{gradients} with respect to all neurons. 
These gradients are then used to update the weights of each neuron. 
When all batches in $\mathit{D_t}$ are completed (i.e., finish one \textit{epoch}), $D_t$ is reshuffled and partitioned into new non-overlapping batches.
After several epoches, the initially-randomized neural network will be gradually shaped into a specified network targeting at a specific task.
%\ww{why we record gradient and validation? we need to explain what they are for, why they are imporant, try explain more here.}
Meanwhile, for every given number of iterations, the network is evaluated via $\mathit{D_v}$.
Similarly, $D_v$ is fed into the network and then the output classification results are collected and compared with the ground truth.
However, the results are only used to validate whether a training process goes well and never used to update neuron weights.
%The validation step is a vital part of the whole training process, since it acts as a ``test drive'' of the network to help experts track how the network performance evolves over training~\cite{bengio2012practical}.%Thus, it can reveal a great deal of dynamics in the training process and help users understand how the network is changed internally.%\ww{validation is critial in this paper, we need to explain and emphasize its important.}%to test the performance of current network. This information can help users track whether the network is making progressive improvement or already overfitting~\cite{bengio2012practical}.%It usually requires tens or hundreds epoch to get the training done, where one epoch means that the entire training dataset has been fed once.%!TEX root = ../deeptracker.tex% !TeX spellcheck = en_US\section{Related Work}\label{sec:relatedwork}\subsection{CNN Visualization}
CNNs have recently received considerable attention in the field of visualization~\cite{seifert2017visualizations}. 
Existing approaches can be classified into two categories, namely, feature-oriented and evolution-oriented.

Feature-oriented approaches aim to visualize and interpret how a specific CNN behaves on the input images to disclose what features it has learned.
%\ww{you just rephrase the words, still no idea what they aim at. If so, you should provide examples.}%\ti{Feature-oriented approaches aim to observe the }
Most of the existing studies belong to this category.
Some studies~\cite{zeiler2011adaptive,zeiler2014visualizing} modify part of the input and measure the resulting variation in the output or intermediate hidden layers of a CNN. 
By visualizing the resulting variations (e.g., using a heatmap), users can identify which parts of the input image contributes the most to the classification results.
By contrast, other studies~\cite{zeiler2014visualizing,springenberg2014striving,mahendran2015understanding,dosovitskiy2015inverting} attempt to synthesize an image that is most relevant to the activation (i.e., the output of a layer after an activation function) of interest to help experts determine which features of a specified image are important for the relevant neurons.
%For example, Zeiler and Fergus~\cite{zeiler2014visualizing} propose a deconvolutional network to determine the contribution of each pixel of the input image and then visualize it in the form of a synthesized image; 
For example, Mahendran and Vedaldi~\cite{mahendran2015understanding} reconstruct the input images that can either activate the neurons of interest or produce the same activations as another input image.
Besides, some methods focus on retrieving a set of images that can maximally activate a specific neuron~\cite{girshick2014rich,erhan2009visualizing}.
In this manner, users can discover which types of features or images are captured by a specific neuron. 
Built on this method, Liu et al.~\cite{liu2017towards} develop a visual analytics system that integrates a set of visualizations to explore the features learned by neurons and reveal the relationships among them.
%\dy{Their work is not tested in practical model and large scale data.}%In addition, some work~\cite{rauber2017visualizing,tsnecnn} utilizes dimension reduction technique like t-SNE to project the high-dimension activation vectors of the last layer (i.e., the class scores) or an intermediate hidden layer onto a 2D space, providing an overview of relationships between classification results.
In addition, some work~\cite{rauber2017visualizing,chung2016revacnn,kahng2018activis,Pezzotti2018DeepEyes} utilizes dimension reduction technique to project the high-dimension activation vectors of FC or intermediate hidden layers onto a 2D space to facilitate revealing the relationships among outputs.

In contrast to those studies that investigate how a specified network works, only few studies concentrate on visualizing network training processes.
%In contrast to the aforementioned methods that mainly explain how a given CNN (usually a well-trained network) works, the other category of previous studies concentrate on visualizing the network training process.%Although our work also belongs to this category, it is different from the existing ones in various ways.%In other words, they fail to show how network parameters and image classification results change over a CNN training process.%In this study, we concentrate on visualizing the network training process.%While compared with the learned feature visualization, There are fewer studies regarding to visualizing the network training process. %There is little research mainly focusing on doing this.
One typical method is to pick several snapshots of a CNN over the training process and then leverage feature-oriented approaches to compare how a CNN behaves differently on a given set of inputs at various iterations~\cite{zeiler2014visualizing, chung2016revacnn, zeng2017cnncomparator, alsallakh2018convolutional}.
For example, Zeiler and Fergus~\cite{zeiler2014visualizing} use deconvnet approach to visualize a series of synthesized images that are most relevant to one activation of interest at a few manually picked snapshots, and then observe the differences between them.
\ti{
Zeng et al.~\cite{zeng2017cnncomparator} present a matrix visualization to show the weight differences of filters of one layer as well as this layer's input and output in two model snapshots. Their system also supports side by side comparison on the learned features of neurons (the computation method is similar to the work~\cite{girshick2014rich}) in different model snapshots.
One limitation of these methods is that when there are myriad filters, images, and iterations, it is challenging to select proper ones to observe and compare.
By contrast, we attempt to reveal the rich dynamics of the network parameters and the classification results at a larger scale to help experts find the notable filters, images, and iterations.
In this point, Alsallakh et al.~\cite{alsallakh2018convolutional} analyze the same data facets (i.e., input images, network parameters, and classification results). However, the work focuses more on identifying the hierarchical similarity structures between classes and still belongs to the category of multiple snapshots comparison, thereby suffering from the same limitation. 
}

To analyze the evolution of CNN parameters, Eliana~\cite{eliana2016pca} treats the parameters of the entire network at one iteration as a high-dimension vector, uses PCA to map the vectors at all iterations onto a 3D space, and creates trajectories for these points. However, this visualization is too abstract to extract useful insights for understanding and debugging the training process.
To analyze the classification results, Rauber et al.~\cite{rauber2017visualizing} create a 2D trails graph to present an overview of how the CNN classification results evolve by leveraging the projection techniques.
However, this method suffers from scalability and visual clutter problems when applied to large-scale datasets (e.g., ImageNet). Besides, this method only provides a very high-level overview and cannot answer those questions that involve individual classes or images.
\ti{The work most similar to ours should be the one by Liu et al.~\cite{liu2018analyzing}, whereas the work mainly targets at deep generative models and would have serious scalability issue if applied in an industry-level CNN training. Besides, compared with that work, we specifically provide a series of hierarchical methods that are tailored for CNNs to visualize the training dynamics, including classification results and network parameters. 
%Our approach is also capable of examining how parameter changes impact the model performance on each class.
%have different concerns.
%We not only aim to visualize the rich dynamics concerning the network parameters at different levels of detail, but also target in revealing the details about class-level and image-level performances.
}%We also attempt to discover the correlation between network parameters and validation image classification results at multiple scales.%. Specifically, we propose a hierarchical small multiples visualization combined with a network graph to support the exploration of network parameters over training at multiple scales.%In particular, we propose a highly space-efficient heatmap-based small multiple visualization to facilitate the exploration of classification results over training at different levels of detail.%In details, We also present a novel correlation matrix and cube-style visualization to help experts explore the complex relationships among network parameters, classification results, and iterations, thereby allowing them to quickly identify the notable filters, images, and iterations.\ti{Furthermore, we design a novel correlation matrix and 2.5D cube-style visualization to help experts examine the complex relationships exist among network parameters, classification results, and iterations.}%\ww{this paragraph is too short, need to say more about the difference between ours and theirs.}%With a different purpose, our work focuses on analyzing how the network parameters themselves and the classification results of all validation images change.%~\ww{sentence not clear. It is really important to let reviewers know your work is different from the previous. If you say this unclear, I only know there is different, but I do not know that it is. Then I have two choices, either taking your words for it, or questioning your words, you need to explain.}%In addition, some popular online tools, such as Tensorboard~\cite{tensorboard}, Nvidia Digits~\cite{nvidiad}, and Deeplearning4j~\cite{Deeplearning4j}, only use simple charts to show high-level statistical information of network parameters over the training process and cannot reveal more detailed statistical information regarding to filter-level. Moreover, due to the trend that CNNs are becoming bigger and deeper~\cite{he2016deep,szegedy2016inception,szegedy2015going,simonyan2014very}, these tools are not fitted to execute more complicated exploratory tasks such as comparing the trends of one type of statistical information among multiple layers.%\ww{what is desired patterns? Better say that users are no longer happy with these primitive, overly-aggregative information, and desire to know more...}%\td{To reveal more details about CNN training processes, we propose a novel tree-based small multiple time-series visualization technique which can display the evolutions of network parameters (i.e., weight and gradient) from different levels of details. Besides, we leverage pixel visualization technique to reveal the filter-level parameter evolution. Apart from the inner parameters of a CNN, we also present a heatmap-based small multiple visualization to help users gain more detailed information about the classification results for each class. More importantly, to the correlation analysis between multiple kinds of data, we novelly are the first who present a novel time-cube visualization technique to allow users to conduct co-analysis between network parameters and image labeling data.}\ww{duplicated, probably remove.}\subsection{Multiple Time Series Visualization}

Time series data have been extensively studied due to their ubiquity.
Numerous approaches~\cite{aigner2011visualization, aigner2008visual, bach2014review} to time series visualization have been proposed.
Our system also falls into this field, since training logs are essentially a type of time-based information.
Specifically, our system is most related to existing work that visualizes multiple time series.
%Aigner et al.~\cite{aigner2011visualization, aigner2008visual} propose a framework to categorize these approaches based on the nature of temporal attributes, e.g., whether the time scope is point or interval, whether the value scale is ordinal, discrete, or continuous, and whether the timeline is cyclic or linear.%Among these approaches, those visualizing multiple time series are most relevant to our work. 
To visualize multiple time series, one method is to place multiple charts (e.g., line charts) in the same graph space to produce overlapping curves. However, this method reduces the legibility of individual time-series~\cite{javed2010graphical}.
In contrast to overlaying multiple series, one popular alternative is to use small multiples~\cite{tufte1983visual} that split the space into individual graphs, each showing one time series. Using small multiples also allows for an effective comparison across charts. Several factors may also affect the performance of small multiples~\cite{heer2009sizing,javed2010graphical}, such as the types of charts used (e.g., line charts and horizon graphs), the number of series and the vertical space allocated to each series. The improper use of time-series charts, the increased series, and the small vertical space of each series will result in a serious visual clutter problem.

In this work, the evolution of the image classification results of each class and the weight parameters of each layer can be viewed as two types of multiple time series data. Given the large number of classes and layers in a practical CNN training, we identify several space-efficient charts that can characterize the training dynamics. Besides, we propose a similarity-based layout and a hierarchical exploration method to support the exploration of relationships among multiple time series to address the visual clutter problem. We also present a novel cube-based visualization, targeting at the exploration of complex relationships among various types of heterogeneous time-series data (e.g., image classification results, neuron weights, and training iterations).

%\subsection{Time Series Data Visualization}%Time series data have been extensively studied due to their ubiquity~\cite{shneiderman1996eyes}.%A remarkably large variety of time-series data visualization techniques that have been proposed. %Several surveys are completed from different perspectives as well~\cite{brehmer2016timelines,bach2014review,aigner2011visualization}. %Brehmer et al.~\cite{brehmer2016timelines} elaborate on the design space and considerations particularly in a context of story telling with the aim of balancing expressiveness and effectiveness. %Bach et al.~\cite{bach2014review} discuss a variety of techniques in the context of space-time cube (i.e., STC).%Aigner et al.~\cite{aigner2011visualization} propose a framework to categorize myriad approaches to time series visualization that are intended primarily for exploratory data analysis.%In the framework, the techniques are classified based on the nature of the temporal attribute, e.g., whether the time scope is point or interval, whether the value scale is ordinal, discrete, or continuous, and whether the timeline is cyclic, linear, or branching.  %As for our application scenario, the techniques used for visualizing the data with point scope, discrete or continuous scale are most relevant to us. In this light, some general techniques to deal with such kind of data includes, several simple charts such as, index charts, horizon graphs, stacked graphs, and small multiples~\cite{heer2010tour, javed2010graphical}, some contextual representations like spiral visualization~\cite{weber2001visualizing} and cluster and calendar-based visualization~\cite{van1999cluster}, pixel-based visualization for time series~\cite{ankerst1996circle, kumar2005time, hao2007multi}, and multi-resolution techniques~\cite{hao2007multi} for exploring patterns in large time-series data.\ww{whole subsection is strange, please rewrite.}%Small multiples are a general concept, which is described as a set of miniature visual representations~\cite{mulrow2002visual}. When applied to line graph visualization, it means that we split the space into individual graphs. For time-series data, . One of the biggest advantage of using small multiples is that it provide an overview of the data and in the meanwhile enable users visually compare the data as all charts use the same axis scaling~\cite{javed2010graphical}. However, due to the limited displaying space, it is not allowed to show too many time-series in the same time. To overcome this disadvantage, %In this study, we enhance\ww{why enhance? why existing does not work? scalaiblity? special needs that they cannot handle well? maybe emphasize that our data is also heterogeneous, they need to be enhanced, and explain how enhanced.} small multiple displaying technique with a tree-based layout combining with several novel interaction techniques to support effective identification and comparison of trends among different CNN layers from different levels of details. Besides, we integrate pixel-based visualization into the tree view to enable users easily switch between aggregated and detailed representations. Furthermore, we novelly present a 1D heatmap-glyph-based small multiple visualization\ww{not really novel, we will design something else and then put them here} to enable users effective exploration and discerning different evolution patterns of each class classification result.%\td{In this study, we firstly} %!TEX root = ../deeptracker.tex% !TeX spellcheck = en_US\section{Requirement Analysis}\label{sec:requiments}%This section first describes the data format dumped in the training process of CNNs. Subsequently, we discuss the design requirements.\name was developed in approximately nine months, in which we collaborate closely with three experts (denoted by \ea, \eb, and \ec) who have considerable experience in CNNs. We held regular discussions with these experts once a week.

%\subsection{Data Abstraction}%$L=\{l_{i}|i\in []  \}$%All the experts show their desires to . Thus, 
From our regular discussions, we learned that the training process should be carefully babysat. The experts have to tune and fix a number of \textit{hyper-parameters} (learning rate, batch size, layer number, filter number per layer, weight decay, momentum, etc.) before starting a training trial.
These hyper-parameters, which strongly influence how a CNN is trained, are usually selected based on the experiences learned from their previous trials. 
%\dy{It is noted that, learning rate is a special hyper-parameter that can be changed during a training process. Typically, it is suggested to turn down the learning rate when the validation error rate and loss do not decrease anymore for a long time.}%After a training starts, the weights of each layer will be iteratively updated automatically, and the experts have little control over the updates.
During a training, there are several useful quantities the experts want to monitor, such as loss function (the residual error between the prediction results and the ground truth), train/validation error rate (the percentage of mislabeled images), weight update ratio (the ratio of the update magnitudes to the value magnitudes), and weight/gradient/activation distributions per layer. Basically, both loss and error rate should decrease over time; the consistent increase or violent fluctuation of loss on $D_t$ may indicate a problem; a big gap between the error rates of $D_t$ and $D_v$ may suggest that the model is over-fitting, while the absence of any gap may indicate that the model has a limited learning capability; the update ratio\footnote{In most cases, if the update ratio is lower than 1e-3, the learning rate might be too low; if it is higher than 1e-3, the learning rate is probably too high.} is expected to be around 1e-3; the weight distributions per layer in the beginning should overall follow Gaussian distributions with different standard deviation settings\footnote{\label{note7}Xavier Initialization~\cite{glorot2010understanding} is applied in our model. Basically, the deeper (close to loss layer) the layer is, the smaller the sd is.} and may become diverse after training; and exploding or vanishing gradient values are a bad sign for the training.
%\dy{At each iteration, the neuron weights themselves and how they change (gradient and update ratio\footnote{The ratio of the update magnitudes to the value magnitudes, which is expected to be around 1e-3 in most cases.}) are the key information that defines the network and training quality.}%For example, the weights must approximately have a normal distribution after the first several iterations. %\dy{For example, the experts usually use Xavier Initialization~\cite{glorot2010understanding} to initialize weights, leading to the result that in the beginning weight distributions in each layer should be very different. Besides, exploding or vanishing gradient values are also a bad sign for the training.}%Otherwise, it may indicate a problematic training caused by several reasons, such as a high learning rate or insufficient regularization (e.g., weight decay). %To track the change in performance across iterations, current popular training frameworks usually provide two pieces of summary information, namely, error rate and loss, on the training and validation datasets ($D_t$ and $D_v$).%The error rate indicates the percentage of mislabeled images, while the loss measures the residual error between the prediction results and the ground truth.%Typically, both error rate and loss should decrease over time. %The consistent increase or violent fluctuation of loss on $D_t$ may indicate an ill distribution of weights. %A big gap between the error rates of $D_t$ and $D_v$ may suggest that the model is over-fitting, while the absence of any gap may indicate that the model has a limited learning capacity.%The aforementioned are some basic rules that the experts concluded from their numerous trials. The aforementioned rules of thumb are all based on the analysis of high level statistical information.
However, the experts still strongly desire to examine more details underlying the statistic, so that they can gain more knowledge and suit the remedy to the case when problems occur. 	
For example, the experience tells the experts that it is better to continue training models (e.g., ResNet~\cite{he2016deep}) with the same learning rate for a while rather than turn it down immediately, when the overall error rate stops to decrease. The experts are very curious about what happens to the model and its performance on each class of images during the period. 
%it is common for the global error rate for all images in $D_v$ remaining stable for a long time, but why we do not choose to turn down the learning rate immediately, need to do so and what happens for the performance on each individual class. 
Also, we may often see a fluctuation of loss or an occasional exploding gradient values, and what brings about this? Are there any layers or filters that behave abnormally? 
These details are never uncovered before.
Thus, the experts strongly desire a tool to enable them to explore the hidden dynamics behind a CNN training. 
%interact with the complete training log data and explore multiple types of training behaviors.%The only important thing the experts always emphasize is that the tool should be designed for analyzing industry-level CNN training process.
After several rounds of structured interviews with the experts, we finally summarized and compiled the following list of requirements:

%\dy{Since our primary concern is to visualize the industry level dnn training process, and all our start point to visualize such dnns, I think we do not have to demonstrate our method can be applied into small models. What we need to do is emphasize that we focus on dealing with industry level DNNs model. At most, we can add another dataset, i.e. cifar, to demonstrate it (with low priority, need 2 days).}%Previous tools are not allowed the experts to effectively examine some situations, like comparing weight distribution in one scale.%However, the experts also encountered many phenomena that they could not explain or understand.%\dy{Add one example to illustrate when gradient explosion occurs, which filters variate most?}%For example, when the global error rate for all images remains stable, significant changes may still happen in some individual image classes.%Sometimes there are significant changes (high update ratios) in a few filters, how they impact the performance on several classes.%The experts desire to know which filters have the greatest influence on the performance changes of which classes.%These detailed changes obviously cannot be revealed via simple summaries, such as global error rate and loss.%During the process, current popular frameworks provide the experts with the basic statistical information of weight and gradients for each layers, which are useful for them to understand and debug the network.%For example, for weights, it should have an approximately Gaussian (normal) distribution after several iterations. If there are weights that are diverging to very large positive or negative values, this may be caused by a high learning rate or insufficient regularization (e.g., weight decay). %For the gradient information, the experts should keep an eye out for exploding/vanishing values that indicate some problems may exist in current networks. There should be different statistical value scale or trend for different layers at different depths, the experts often need to compare them.%In addition, there are two more types of values are important indicators for the experts to track the performance of a CNN, namely, the error rate and the loss on a given dataset ($\mathit{D_t}$ and $\mathit{D_v}$). The error rate is the percentage of images labeled incorrectly and the loss measures the prediction errors. Typically, both error rate and loss should (overall) go down over iterations. Increasing loss on $\mathit{D_t}$ can be indicative of some network issues such as, the high learning rate or incorrect data normalization.  A big gap between error rate of $\mathit{D_t}$ and $\mathit{D_v}$ may suggest the model is overfitting, while no gap may indicate the model has limited learning capacity.%However, when the number of layers increase to tens or hundreds, it is becoming more and more challenging for the experts to efficiently find abnormals in layers, not mention to conducting comparison among such many layers. Moreover, only showing how single value like error rate or loss change over time hide the rich dynamics behind it. For example, sometimes even the error rate remain the same, there are some significant changes on some image classes.%Therefore, the feedback collected by the all three experts strongly suggests that a visual system that enables analysts to interact with the complete training log data and explore training behavior is urgently needed. %\ww{maybe give a short paragraph explain how people visualize training in previous work or exiting framework, which is the training/validation error/loss, and what their meaning, and how important it is, and how people interpret them. then we can say our experts are not satisfy with them, because xxx, and then we have frequent discussion to dientify xxx...}%\subsection{Requirement Analysis}%After several rounds of structure interviews with the experts, we summarized and complied a list of design requirements as follows. %Therefore, our focus is to design an informative and intuitive visualization interface for both real-time monitoring of a CNN performance and historical data analysis. In this manner, users can .%Notice that the requirements are derived from the feedback of the experts, as well as the knowledge gleaned from the literature review. \begin{compactenum}[R.1]
	%\setcounter{enumi}{4}
	%\itemsep-0.1em 
	%\item \textbf{ xx }%Preserve the familiar forms for displaying the basic information}.
	%It is a fundamental task to show the model-performance-related information (i.e., the loss and error of training/validation ). Meanwhile, the learning rates 
	%showing the how learning rate variate over time.
	
	\item \textbf{Exploring multiple facets of neuron weight information}.
	%\dy{main focus: very large model, hierarchical manner, levels of details, from module level - bottleneck level - layer level - filter level}
	A single iteration may have millions of weight updates, but individual values are generally meaningless to the experts.
	Instead, the experts are more interested in the statistical information of these weights at different levels of detail (e.g., CONV layer level and filter level).
	All three experts emphasized the importance of intuitively and effectively examining general types of statistics, such as sum and variance, between these levels.
%	The layer-relevant information includes layer-level and filter-level statistical information. For the layer-level information, it contains various types of statistics, such as sum and var. All the experts emphasize the importance of using intuitive (i.e., easy to understand) visualization to show this different types of layer-level statistical information. %Further, due to the hierarchical structures on CONV layers, the experts demands to be able to see the aggregated. 
	Besides, \ea and \eb strongly desire to see the weight change degree for filters over iterations to identify which filters change dramatically at which iteration or how a filter changes across iterations.
	% identify the exact location of the current selected layer

%should be allowed to identify the specific value of a selected iteration, the trend over the entire training process, and positive and negative for a statistical information of a given layer. In addition, as there will be too many layers when using a very deep CNN (e.g., vgg-19 and resnet50),it is impossible to show all the layers directly. The system should provide a reasonable aggregation and interaction manner to allow the experts to explore the information they desired while not disturbed from other redundant information.\\
		
	\item \textbf{Comparing multiple layers}.
	All three experts like to compare layer-level statistical information. 
	For example, they want to know whether a specified measure of different layers show a similar trend or distribution (e.g., whether the sum is positive or negative).
	Accordingly, our visualization should also help these experts in performing such comparisons. 
	%Due to the great depth and the inner hierarchical structure of a very deep CNN (e.g., resnet50), the layer-relevant information. 
	%For example, the std of weight should be smaller for the layers with less neurons. Besides, knowing the differences and similarities among layers can help the experts gain more understanding about the function of layers.
		
	\item \textbf{Tracking the classification results of validation classes}.
	Validation is a critical step in the training process that ``test drives'' the trained CNN and tracks its performance change across iterations~\cite{bengio2012practical}.
	Previous tools only measure the global validation loss/error, thereby concealing the rich dynamics of how the image labels of each class change over time.
	%Previous tools only measure the global validation loss/error for comparison purposes.
	%Meanwhile, it also conceals the rich dynamics of how image labels of each class change over time.
	When the error rates do not reduce as expected, the experts find that such highly-aggregated information is useless and cannot help them understand why or when the training runs into a bottleneck.
	%Previous tools only provide the experts with high-level model performance information, namely, the validation loss and  error. It fails to disclose the detailed information about how the labels of images of each class change over the time. 
	Therefore, the experts want to know how the images of different classes behave differently and identify those classes that are easy or difficult to train.
	%Which classes of images are easy to identified correctly and which classes are difficult for classification. 

	\item \textbf{Detecting important iterations}.
	One complete training process usually contains millions of iterations, but it is obvious that not all iterations are equally important.	
	For example, some image classes may suddenly change their error rates after certain weight updates.
	The experts are interested in these patterns, which may help reveal in-depth relationships between filters and image features.
	However, the overall error rate trend does not help much, since it generally decreases slowly and steadily.
	Thus, the experts hope that our system can help them identify the abnormal iterations and the corresponding classes.
	
%	In the training process, although the overall accuracy to all images is always decreasing slowly and steadily, it does not hold true for the images of one class. The experts shows great interests on the iterations when the error of one or a set of classes may change significantly. The visual encoding should highlight these abnormal iterations and the corresponding classes.
	
	\item \textbf{Examining individual validation classes}.
	Our initial prototype shows that different classes clearly have different error rate evolution patterns. 
	%Thus, experts \eb and \ec are curious about those classes of poor performances, thereby desiring to further explore the image label information for these classes. 
	Thus, experts \eb and \ec are curious about those classes with very poor or excellent performance, thereby desiring to further explore the image label information for these classes. 
	For example, they want to see whether and why some images are always misclassified. 
	%such as what kind of images in this class are always labeled wrongly or rightly, which images are not in a stable status(i.e., sometimes labeled wrongly and sometimes labeled rightly), and what exactly happens in the detected important iteration.
	
	\item \textbf{Enabling correlation exploration}.
	Apart from analyzing the weight and validation data separately, the experts are also curious about their relational patterns.
	They are specifically interested in uncovering the relationships between the layers or filters and the validation images, such as how the changes in network parameters respond to the image labeling results for each class. 
	By connecting these two pieces of information together, they hope to gain fundamental insights into the behaviors of CNNs and to improve training results.
%	In particular, they want to figure out how the changes of network parameters respond to image labeling result for each class. They are especially interested in uncovering the relationships between the layers or filters and the images of each class. In other words, for a class of images, which layers or filters may have the greatest impacts on their labeling results.
%	Although the experts agree that analyzing the weight and validation data separately can offer the experts understanding about how a CNN is trained~\cite{bengio2012practical, rauber2017visualizing}, they show more interests on the correlation between the changes of layer-relevant statistical data and image labeling data, which is no studied in prior work. In particular, they want to figure out how the changes of network parameters respond to image labeling result for each class. They are especially interested in uncovering the relationships between the layers or filters and the images of each class. In other words, for a class of images, which layers or filters may have the greatest impacts on their labeling results.
\end{compactenum}%!TEX root = ../deeptracker.tex% !TeX spellcheck = en_US\section{System Overview}\label{sec:systemoverview}\begin{figure}[htp]
	\centering
	\includegraphics[width=0.8\columnwidth]{resources/system_overview}
	\vspace{0mm}
	\caption{Three components of \name. The raw data are preprocessed into a hierarchical structure and then stored into five application-specific data indexes to enable real-time interactions. On top of the efficient data storage, several visualizations are combined together to help experts with analysis tasks from different levels and perspectives.}
	\label{fig:system_overview}
	\vspace{0mm}
\end{figure}\name is a web-based application developed under the full-stack framework, MEAN.ts (i.e., MongoDB, Express, AngularJs, Node, and Typescript). The back-end part of our application is deployed in a server with 3.10GHz Intel Xeon E5-2687W CPU and 32GB memory. 

The architecture of our system (Fig.~\ref{fig:system_overview}) begins with the data processing part, where the entire training log is hierarchically organized, and several application-specific indexes are built to support real-time interactions.
On top of the efficient data storage, we build three coordinated views, namely, the Validation View, the Layer View, and the Correlation View, to support an interactive analysis from different levels and perspectives.
%The main interface consists of three views: a validation view, a layer view, and a correlation view. 
The Validation View aims at providing a visual summary of CNN performance on different validation classes. 
By combining our anomaly detection algorithm and small multiples, experts can easily identify different image class behavior patterns and critical iterations for each image class (\textbf{R3}, \textbf{R4}). 
Experts may also drill down to the class of interest to explore further image label information (\textbf{R5}).  
%By introducing a layout algorithm and a glyph visualization, experts can quickly identify different image class behavior patterns and critical iterations for each image class. %When experts select a class of interest, a pixel chart will be used to allow experts to track the classification result change for each image of this class over all iterations.
The Layer View aligns the weight information with the CNN structure to help experts explore various statistical information in the network hierarchy. 
Experts can further drill up or down in the network hierarchy to compare these measures at different levels of detail (\textbf{R1}, \textbf{R2}).
%When experts want to know more about one specific layer, a pixel chart here is provided to show a filter-level information.
The Correlation View presents a novel grid-based visualization method to provide an overview of the correlation between the image classification results and the neuron weights of each filter (\textbf{R6}).
\ti{
%The Correlation View should be used together with the other two views, composing a 2.5D cube, to add semantic meanings. 
The three views compose a cube, with which the experts can simultaneously explore the changes of class-level performances, the variations of filter-level weights, and the correlations between them.
}%After identifying several correlations of interest, the experts may further align these three views on a cube to compare these correlations in detail without frequently switching between views.%In addition, the three views can be combined into a 3D cube, with each face representing one view, thereby allowing users explore the correlations more conveniently without switching views frequently.\section{Data Acquisition and Construction}\label{sec:dataprocessing}%\dy{batch norm's parameters. There is no need to save norm, when tested, the network's norm values will be set to 0, do postbn first. As norm'values are only related to the input image volumes, useless.}%We worked closely with the experts and directly inserted source codes into their training programs to dump necessary information for analysis.	%As our focus is industry-level CNN training, we conduct our experiments with ResNet-50~\cite{he2016deep} and ImageNet Dataset~\cite{russakovsky2015imagenet}.\ti{
The primary motivation of this work is to monitor industry-level CNN training processes. Therefore, we conduct our experiments with ResNet-50~\cite{he2016deep} and ImageNet Dataset~\cite{russakovsky2015imagenet}.
ResNet-50, containing 50 weighted layers (i.e., CONV and FC layers), is among the most popular CNNs that have been recently used in practice and meanwhile ImageNet 2012 is also among the largest and most challenging publicly available datasets.  
The dataset includes $1,000$ classes of images, each class containing $1,300$ training images and $50$ validation images.
Training such a model needs around 120 epoches (nearly 1.2 millions iterations when batch size is 128) to achieve convergence.
Simply dumping all the information for every iteration can easily have the size of dumped data exceed several petabytes and take about 4 weeks. Through discussion, we all thought that $1,600$ is a reasonable interval to capture meaningful changes (about 7 times per epoch). This reduces the log to a manageable size (about 1TB).
}\ti{
For each dump, we recorded two pieces of information, namely, neuron weights/gradients of CONV layer and FC layer and image classification results. 
The parameters on BN layers were not recorded, as they can be totally recovered given the weights on CONV and FC layers and always need to be updated when applied in a new dataset.
Besides, we did not record the activations of each layer/filter for every validation image, as doing so is technically impracticable considering the extremely large models and datasets and the limited disk storage. Further, activation evolution visualization is beyond the research scope of this paper. 
Sec.~\ref{sec:conclusion} discusses activation visualization is indeed a perfect complementary technique to our work.
}% However, Besides, as we have already dumped all the necessary weights, one can easily recover the entire network at certain dumped iteration and then generate the corresponding activations of the images of interest to conduct further analysis (see the discussion of future work in Sec.~\ref{sec:conclusion}).%Although some CNNs, such as ResNet, contain batch normalization layer (BN layer), the experts think it is unnecessary to record and analyze such information, because the parameters on BN layers can be recomputed given the weights on CONV and FC layers and part of the input images for current testing dataset.%In all, there are 1.3 million training images and $50,000$ validation images.%, and ImageNet 2012 is also one of the benchmark and challenging datasets%As the experts emphasize the importance of working in practical environment (i.e., train a large CNN on very large scale dataset). Thus, suggested by the experts, we mainly trained resnet-50~\cite{he2016deep}, one of the default choice for using CNN in practice with 50 layers~\cite{cs231n}, on the ImageNet 2012~\cite{russakovsky2015imagenet} dataset. The dataset has 1000 classes of images, each containing $1,300$ high-resolution training images and $50$ validation images respectively. In all, there are 1.3 million training images and $50,000$ validation images.%During the experiments, we found that dumping the information at each iteration can easily increase the overall training time at least by one order of magnitude (about 3-4 weeks without dump operation when training the model on a machine with 4 TITAN X GPUs) and require several petabytes to store one complete training log, both of which are unrealistic and unnecessary in practice.%After discussing with the experts, we increased the dumping interval to $1,600$ iterations.%Since each training in our experiments requires about 1.2 million iterations (In our basic setting, the mini-batch size is 32 for one GPU and the total batch size is $32*4=128$ due to the use of four GPUs), $1,600$ is considered a reasonable interval to capture meaningful changes (about 7 times per epoch) and to reduce the log to a manageable size (around 1TB per complete training). We have carried out several times of experiments with different batch size and learning rate settings.%as the parameters of BN layers totally depends on the current weights of network.%The whole network can be safely recovered only knowing the weights of CONV and FC layers, as the parameters of BN layers can be computed with the weights on CONV and FC layers and the input images.%After discussing with the experts, we identify two fundamental yet critical pieces of information in the training process, namely, the layer-relevant weight/gradient information and image classification results for each class at every iteration. Considering the huge data scalability if all the parameters and image information are dumped for all iterations, we use downsampling on the raw data and only record information at prepicked iterations. %In our case, we record data nearly seven times per epoch (i.e., 1600 iterations when batch size is 128) and there are totally 120 epochs. Even sampling is applied, the raw data (billions of parameters) still easily exceed a couple of tera-bytes for each training. To preprocess such amount of data and organize it in a hierarchical manner to support out analytical tasks. There are two types of hierarchy structures related to layer information and image classification information, respectively. 
We organized the weight/gradient information according to the natural hierarchial structure of ResNet-50. It consists of four \textit{CONV modules} (plus the first CONV layer and the final FC layer, there are 50 layers in total). Each module contains several \textit{bottleneck blocks}~\cite{he2016deep} that comprise three to four basic CONV layers (data storage in Fig.~\ref{fig:system_overview}).
Thus, we grouped all neuron weights to align with such hierarchy.
\ti{
In a similar manner, we organized the classification results hierarchically from individual level, class level, to model level.
We stored all the data into MongoDB\footnote{MongoDB is a free and open-source cross-platform document-oriented (NoSql) database. \url{www.mongodb.com}}.
In particular, we precomputed all the relevant aggregation values, such as weight means and error rates, for each filter, layer, image, and class.
Nevertheless, the distilled data still remain too large to load into memories (about dozens of gigabytes per training).
Therefore, we analyzed the frequent needs of the experts and built several indexes to enable real-time interactions, including Layer-Stat index $I_{ls}$, Layer-Filter index $I_{lf}$, Iter-Filter index $I_{if}$, Cls-Stat index $I_{cs}$, and Cls-Image index $I_{ci}$.
\begin{compactitem}
	\item $I_{ls}$ retrieves the statistic values (e.g., mean and sd) at every iterations for any given layer;
	\item $I_{lf}$ lists all the filter-level information (e.g., changing degree of each filter) at every iterations for any given layer;
	\item $I_{if}$ searches the top changing filters from all layers at any given iteration;
	\item $I_{cs}$ extracts class-level information (e.g., class performances, the different types of abnormal images~Sec.~\ref{sec:anomaly}) over all iterations for any given class;
	\item $I_{ci}$ fetches the meta-data of images for any given classes.
\end{compactitem}
}%\textbf{Layer-Stat Index $I_{ls}$}. The weights on a layer can be seen as a vector $\theta$, which can be summarized in various ways, such as sum, sd, and mean magnitude (the average of the absolute value of each weight).%For any type of statistic, with the index $I_{ls}$, we can quickly retrieve the statistic values over all $n$ iterations of a layer $L_i$ as \{{$L_i$} $\mid$ $s_1, ..., s_n$ \}. %Notice $s_j$ is an object that stores each type of statistic of the weights of layer $L_i$ at iteration $j$. %\textbf{Layer-Filter Index $I_{lf}$}. This is the second level of index to help our system locate the filters inside a layer. The weights of each filter are treated as a vector $\beta$. %In practice, the experts are more interested in how the weights in a filter differ from the previous iteration. In this end, many vector similarity measurement can be used, such as Euclidean distance, Manhattan distance, and cosine similarity.%For each type of measurement, each entry in $I_{lf}$ lists all the distance measures of all filters in layer $L_i$ over all $n$ iterations, that is, \{{$L_i$} $\mid$ $f_{i1}, ..., f_{in}, f_{j1}, ...$ \}.%\textbf{Iter-Filter Index $I_{if}$}. Unlike $I_{lf}$, $I_{if}$ retrieves all filters in all layers at a specific iteration \{{$I_i$} $\mid$ $f_{ji}, f_{ki}, ...$ \}. This index is built to identify which filters have changed the most at the several iterations of interest.%\textbf{Cls-Stat Index $I_{cs}$}. Similar to layer-stat index $I_{ls}$, each entry $I_{cs}[c_i]$ in this index stores all the class-relevant information of a given class over all the $n$ iterations, such as error rate and different types of abnormal image numbers (Sec.~\ref{sec:anomaly}). For a specific type of class-relevant information, one can easily obtain the value of a specified type of an image class through \{{$C_i$} $\mid$ $s_1, ..., s_n$ \}. %\textbf{Cls-Image Index $I_{ci}$}. This index allows a quick retrieval of image-relevant information, including image file name, original label, and the computed classification results (i.e., computed labels) on all $n$ iterations, by a specific class name.%For the layer information, there are several levels of details due to the natural design methodology of very deep CNNs. In our case (i.e., resnet-50), there are five big CONV layers, each includes many ``bottleneck block''~\cite{he2016deep} (another popular kind of similar structure is called ``inception block'' used in google-inception-v4~\cite{szegedy2016inception}) that consists of 3 or 4 elementary CONV layers (as mentioned in Sec.~\ref{sec:background}). Requested by the experts, we compute the statistical information of high-level layers by aggregating all the contained elementary CONV layers to allow the experts to compare the information from different aggregation levels, which is never done in prior work. Besides, for each elementary layer, the information about filters in it is also significant and is also stored. %Then, we recorded the classification result and correctness of each validation image in each dump.%Afterward, we aggregated the information for each class and over all iterations for individual images.%All raw data were preprocessed and stored into MongoDB\footnote{MongoDB is a free and open-source cross-platform document-oriented (NoSql) database. \url{www.mongodb.com}}. In particular, we precomputed all the relevant aggregation values, such as weight means and error rates, for each filter, layer, image, and class. These values were packed together based on their types and positions in the network hierarchy. %For example, all the label information regarding the images of one class were packed as a \textit{document} (the basic storage unit in MongoDB) and all these documents were further combined as a \textit{collection} (a higher level of storage unit in MongoDB). A similar method was employed to handle the network parameter information which has four levels (from the CONV module level to the filter level).%\ww{talk more about the mango storage, otherwise, it will sound trival. People may think it as simple as clicking a button in SQL.}%For the classification information, for each image at one iteration, we have an output 1000-dimension-vector, each dimension representing the probability of the image belonging to a corresponding class. The CNN chooses the one with the highest probability as the classification result. In contract to the previous tools, which only record one value indicating the overall error rate for all images in $D_v$ (model level), we further store the error rates for each class (class level) and record the labeling information over time for all images (image level). Besides, to support the real-time interactions, we build the following application-specific indexes.%\ww{when when feeding a image, we have a output of vector with length = 1000, representing 1000 classes of image, each bit represents the probability of the image belonging to that class, and the system chooses the one with the highest score as the classification result. we compare the result with its know label, if match, so it is accurate, if not, so it is wrong. then for each image, at each iteration, we have a true/false value. then we can collect a sequence of true/false representing the validation history of that particular image... for the gradient history, you need to do the same. }%\ww{maybe we only say two categories, consistent with sec 2 and easy to remember, and if needed, you can give a sentence or two in the system overview or case study, just saying, requested by the experts, we also put the common overall loss/error curves that are also commonly seen in many online visualizations like xxxx. move arguments from sec 2 here. keep sec 2 dry and objective. We explain two types of log data and argue their importance here.}%\textbf{Layer-Stat Index $I_{ls}$}. The weights on a layer can be seen as a vector $\theta$, which can be summarized in various ways, such as sum, std, mean magnitude (the average of the absolute value of each weight).%For any type of statistic, with the index $I_{ls}$, we can quickly retrieve the statistic values over all the $n$ iterations of a layer $L_i$ (\textbf{R1, R2}), namely, \{\underline{$L_i$} $\mid$ $s_1, ..., s_n$ \}. %Notice $s_j$ is an object that stores each type of statistic of the weights of layer $L_i$ at iteration $j$. %%\textbf{Layer-Filter Index $I_{lf}$}. This is the second level index to help our system locate filters inside a layer. The weights of each filter are treated as a vector $\beta$ too. %In practice, the experts are more interested in how the weights in a filter differs from the previous iteration. In this case, many vector similarity measurement can be used, such as Euclidean distance, Manhattan distance, and cosine similarity.%Thus, for each given type of measurement, each entry in $I_{lf}$ lists all distance measures of all filters in layer $L_i$ over all the $n$ iterations (\textbf{R1, R2, R6}), that is, \{\underline{$L_i$} $\mid$ $f_{i1}, ..., f_{in}, f_{j1}, ...$ \}.%%\textbf{Iter-Filter Index, $I_{if}$}. Different from the index $I_{lf}$, the iter-filter index $I_{if}$ retrieves all the filters in all layers at a given iteration \{\underline{$I_i$} $\mid$ $f_{ji}, f_{ki}, ...$ \}. This index is built to search which filters change most hugely at the several iterations of interest (\textbf{R4, R6}).%%\textbf{Cls-Stat Index, $I_{cs}$}. Similar to the layer-stat index $I_{ls}$, each entry $I_{cs}[c_i]$ in this index stores all the class-relevant information (\textbf{R3}) of a given class over all the $n$ iterations, such as error rate, different types of abnormal image numbers (\textbf{R4}, Sec.~\ref{sec:anomaly}). For a given type of class-relevant information, one can easily obtain the value of the specified type of a image class through \{\underline{$C_i$} $\mid$ $s_1, ..., s_n$ \}. %%\textbf{Cls-Image, $I_{ci}$}. This index allows quickly retrieving the image-relevant information (\textbf{R5}) including image file name, original label, and the computed classification results (i.e., computed labels) on all the $n$ iterations, by given a class name.%std (standard deviation), var (variance), distribution related information (i.e., min, one quarter, mean, three quarter, max), %mean magnitude (the average of the absolute value of the parameters), the ratio of mean magnitude.%!TEX root = ../deeptracker.tex% !TeX spellcheck = en_US\section{Visualization}\label{sec:visualization}

In this section, we describe our three coordinate views, namely, the Validation View, the Layer View, and the Correlation View, that help experts accomplish the aforementioned analytical tasks.

\subsection{Validation View}
Several urgent requirements (\textbf{R3}, \textbf{R4}, \textbf{R5}) from the experts need to examine how the evolving CNN acts differently on the validation images of each class rather than how the overall validation error rate differs over training.
Thus, we design the Validation View (Fig.~\ref{fig:case1-2}\&\ref{fig:case1}) to present all image classes in $D_v$.
%By default, this view  provides a visual summary of the performances of individual validation classes over the training process (\textbf{R3}).%Therefore, the experts can easily identify those classes that show similar performance trends (\textbf{R3}).%To provide more details (\textbf{R5}), a pixel-based visualization method and an anomaly detection algorithm are proposed to show the evolving classification results of every image (Fig.~\ref{fig:case1}d) and to help users explore the iterations of interest (\textbf{R4}), respectively.%With our anomaly detection algorithm, we highlight the iterations of interest on the color stripes with glyphs to help%In addition, we also introduce an outlier detection algorithm, combined with a glyph to highlight the iterations that the experts may interested in (\textbf{R4}).%Specifically, this view allows experts to explore the overall performance of all image classes\begin{figure}[htbp]
	\centering
	%\includegraphics[width=0.95\columnwidth]{resources/case1-2}
	\includegraphics[width=0.95\columnwidth]{resources/tist_cluster}
	\vspace{-2mm}
	\caption{From top (a) to bottom (b), image classes are more and more difficult to train.}
	\label{fig:case1-2}
	\vspace{-4mm}
\end{figure}\subsubsection{Visual Encoding}\label{sec:validation_view_encode}%The validation view based on a horizontal small multiples allows users to obtain a quick overview of each class performance and make comparison among them.\ti{By default, the view starts with a visualization of \textbf{cluster-level} performance (\textbf{R3}).
The classes with similar evolving trends form a cluster and then their error rates at every iteration are averaged.
The averaged error rates are then depicted as a colored stripe, where the x-axis encodes the iterations and the error rates are encoded by colors (Fig.~\ref{fig:case1-2}).
We choose k-means as the clustering algorithm and $k$ can be adjusted according to demands (Fig.~\ref{fig:case1-2} shows the case when $k=4$).
Experts can open up one cluster to further examine the performance in \textbf{class-level} (\textbf{R3}). 
The design is based on the following considerations.
First, the experts are more interested in the overall classes than in individual iterations.
%We have several design considerations that drive us to design this overview like so: 1. the experts care more about overview comparison among classes and pay less attention to the local values at one iteration,
Thus, small multiples technique (juxtaposed techniques) is chosen for their superior performance in high-level comparison tasks (e.g., global trends for every series)~\cite{javed2010graphical}.
Second, we cannot present all the classes ($1,000$ in ImageNet) at one time, we have to consider a hierarchical and highly space-efficient visualization.
However, many traditional charts, such as line charts and horizon graphs, require a larger vertical space~\cite{heer2009sizing} than 1D heatmaps.
Compared with traditional charts, heatmaps are also more easy to do side by side comparison for their symmetrical space (i.e., no irregular white spaces).
As a result, all experts prefer the heatmap-based small multiples.}%By explaining each chart's strengths and weakness to the experts, we finally%thereby facilitating their comparison. We present the experts with some design alternatives, such as filled line charts and horizon graphs, and explain to them their relative strengths and weaknesses. All experts prefer the heatmap-based small multiples.%\textbf{Class-level performances}. By default, the Validation View presents an overview of how the performances (i.e., error rates) of validation classes evolve over training.%Each class is depicted as a colored stripe. The x-axis encodes the iterations and the error rates are encoded by colors (Fig.~\ref{fig:case1-2}) to enable experts to compare and obtain a quick overview of all performances (\textbf{R3}).%Each class has its own time series, thus small multiples~\cite{javed2010graphical} are used to show all classes, each series represented by a heatmap chart.%The heatmap can be viewed as $n$ (i.e., the number of dumped iterations) rectangles of a fixed height and one pixel width. The error rate at iteration $i$ is encoded by the color on $ith$ rectangle, where the diverging color from green to red is used with the deep red indicating a high error rate.%In addition, to help experts examine classes in groups, we utilize Multidimensional Scaling (MDS)~\cite{kruskal1964nonmetric} to ensure that classes with similar evolving patterns are placed close.%Besides, since the experts not only want to see one class performance changes over time but also desire to explore the relationships among different classes (R.3), we further utilize the vertical position channel to encode this type of information.%To this end, for a class $C_i$, its error rates at each iteration can be views as a vector [$er_1, er_2, ..., er_n$], where each bit is a real number ranging from 0 to 1.%Then, we can compute the cosine similarities among different classes and utilize Multidimensional Scaling (MDS)~\cite{kruskal1964nonmetric} to create the layout.%MDS is a well-established dimension reduction method which is good at preserve global structure than other methods. In our case, we use MDS to project all the high dimension class vectors onto a 1D value $c_i$ and then sort the vertical positions of each class according to the size of value $c_i$. In the resulting layout, thereafter, the classes of a similar performance evolution trend will stay more closer globally.%\textbf{Design Consideration}.\textbf{Image-level performances, R5}. The class-level color strips can be further unfolded to explore the image-level evolution patterns.
Unfolding a heatmap reveals a pixel chart (Fig.~\ref{fig:case1}d), with each row (1px height) representing an image and each column (1px width) representing an dumped iteration (consistent with the class heatmap).
We use red and green colors to indicate the incorrect and correct classifications, respectively.
Meanwhile, the experts can zoom/pan the pixel chart for a closer inspection. Clicking on a row shows the original corresponding image.

\textbf{Anomaly iterations, R4}. \ti{As experts are concerned about the iterations with abnormal behaviors, we particularly propose a algorithm to detect these anomaly iterations (refer to Sec.~\ref{sec:anomaly}).
Experts can choose to only show the classes with anomaly iterations (Fig.~\ref{fig:case1}).
At this point, for each class-level color stripe, we use triangular glyphs to highlight these detected anomaly iterations.
The upside-down triangles ($\bigtriangledown$) and normal triangles ($\triangle$) indicate those anomaly iterations that are detected by the left-rule and right-rule, respectively.
The widths of triangles encode the anomaly scores. 
Experts can set a threshold value to filter the triangles with low anomaly scores.}\subsubsection{Anomaly Detection}\label{sec:anomaly}%have been proposed for a variety of analytical tasks, such as system diagnosis and biological engineering.  Markov is treated as a box. Considering the special application scenario, the rule-based model is more favorable.
In our scenario, the classification results for an image can be represented by a 0/1 sequence ($[a_1, ..., a_n]$), where each element represents a correct or incorrect result at the corresponding validation iteration.
The experts are curious about the iterations when a significant amount of 1/0 flips (i.e., 0 to 1 or 1 to 0) occur for a class.
In general, this problem can be modeled and solved using Markovian-based anomaly detection algorithms~\cite{aggarwal2015outlier}.
%Thus, the Markovian-based anomaly detection algorithms~\cite{aggarwal2015outlier} for discrete sequences can be considered.%As our purpose is to find special iterations, the algorithms for detecting position outliers are our targets.%In position-based outliers, the values at specific positions are predicted by a model, which conforms with our needs.
Despite the popularity of using Markovian methods to detect outliers in discrete sequence, we decide to employ rule-based models~\cite{aggarwal2015outlier} for two reasons.
First, Markovian methods are a black box and the resulting outlier values are sometimes difficult to comprehend. Second, the experts have explicitly described two types of iterations they are very interested in, namely, those iterations when many images with values that remain stable for many previous iterations suddenly flip (denoted by the \textit{left-rule}) and those iterations when many images flip and keep their values stable after many iterations (denoted by the \textit{right-rule}).
Fortunately, these anomalies can be easily modeled using rules.
The rule-based models primarily estimate the value $P(a_i|a_{i-k},\ldots,a_{i-1})$, which can be expressed in the following rule form: $ a_{i-k},\ldots,a_{i-1} \Rightarrow a_{i}.$
In our scenario, if an image has the same value (either 0 or 1) in the previous consecutive $k$ iterations ($i-k,\ldots, i-1$), then its value must be the same at iteration $i$ (the left-rule).
Otherwise, iteration $i$ is considered an outlier for the specified image.
Based on these considerations, we develop an application-specific algorithm to detect anomaly iterations in the validation history. The algorithm includes the following steps:
%To evaluate the anomaly score for each iteration of one specified class with $m$ images, the pipeline follows two major steps:\begin{compactenum}
\item{\textbf{Rule-Judgement}:} ~The algorithm computes a vector $[l_{i1}, \ldots, l_{in}]$ for every image $i$, where $l_{ij} =1$ if the left-rule is satisfied, otherwise, $l_{ij} =0$;% is judged by checking whether left-rule at iteration $j$ is satisfied. If satisfied, $l_{ij} = 1$ and otherwise $l_{ij} = 0$.

\item{\textbf{Aggregation}:} ~For each class that contains $m$ images, the algorithm aggregates all the computed vectors for each image into one $[L_1, ..., L_n]$, where $L_j = \sum_{i=1}^{m}l_{ij}$, \ti{denoting the left anomaly score at iteration $j$ for this class.}
\end{compactenum}The approach is a window-based method, and the experts can adjust the window size $k$ to control the sensitivity of the anomalies.
In a similar manner, we detect the anomalies from the opposite direction for the right-rule.
%To best fit the time scale of our analysis, the window size $k$ and the detection threshold $th$) were all manually selected.%Many general anomaly detection algorithms can be applied to detect the outlier values at the time stamps are%Many automatic outlier detection algorithms~\cite{aggarwal2015outlier} can be applied to our scenarios.However, considering the special application environment, we propose a application-specific outlier detection algorithm inspired from window-based xxx methods. To ..\subsection{Layer View}

The Layer View focuses on weight-related tasks (\textbf{R1}, \textbf{R2}).
The view consists of two connected parts, namely, the CNN structure and the hierarchical small multiples (Fig.~\ref{fig:layer_view_illustrator}), so that experts can hierarchically explore and compare various types of statistic in the context of the network structure.

%obtain an overview insights on the positions of the layers of interests in the entire network structures, when exploring and comparing the rich dynamics of these layers.\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.95\columnwidth]{resources/layer_view_illustrator}
	\vspace{-2mm}
	\caption{Visual encodings in the Layer View: (a) a CONV layer, (b,d) hierarchical bars, (c) links between the CNN structure and (e) the hierarchical small multiple charts, (f) a pixel chart for one layer.}
	\label{fig:layer_view_illustrator}
	%\vspace{-4mm}
\end{figure}\textbf{CNN structure}.
%Previous tools like TensorBoard explicitly provide experts with a network visualization of CNN structures.%The experts often refer to the visualization to examine the connections between different layers.%Thus, they also hope our tool can use a similar visualization to help them explore the statistical information of each layer and know their relative positions in the entire network (\textbf{R1}).%The experts request that the familiar and intuitive visualization of network graph should be used. Suggested by the experts, we adapt Netscope, one of the popular network structure visualization tools, for our scenario.
The experts hope our tool can help them explore the statistical information of each layer and meanwhile know their relative positions in the entire network (\textbf{R1}).
Thus, we adopt Netscope\footnote{Netscope is a web-based tool for visualizing neural network architectures. \url{http://ethereon.github.io/netscope/}}, a popular neural network visualizer, in our system.
\ti{
The green rectangle is data input layer, the red ones are the CONV layers, and the purple ones mean the pooling layers.
The links between these rectangles show the network structure.
We further add blue level bars (Fig.~\ref{fig:layer_view_illustrator}b) to encode the latent hierarchy (from CONV modules, bottlenecks to basic CONV layers, Sec.~\ref{sec:dataprocessing}).
}
The right most level bars represent CONV modules (Sec.~\ref{sec:systemoverview}), which are recursively divided into smaller level bars until reaching elementary CONV layers (i.e., red rectangles).
%In the graph, rectangles of different colors represent different types of layers (green for data input, red for CONV layer, deep red for FC layer, and orange for others). The layout and connections between rectangles reveal the whole network structures. Different from Netscope-style, we further add blue bars to encode the latent hierarchical information that are never shown before in previous similar tools. The rightest bars show a big CONV (Sec.~\ref{sec:systemoverview}), which can be further divided into small bars representing bottleneck block. The smallest bars are attached on the right side ot each elementary CONV layer (i.e., red rectangles).%The highlighted bars and blue linking edges interact with the small multiple charts on the right side, visualizing the relationships between each small multiple chart and each red rectangle.\textbf{Hierarchical small multiples}.
%With the increasing of the number of layers, it is impossible for the experts to manually add charts one by one to watch a given type of statistical information of one layer just the same with TensorBoard does.
To assist experts in exploring and comparing layers of a deep CNN (\textbf{R1, R2}), a space-efficient visualization technique is demanded.
Thus, we leverage hierarchical small multiples to show layers of interest (Fig.~\ref{fig:layer_view_illustrator}e).
\ti{By default, experts are presented with the information about CONV modules and then can drill down to see more information about low-level CONV layers with interactions with the network graph (i.e., click on the corresponding level bars).
The width of outcropping rectangles (Fig.~\ref{fig:layer_view_illustrator}d) encodes the aggregation level of current layer charts. For example, the top second layer chart in (Fig.~\ref{fig:layer_view_illustrator}e) shows the bottleneck-level aggregation information and the following three layer charts show the basic CONV layer level information. Besides, the links (Fig.~\ref{fig:layer_view_illustrator}c) mark the real positions of the layer charts in the network structure.
%One can click on the level bars (Fig.~\ref{fig:layer_view_illustrator}b) to open up corresponding level layer charts.  
}

The small multiples support multiple types of charts including line chart, horizon graphs~\cite{heer2010tour} and box plots to emphasize the different aspects of the statistical data.
The experts use box-plots to see the rough distribution of statistical values and use basic line charts to examine individual values. Besides, the experts prefer to use horizon graphs when performing tasks in regard to trend tracking and comparison (\textbf{R2}), because of its effectiveness in visualizing divergent weight values~\cite{javed2010graphical}.
% and easily discerning positive and negative values that have different meanings for neurons' weights.
Similar to unfolding the class heatmap to a pixel chart, the experts are also allowed to open the layers of interest as a pixel chart (Fig.~\ref{fig:layer_view_illustrator}f) that presents the filter-level information (\textbf{R1}). Each row (1px height) in the pixel chart represents one filter, and each column (1px width) indicates one iteration. We use sequential colors to encode pixel value (e.g., the cosine similarity between two subsequent dumped iterations).
%\ti{By default, all the filters in one layer are displayed for easy comparison. But when layer view is used as the front view in cube (Sec.\ref{sec:cubeview}), only the filters that are among top-k changing filters}%\ti{%In normal case, it shows all the filters in a layer because %}%As with the pixel chart for image classes, this pixel chart supports horizon and vertical zoom.%Thus, in this view, we leverage small multiple to show the information of the layers of interests.%After showing various types of time-series charts to the experts, we finally integrate three types of chart, including line chart, box-plot, and horizon graph. Line chart allows the experts to explore the statistics (e.g., sum, std) for one layer in detail, such as identifying a value in one iteration (\textbf{R1}). Box-plot can be used to show the distribution statistical values (i.e., [min, one quarter, mean, three quarter, max]). Horizon graph is the one favored by the experts most and mainly used to carry out tasks like trend tracking and comparison (\textbf{R2}), due to its highly space-efficient property~\cite{heer2009sizing}, superior in disperse tasks (trend comparison)~\cite{javed2010graphical} and easily discerning positive and negative values that have different meanings for neurons' weights.%Furthermore, owing to the hierarchy property of current large CNNs (Sec.\ref{sec:dataprocessing}), the experts desire to know the difference between more high-level CONV layers. Thus, the small multiples are shown in hierarchical manner. One advantage of this manner is providing more detailed low-level information and preserve the context information in the meanwhile. The other strength is preventing to show too much information in the beginning that may trouble the experts in having no idea about where to see. In addition, similar to unfolding the class heatmap to a pixel chart, the experts are also allowed to open layers of interests as a pixel chart, which shows the filter-level information (\textbf{R1}).Each row (1px height) in the pixel chart represents one filter and each column indicate iteration (1px width). As with the pixel chart for image classes, this pixel chart supports horizon and vertical zoom.%\tii{only activate the layers with anomaly filters. Refer to cube view. Mark anomaly filters globally, dashed vertical line to reminds the positions.}\subsection{Correlation View}\label{sec:correlation}%\begin{figure}[htbp]%	\centering%	\includegraphics[width=0.48\textwidth]{resources/correlation_view.jpg}%	\caption{Alternative Design}%	\label{fig:correlation_view}%	%\vspace{-2mm}%\end{figure}This view  helps experts establish connections between the filters and images.
In particular, the experts want to understand further how the changes in network parameters are related to class performances (\textbf{R6}).
%In particular, they want to know the relationships between the layers or filters and the classes.
For example, several anomaly iterations may be detected for a single class.
For each detected anomaly iteration, we can identify a set of \textit{anomaly filters} (i.e., the top $k$ filters with largest changes at that iteration).
Since different classes may share anomaly iterations and different anomaly iterations may share anomaly filters, are there any filters that are commonly seen in these iterations?
Do any of the anomaly classes or filters strongly co-occur?
%For example, which filters are changed the most for each of the identified anomaly iterations, or whether there are occurred changes of classes or filters.%for the class, which layers these filters belong to, and are there other classes having the same filters  that change most hugely at their abnormal iterations.
We designed the Correlation View to answer these questions.
%\ti{Note that this view have to be used with the aforementioned two views to add semantic meaning, that is, stitching three views as a 2.5D cube (refer to Sec.\ref{sec:cubeview}).}%\vspace{-3mm}%\begin{spacing}{0.5}%{\fontsize{10}{10}\selectfont%\begin{algorithm}[!htb]%	\caption{Set Partition} \label{alg:setsplit}%	\small%	to do%	\begin{algorithmic}[1]%		\Statex {\bf Function} Partition( Target set $S_{target}$)%		\State $S_{result}$ := $\emptyset$%		\For{each target set $s_t$ in $S_{target}$}%		\State $S_{new}$ := $\emptyset$%		\For{each mini set $s_r$ in $S_{result}$}%		\State $itersection$ := $s_t \bigcap s_r$%		\State $S_{new}$ := $S_{new} \bigcup intersection \bigcup (s_r - s_t)$   \label{alg:set:split}%		\State $s_t$ := $s_t - s_r$%		\EndFor%		\If {$s_t$ is not empty} $S_{new} \bigcup s_t$    \label{alg:set:addremain}%		\EndIf%		\State remove all empty set in $S_{new}$%		\State $S_{result}$ := $S_{new}$%		\EndFor%		\State {\bf return} $S_{result}$ %\label{alg:klocations:return}%	\end{algorithmic}%\end{algorithm}% Algorithm\begin{algorithm}[t]
	\SetAlgoNoLine
	\KwIn{Target set $S_{target}$.}
	\KwOut{Minimum partition for $S_{target}$.}
	$S_{result}$ = $\emptyset$\;
	\For{each target set $s_t$ in $S_{target}$}{
		$S_{new}$ = $\emptyset$\;
		\For{each mini set $s_r$ in $S_{result}$}{
			$itersection$ = $s_t \bigcap s_r$\;
			$S_{new}$ = $S_{new} \bigcup intersection \bigcup (s_r - s_t)$   \label{alg:setsplit:split}\;
			$s_t$ = $s_t - s_r$\;
		}
		\If{$s_t$ is not empty}{
			 $S_{new} \bigcup s_t$\;    \label{alg:set:addremain}
		}
		remove all empty set in $S_{new}$\;
		$S_{result}$ = $S_{new}$\;
	}{\bf return} $S_{result}$ \label{alg:setsplit:return}

\caption{Minimum Set Partition}
\label{alg:setsplit}
\end{algorithm}%\setlength{\textfloatsep}{5pt}%}%\end{spacing}%\vspace{-3mm}\textbf{Filter set partition}.
We first introduce the \textit{mini-set} concept to organize anomaly filters that are shared by multiple anomaly iterations and different classes.
For each class $C_i\in\{C_i|{1\leq i \leq n}\}$, we denote its anomaly iterations by $T_i = \{t_{i,k}|{1\leq k\leq n_i}\}$.
Thus, all anomaly iterations are $\cup_{1\leq i \leq n}T_i$, denoted by $T$.
For each anomaly iteration $t\in T$, we denote its anomaly filters at CNN layer $L_j\in\{L_j|{1\leq j \leq m}\}$ by $s_{j,t}$.
Thus, for each layer $L_j$, we can collect all anomaly filter sets $\{s_{j,t}|t\in T\}$ (denoted by $S_j$)  and all anomaly filters $\cup_{t\in T}s_{j,t}$ (denoted by $s_{j}$).
Thus, mini-set aims to find a minimum set partitions of $s_{j}$ (denoted by $s_j^\ast$) that each $s_{j,t}$ can be assembled from some elements (i.e., mini-sets) in $s_j^\ast$.
%Since an anomaly filter can belong to any number of these mini-sets, we define weights for each mini-set as the times of this mini-set used to assemble all $s_{j,t}$ multiplies the size of the mini-set (i.e., contained number of filters). The defined weight of each mini-set reveals the strength of relationships among filters, classes, and anomaly iterations.
We specifically propose a Set Partition Algorithm (Alg.~\ref{alg:setsplit}) to find $s_j^\ast$.
The algorithm accepts a target set as input (i.e., $S_j$). $S_{result}$ is initially empty and a new anomaly filter set is used at each time to partition the mini-sets contained in $S_{result}$ (cf. lines~4 to 7). If the new anomaly filter set is not empty after partitioning, then it is added as a new mini-set (cf. line~8). Finally, the partitions contained in $S_{result}$ will be returned.

\begin{figure}[t]
	\centering
	\includegraphics[width=1\columnwidth]{resources/correlation_view}
	\caption{ (a) The abstract version of correlation view, where rows and columns represent layers and image classes, respectively. A sequential color scheme is used to encode the number of anomaly filters. (b) The complex version of correlation view, where the detailed information of individual anomaly filters are shown. (c) A layout solution for coordinated analysis without using skewed axes. }
	\label{fig:correlation_view}
	%\vspace{-2mm}
\end{figure}%(cf. line~\ref{alg:klocations:7})%, can help experts discover strong relationships between layers, classes, and anomaly iterations. \ww{mention alg 1}%To construct the Correlation View, we first introduce a concept of \textit{mini-set}.%Correlation matrix provides an overview for exploring the relationships between the layers or filters and the classes. To identify which filters in one layer change most hugely for many different identified abnormal iterations of some classes. Here we first introduce a concept \textit{mini-set}. For each abnormal iteration of each class, we denote the set of filters in layer $L_i$ that change most hugely as $s_{t_j}$. Our purpose is to find minimum number of exclusive sets of filters, with which each $s_{t_j}$ can be assembled. For example, there are three sets, $[1,2,3]$, $[1,2]$, and $[3]$. Thus, the minimum number of exclusive sets should be 2, that is, $[1,2]$ and $[3]$, as all the three sets can be represented as union of some of them. These exclusive sets are denoted as mini-sets.\textbf{Visual encoding.}
To intuitively represent these relationships, we introduce a grid-style visualization (Fig.~\ref{fig:correlation_view}), where rows and columns represent layers and image classes, respectively. The number of rows and columns equal to the number of layers with anomaly filters and classes with anomaly iterations, respectively.
\ti{
We start from a abstract version.
In this version (Fig.~\ref{fig:correlation_view}a), for $\mathrm{Cell}_{i,j}$, a sequential color scheme is used to encode the number of anomaly filters ($\cup_{t\in T_j}s_{i,t}$). 
The darker the color it is, the more anomaly filters appear in layer $L_i$ that are related to class $C_i$.
%Meanwhile, we use the size of inside rectangles as a double encoding to represent the anomaly filter numbers.
From this visualization, we can easily observe the correlations between layers and classes, while it also hides much detailed information.
We cannot answer questions like whether the filters in $\mathrm{Cell}_{i,j}$ are the same with $\mathrm{Cell}_{i,k}$ (this kind of information shows how many classes this filter can impact and help examine the relationships among classes), or whether there are filters in $\mathrm{Cell}_{i,j}$ appearing in more than one anomaly iteration (this shows the importance of these filters for class $C_j$).
}

To solve these problems, we provide an advanced version (Fig.~\ref{fig:correlation_view}b).
For $\mathrm{Cell}_{i,j}$, the width and height encode the number of anomaly iterations and the number of anomaly filters of the corresponding class and layer (i.e., $|T_j|$ and $|s_{i}|$), respectively.
%In this visualization (Fig.~\ref{fig:correlation_view}a), rows and columns represent layers and image classes, respectively.%For each cell in the grid (e.g., $\mathrm{Cell}_{i,j}$), the width and height encode the number of anomaly iterations and the number of anomaly filters of the corresponding class and layer (i.e., $|T_j|$ and $|s_{i}|$), respectively.
Based on these numbers, the columns and rows are further divided with vertical/horizontal lines.
For a class (e.g., $\mathrm{Column}_{j}$), $|T_j|$ vertical lines are drawn to represent all related anomaly iterations (i.e., $[t_{j,1}, t_{j,2},\ldots,t_{j,n_j}]$).
For each row of layer $L_i$, there are  $|s_i^\ast|$ horizontal lines representing all mini-sets in that layer.
The intersections between these horizontal and vertical lines are highlighted with blue rectangles if the corresponding mini-set is part of the anomaly filters of the corresponding anomaly iteration.
The height of the rectangles represents the number of filters of the corresponding mini-set.
\ti{Obviously the introduction of mini-sets dramatically cuts down the number of horizontal lines and blue rectangles, otherwise each anomaly filter require one horizontal line and one rectangles, which may cause serious visual clutter problem. In fact, mini-sets can be viewed as a partially aggregation version instead of representing all the anomaly filters as horizontal lines and rectangles.
Users can set the minimum appearing number of mini-sets to filter the sets with lower importance.}%\tii{Give some example patterns about the importance of filters, or the classes internal correlations.}%The horizontal lines's widths equal to the corresponding mini-set size and opacity is used to encode the value that is computed by multiplying the mini-set size and the the used times of this mini-set (denoted as \textit{Correlation Degree}). Thus, for the one with low correlation degree, it will become transparent.%With this design, experts can easily discover the distributions and correlations between filters and classes by using this grid-style visualization.%For example, experts can easily follow these lines to discover those layers/filters that are related to certain classes.%\ti{Beyond that, we also provide the experts with a simple version (Fig.~\ref{fig:correlation_view}b) to only uncover the correlation between layers and classes while hiding the relationships across classes and the iteration-related information. In this version, for $\mathrm{Cell}_{i,j}$, a sequential color was used to encode the number of filters ($\cup_{t\in T_j}s_{i,t}$). The size of inner rectangle represented the number of filters shared by all $s_{i,t}$ in $T_j$.}%The rows and columns of correlation matrix represent layers and image classes, respectively. The width and the height of $Cell_{ij}$ encode the number of abnormal iterations identified for class $C_j$ and the number of filters contained in layer $L_i$.%Inside the cell, there are several rectangles representing the filters that changes most hugely.%For the $Cell_{ij}$, it is further divided into sub-rows and sub-columns, each sub-row indicting one mini-set of filters (at least one) and each column representing one detected abnormal iteration.%If there is one mini-set of filters in layer $L_i$ that changes most hugely for one the abnormal iteration of class $C_j$, a rectangle will be drew on the corresponding sub-row and sub-column in the $Cell_{ij}$. The height of the rectangle suggest the number of filters contained in the minimum set. The vertical edges link all the filters that changes most hugely in one abnormal iteration for one class. The horizontal edges link all the same mini-set of filters in one layer for each class.%\textbf{Design consideration}.%This view has been iteratively re-designed several times with the discussions of the experts.  We can choose to only encode the number of anomaly filters appearing %The major concern is the tradeoff between abstract and detail.%Inspired by MatrixWave~\cite{zhao2015matrixwave}, the cells of layer-class matrix initially were designed to have the same width and height (Fig.~\ref{fig:correlation_view}b). For $\mathrm{Cell}_{i,j}$, a sequential color was used to encode the number of filters ($\cup_{t\in T_j}s_{i,t}$). The size of inner rectangle represented the number of filters shared by all $s_{i,t}$ in $T_j$. We also considered to use glyphs (Fig.~\ref{fig:correlation_view}c) to show the number of each group of filters that are grouped by the co-occurrence times. Although this method reveals the correlations between layers and classes and can identify the number of most critical filters in one cell (the ones shared by most $s_{i,t}$ in $T_j$), it fails to disclose the inner relationships between classes and to help the experts identify the critical filters. %The experts dislike it.%Then, we designed a second version of Correlation View, which was partly inspired by UpSet~\cite{lex2014upset}. For this version, we did not apply partition algorithm to divide $s_j$ into mini-sets, but rather drew a horizontal line for each filter. Although this design can reveal the correlation between classes and anomaly iterations in great detail, this design encountered a serious visual clutter problem. In the end, we adopted the set partition algorithm to aggregate individual filters and to reduce the number of horizontal lines while preserving the desired information. %One more advantage of such aggregation is that the line's width and opacity channel can be further utilized to encode the importance of mini-sets.%Eventually, we adopt the design shown in Fig XX..\subsection{Cube Visualization}\label{sec:cubeview}%\dy{space-efficient, visualize all components in one screen to enable users to conduct coordinate analysis. Usually 3D is not preferred for information  visualization  duo to occlusion  and perspective  distortion. But our cube design does not have these  problems... Skewed axis. Justify: 1) limited display space 2) correlation understanding 3) sharing the same time axis by skewed axis method~\cite{berry2004binx}.}

The log data contain three main aspects of information, namely, iterations, validation information, and weight information.
The three aforementioned views are designed to show all possible 2-combinations of these three types of information, respectively.
\ti{
Although these views can be used individually, they need to be combined together to form a complete picture.
}
Thus, we propose a novel and intuitive visualization technique, which naturally and seamlessly stitches the three views together, based on their shared axis (inspired from Binx~\cite{berry2004binx}), into a ``cube'' shape (Fig.~\ref{fig:teaser}).
%To reduce the cognitive burden of context switching between different views, we propose a novel cube-style visualization technique.%that can intuitively integrate the three views together.%Specifically, we stitch these views together (based on their shared aspects) into a ``cube'' shape (Fig.~\ref{fig:teaser}).
When experts find or highlight a pattern of interest, they can easily track the pattern over the edges to find the related information in the other two views easily. 

\ti{
The use of skewed axes may bring about a possible perspective distortion problem. Nevertheless, the advantages of the cube-style design far outweigh the disadvantages.
Given the limited pixels in a computer screen and each view requiring a large display space, the experts all agree that the cube-style design is the most space-efficient and intuitive manner to show all the information. Furthermore, with such design, it prevents the experts from switching from multiple views, reducing the cognitive burden and the load of memory.
This allows the experts to conduct correlation analysis more effectively.
We also provide a compromised solution to handle the distortion problem, that is, laying out the three views in the form like Fig.~\ref{fig:correlation_view}c. So the experts can firstly examine the layer view (horizontally) or validation view (vertically) together with the correlation view, and then switch to cube mode to explore the three views together.
}\ti{
Notice that there are some different settings for several views in the cube.
For the layer view (front), only the layers with anomaly filters are activated (see the activated blue bars in the front view of  Fig.~\ref{fig:teaser}), the weight variation of each anomaly filter is represented as a horizontal color strip.
For the validation view (top), only the classes with anomaly iterations are preserved.
%Experts can even turn up the threshold score of anomaly scores to further reduce the number of presented classes. 
%Both layer view and validation view share
%For the correlation view (right), the row number equals to the number of activated layers and the column number equals to the number of the anomaly classes.
The following lists several common exploration pipelines:
\begin{compactitem}
	\item P1: from the layer view (front), we can quickly check the distribution of activated layers in the overall network and pick some anomaly filters of interests. Then, by tracking along the horizon axis to the correlation view (right), we can examine which classes these filters impact and how important these filters are to the classes. Finally, we can observe the evolving patterns of these classes and the corresponding anomaly iterations in validation view (top).
	\item P2: from the validation view (top), we can firstly mark several anomaly iterations of some classes. Then, we can check the corresponding columns in the correlation view, finding the rows that contain anomaly filters and exploring the importance of these filters to these classes and how these filters impact the other classes. Finally, by highlighting these corresponding rows, we can observe them in the layer view to see how these filters behave around the picked anomaly iterations.
	\item P3: from the correlation view (right), we can search the horizontal lines across many rectangles (it means these filters impact many classes at the same time) or the rectangles that appear more than one time in the same cell (these filters are judged as anomalies many times for a class and may have great impact on this class). With these selected horizontal lines or rectangles, we can simultaneously track their corresponding weight variation information in the layer view (front) and class performance information in the validation view (top).
\end{compactitem}
}%For example, experts may click on one or more mini-sets of filters on the Correlation ``surface,'' then our system automatically highlights the related classes and layers on the other two ``surfaces'' to help experts examine the error rates of these classes, anomaly iterations, and filter change patterns and positions in the CNN structures at the same time.%We admit that there exists a possible perspective distortion problem for the use of skewed axises, the advantages of the cube-style design, however, far outweigh the disadvantages. %\ti{Given the limited pixels in a computer screen and each view requiring a large display space, the experts all agree that the cube-style design is the most space-efficient and intuitive manner to show all the information. Furthermore, with such design, it prevents the experts from switching from multiple views, reducing the cognitive burden and the load of memory.%This allows the experts to conduct correlation analysis more effectively.}%\dy{One slightly different in cube view is that, the heights of each small multiples of Validation View (top face) and Layer View (front face) are brought into correspondence with related cell's height and width in Correlation view (right face). Besides, the small multiples for layers in front face are replaced with color stripes, each representing the change pattern of one anomaly filter (the height and vertical position are consistent with the one in Correlation view). Since all the opened layers are basic CONV layers, only the smallest blue bars that exist anomaly filters are highlighted. }%Thus, the cube consists of three faces: the top face is the validation view. It is to be noted that the height of each heatmap equals to the width of corresponding column in correlation matrix now, suggesting the number of abnormal iterations. Besides, the timeline is attached on the top the top face; the front face shows the layer view, where the height of each layer equals to the height of corresponding row in the correlation matrix as well; the right face is the correlation matrix. When the experts scoll in the right face, the front face and the top face will scoll too to ensure the positions of layers and classes can match the correlation matrix in the right face.%Although the aforementioned three views can be explored individually to find interesting patterns, they all share dimensions%To further understand the patterns found in the correlation matrix, the experts often need to switch to validation view and layer view. To reduce the cognitive burden on working memory, we propose a novel cube-style visualization technique that can intuitively integrate the three proposed views together to help the experts explore the complex relationships among the multiple types of heterogeneous training data (neuron weights, validation images, and training iterations). The cube consists of three faces: the top face is for the validation view. It is to be noted that the height of each heatmap equals to the width of corresponding column in correlation matrix now, suggesting the number of abnormal iterations. Besides, the timeline is attached on the top the top face; the front face shows the layer view, where the height of each layer equals to the height of corresponding row in the correlation matrix as well; the right face is the correlation matrix. When the experts scoll in the right face, the front face and the top face will scoll too to ensure the positions of layers and classes can match the correlation matrix in the right face.%\subsection{Interactions}%Many useful interaction techniques are integrated in \name.%%\textbf{Details on demand.} \name supports the interactive exploration on the training log from different levels of details.%Hierarchical small multiple, open in needs.%Both the class heatmap and layer chart can be flipped into pixel charts for showing more detailed image level and s level information, respectively.%Clicking on pixel, show image.%%\textbf{Chart zoom in/out.} There are two types of zoom operations on charts. First, the pixel chart of image or layer supports horizontal and vertical zooming. Take the image pixel chart as an example, the horizontal zoom in/out (increase/decrease) the width of each cell (i.e., iteration) and the vertical zoom in/out (increase/decrease) the height of each cell (i.e., image). This allows the experts the pixel charts in high resolutions. Besides, zoom in/out also works on hierarchical small multiple chart for layers, allowing the experts expand/shrink the height of charts.%%\textbf{Correlation analysis.} Both validation view and layer view share the same timeline. When the experts hovering on class heatmaps, layer charts, or pixel charts, a dashed vertical line will show up to help the experts . Iteration marking, 3D transforming. With all the aforementioned interactions, a coordinated analysis can be performed efficiently and effectively.%\textbf{Selecting, filtering, highlighting.}%\subsection{Interactions}%\label{sec:interactions}%Generally support some interactions. Hover, sync line! Sync zoom and pan. Highlight. %filtering:%aggregation:%validation view -> keep the classes with anomaly iteration. %For the remaining classes, use clustering algorithm and then aggregate classes in on cluster.%layer view -> keep the layers with anomaly filters.%For filter change degree vis, use the clustering algorithm to aggregate .%correlation view -> keep the filters appearing in many classes (column), remove the mini-set with very small size and appear in very few classes.%!TEX root = ../deeptracker.tex% !TeX spellcheck = en_US\section{Use Examples}\label{sec:evaluation}%case需要SHOW以前系统做不到，我们却能很好解决的。故事最好要长一点，有EXPLORE的过程，这样会又去
We derived these examples through the assistance of our collaborating experts, who were familiar with our designs and data. As a remark, the following results are from the experiment with 8 times larger batch size and learning rate setting than the basic setting introduced in Sec.~\ref{sec:dataprocessing}. 

\subsection{Exploring Validation Results}%\begin{figure}[htbp]%	\centering%	\includegraphics[width=0.48\textwidth]{resources/validation}%	\caption{(A) Overview of all classes. (B) A radial location glyph to present a selected billboard location. (C, D, E) show the alternative solution glyph designs.}%	\label{fig:case1}%	%\vspace{-2mm}%\end{figure}\begin{figure}[htp]
	\centering
	\includegraphics[width=0.8\columnwidth]{resources/case1-1}
	\vspace{-2mm}
	\caption{Overview of validation classes. (a) Two curves show the overall training/validation error rate. (b) Two turning points align well the boundary of stage $s2$. (c) Three peaks appear in the stage $s1$ and align well with (f) the detected anomaly iterations. (d) Two types of mushroom images have different behaviors in the class. (e) Most images in the class flip at the anomaly iteration.}
	\label{fig:case1}
	%\vspace{-7mm}
\end{figure}
The first scenario demonstrates how the experts use \name to explore the image classification results (\textbf{R3}, \textbf{R4}, and \textbf{R5}).

%As a notice, in our training process, there are four times of turning down learning rates during the whole training process, .%stages the hyper-parameter (i.e., learning rate) learning rate turn down\textbf{Performance evolution patterns}.
Fig.~\ref{fig:case1}a shows a typical visualization of training/validation errors that may appear on any popular training platform. The timeline at the top shows a total of 1.2 million iterations.
Beneath the timeline, four line segments represent four stages ($s1$, $s2$, $s3$, and $s4$ in Fig.~\ref{fig:case1}) in the training process, \dy{where the later stage has one-tenth of the \textit{learning rate} of the previous stage.}%which are decided by the hyper-parameter of \textit{learning rate}. %In our case, the learning rate of later stages is only one tenth of the previous stage's.}
We can observe that two sudden drops in the curves match well with the boundaries of the training stages (Fig.~\ref{fig:case1}b).
However, this is a well-known pattern to the experts.
On the other hand, although the overall error rate continues to decrease, the class-level error rates show a more complicated story, that is new to the experts.
By quickly scanning the small multiples in cluster-level, the experts identify there are generally four types of class evolving patterns (Fig.~\ref{fig:case1-2}).
From top to bottom, the four types are more and more difficult to train.
\ti{For example, for the type at the top, these classes are recognized correctly after a few iterations.
By contrast, the classes at the bottom always have high error rates in the entire training process, which means that the resulting network fails to recognize the related images.}
From this, the experts learn that the model has spent most of time to improve its performance on the classes of middle-level classification, since the model has already performed well on the easy-trained classes at a very early stage and is always performing miserably on the hard-trained classes over the entire training. 
%Besides, we also observe that the classes sharing similar visual features tend to have similar evolving patterns, because these classes are placed closely (check the layout encoding in Sec.~\ref{sec:validation_view_encode}).%For example, class 'n03447447' (a boat under the blue sky) and '04562935' (a tower under the blue sky) are neighbors in Fig.~\ref{fig:case1} (row 7 and 8).
From these patterns, the experts consider it promising to accelerate the training process and improve the overall performance by treating classes differently during the training process. That is, stop feeding the easy-trained classes in an appropriate early stage, put more efforts on training the classes of middle difficulties for classification, and figure out why some classes always have extremely high error rates. One similar attempt has been made in a recent work~\cite{lin2017focal}.

%From these patterns, the experts suspect that, for a CNN training process, these two extreme types of images may contribute little to the final network; thus, treating them differently may reduce the total training time or improve overall performance. (\dy{pictures with similar features have similar performance going down process - dog and mushroom on the grass}) %treating  identifing the images of these two  most of the time is spent to train the classes of middle-level classification difficulties (i.e., C2 and C3), since C1 classes have been trained well in the very early time and C4 classes are always trained invalidly.%Each stage lasts 30 thousands iterations and has half learning rate (one type of hyperparameters) than the previous stage's.%Three peaks in stage $s1$ in the model-level error rate chart were marked.%The following many color strips show the changes of error rates of each class over training (\textbf{R3}).%From the top to bottom, classes become more and more difficult for classification.%The experts identified four general performance evolving patterns: 1. some classes (C1, Fig.~\ref{fig:case1}A1) are very easy for classification and their colors change from red to green in a very short time at the beginning of $s1$; 2. some classes (C2, Fig.~\ref{fig:case1}A2) are relative easy for classification. These classes have relatively high error rates in $s1$, but turn to low error rates since $s2$; 3.some classes (C3, Fig.~\ref{fig:case1}A3) are relative hard for classification. The error rates of these classes converge to $50\%$ since $s3$.  4. some classes (C4, Fig.~\ref{fig:case1}A4) are very hard to classify and always have high error rates over training.%From these patterns, the experts concluded that for a CNN training process, most of the time is spent to train the classes of middle-level classification difficulties (i.e., C2 and C3), since C1 classes have been trained well in the very early time and C4 classes are always trained invalidly.%Each time turning down the learning rate comes with a huge decease of the error rate and the loss in short time, whereas in usual time, both decrease normally apart from the three small peaks (denoted as $i_1$, $i_2$, and $i_3$) occurred in the early training iterations in stage $s1$. Since many dynamics are hidden, the experts turned to the validation view for help to seek more detailed information.%about how the evolving CNN perform differently on each classes.%classes have very low error rate in very short time from the beginning of $s1$ (from red to green very quickly), classes start to have low error rate from the beginning of $s2$, classes have relatively low error rates from the beginning of $s3$, and classes alway have high error rates over training. These patterns indicate that different classes have different training difficulty.\textbf{Anomaly iterations}.
The experts are curious about the three sudden peaks in stage $s1$, and then mark these three iterations with dotted lines (Fig.~\ref{fig:case1}c), which look like anomaly iterations (\textbf{R4}).
However, the colors in the small multiples do not have clear patterns related to these iterations.
Then, the experts turn on the anomaly detection and immediately find that many triangles are aligned well with the dotted lines (Fig.~\ref{fig:case1}f), thereby confirming our suspicion.
Then, the experts can click on the corresponding image icons to see the detailed images that contribute to the three peaks.
In addition, there are more anomaly iterations in stage $s1$ then in the later stages.
This interesting pattern can be explained by the reduction of learning rate and the convergence of the model in the later stages. At the same time, it also implies that the learning rate in stage $s1$ is slightly too high, leading to the instability in the model (the case in Sec.~\ref{sec:case2} indicates the same finding for the discovery of potential ``dead'' filters).
%It is also found that there are many triangles showing in the previously marked peaks, suggesting that the classes that are abnormal in these three iterations contribute a lot to the resulting peaks in the model's error rate curve. To know what these classes are, the experts can further click the small image icons left to pop up the original images.%The experts were particularly interested in the classes with anomaly iterations (\textbf{R4}), thereby filtering the classes that have no anomaly iteration detected (Fig.~\ref{fig:case1}B).%% whose abnormal value exceed threshold 6 are remained (Fig. xB). The triangles on the top side and the bottom side of each heatmap correspond to the detected outliers.%As observed by the experts, there are more anomaly iterations in $s1$ and less for the later stages. This can be explained by the change of learning rate and the model start to converge over training. It is also found that there are many triangles showing in the previously marked peaks, suggesting that the classes that are abnormal in these three iterations contribute a lot to the resulting peaks in the model's error rate curve. To know what these classes are, the experts can further click the small image icons left to pop up the original images.\textbf{Details in classes}.
To further examine what happens at the anomaly iterations for a class, the experts can further check the image-level information of the class (\textbf{R5}).
For example, the experts are curious about the abnormally large anomaly iteration in the class of ``mushroom'' (Fig.~\ref{fig:case1}d) that are captured by both the left-rule and the right-rule.
Then, they click and expand color stripe to see the pixel chart of images.
First, they confirm that this iteration is indeed special for this class, because nearly all images flip during particular that \dy{dumped interval} (Fig.~\ref{fig:case1}e).
Thus, they may further investigate to find the layers or filters that cause such flips based on the filter updates around that iteration.
\dy{In particular, the experts comment that, it seems that after the iteration, the CNN model has jumped to a better local optimal for the class, because the green color is more stable after the iteration.
This may result from the reduction of the learning rate (from $s1$ to $s2$).  
This kind of patterns appear frequently in many classes during the whole training process, many of them occurring not in the learning rate transition point.
The experts wonder that the model should be trying to jump from one local optimal to another better local for these classes continuously, so as to reduce the overall error rate gradually.}
This insight has never been obtained because the experts initially thought that the error rate for one class should decrease steadily.
%Besides, one can also see the green area after $i_1$ is larger and smooth than the one before $i_1$. Thus, the experts inferred that during the interval of this two sibling dumbed iterations, the model should jump from a local optimal for this class to another better local optimal. This pattern occurred frequently in many classes. It is because these classes keep jumping from one local optimal to another better local optimal that the overall error rates can go down slowly. This insight is never obtained before, as the experts initially thought that the performance for one class should go down steadily.
Besides, the experts also find that, at the bottom of the pixel chart, several images are mislabeled in the entire training process, although the class is easy to train overall(Fig.~\ref{fig:case1}d).
To understand why, the experts click on these images to examine them, and find that the contents in the mislabeled images have a clear color pattern different from that of the rest of the mushroom images.
The correctly labeled mushrooms are all red, while the mislabeled ones are white or orange.
This finding indicates color is a critical feature that the CNN has learned to classify this class of images.
%Fig.~\ref{fig:case1}B2 shows the pixel chart of class ``Mushroom'', which has a small $\nabla$ on the top (denoted as $i_1$) and large $\triangle$ on the bottom (denoted as $i_2$). Seeing the red area in the bottom of the chart, the experts knew that there are nearly one fifth images that are always mislabeled.%Then By clicking on these images rows (with vertical zoom in), they further found the reasons why these images are never labeled correctly, that is, compared with the other correctly labeled images (almost are red mushrooms), the mushrooms appearing in mislabeled images have clearly different colors in spite of the similar shapes. This indicates color is a critical feature the CNN has learned to classify this class of images.%The experts then zoomed to the anomaly iteration, finding nearly all images are suddenly mislabeled at $i_1$. These mislabeled images are then labeled correctly at the next dumped iteration (i.e., $i_2$).%, among which 31 images change their labels and keep the labels stable for many iterations.%and the right abnormal value 31 suggest that most of their labels never change in the later long iterations.%More importantly, the experts never realized that the performance of a class (especially easy trained class) should go down steadily like model error rate curve. However, they found that many top and bottom triangles show up in sibling iterations (Fig. xx) for many classes (including easy trained class) and inferred that for many classes, they have gone through a short and critical time that the error rates increase dramatically and then decrease to more lower value.%To further verify this, they showed particular interests on mushroom class due to the small top-side triangle (with left abnormal value 8) and large bottom-side triangle (with right abnormal value 31) in the sibling iterations.%By checking its image-level pixel charts (\textbf{R5}), they first found that .%By clicking on these images rows (with vertical zoom in), they found the reasons to explain why these images are never labeled correctly, that is, compared with the other correctly labeled images (almost are red mushrooms), the mushrooms appearing in these images have clearly different colors but similar shapes. This indicate color is a critical feature the CNN has learned to classify this class of images.%Besides, by further zoom into the abnormal iterations, they found nearly all images are suddenly mislabeled in the left abnormal iteration, where 8 images have correct labels for a long time.%These mislabeled images then suddenly are correctly labeled and the right abnormal value 31 suggest that most of their labels never change in the later long iterations.%The more rows of continuous long-length green pixels on the right side of the abnormal iterations than the left side's confirm this.%It also hint the experts that during the interval of this two sibling dumbed iterations, the model should jump from a local optimal for this class to another better local optimal.%Thus, the many pairs of sibling top and bottom triangles indicate the training CNN is on the right track, jumping from one local optimal to the other local optimals that have slightly performance improvement.%Finally, these local optimals for all classes compose the final model error rate.% LABEL VIEW%总是有一下子 对的变错的， 几乎没有 一下子错的变对的%story1: 梯度弥散问题被resnet解决， 看平均速度Norm 或者 改变率， 都是浅层大 在一开始； indicate 可以使用大层训练的方法%story2: 梯度改变率的渐渐下降趋于平缓的现象， guide 调节Lr%sotry3: %基本的，weight的分布， 以及std等，规律的不同。  梯度初始化算法是根据这层神经元数量确定， 决定std， 越多std越小，即和0离的越紧密。%challenges existing in training dnn%局部极值问题%使用监督学习方法来对浅层网络（只有一个隐藏层）进行训练通常能够使参数收敛到合理的范围内。但是当用这种方法%来训练深度网络的时候，并不能取得很好的效果。特别的，使用监督学习方法训练神经网络时，通常会涉及到求解一个%高度非凸的优化问题（例如最小化训练误差  ，其中参数  是要优化的参数。对深度网络%而言，这种非凸优化问题的搜索区域中充斥着大量“坏”的局部极值，因而使用梯度下降法（或者像共轭梯度下降法，%L-BFGS等方法）效果并不好。%梯度弥散问题%梯度下降法（以及相关的L-BFGS算法等）在使用随机初始化权重的深度网络上效果不好的技术原因是：梯度会变得非常%小。具体而言，当使用反向传播方法计算导数的时候，随着网络的深度的增加，反向传播的梯度（从输出层到网络的最%初几层）的幅度值会急剧地减小。结果就造成了整体的损失函数相对于最初几层的权重的导数非常小。这样，当使用梯%度下降法的时候，最初几层的权重变化非常缓慢，以至于它们不能够从样本中进行有效的学习。这种问题通常被称%为“梯度的弥散”.%与梯度弥散问题紧密相关的问题是：当神经网络中的最后几层含有足够数量神经元的时候，可能单独这几层就足以对有%标签数据进行建模，而不用最初几层的帮助。因此，对所有层都使用随机初始化的方法训练得到的整个网络的性能将会%与训练得到的浅层网络（仅由深度网络的最后几层组成的浅层网络）的性能相似。%逐层贪婪训练方法%那么，我们应该如何训练深度网络呢？逐层贪婪训练方法是取得一定成功的一种方法。我们会在后面的章节中详细阐述%这种方法的细节。简单来说，逐层贪婪算法的主要思路是每次只训练网络中的一层，即我们首先训练一个只含一个隐藏%层的网络，仅当这层网络训练结束之后才开始训练一个有两个隐藏层的网络，以此类推。在每一步中，我们把已经训练%好的前  层固定，然后增加第 层（也就是将我们已经训练好的前  的输出作为输入）。每一层的训练可%以是有监督的（例如，将每一步的分类误差作为目标函数），但更通常使用无监督方法（例如自动编码器，我们会在后%边的章节中给出细节）。这些各层单独训练所得到的权重被用来初始化最终（或者说全部）的深度网络的权重，然后对%整个网络进行“微调”（即把所有层放在一起来优化有标签训练集上的训练误差）.\subsection{Exploring Weight-Relevant Information}\label{sec:case2}\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.98\textwidth]{resources/case2-1}
	\caption{(a, b, c) The sd values of each layer decrease slowly and have different scales in different CONV modules. (d) The weight changes in filters are large at the beginning. (e) One outlier filter is detected, whose weights never change during the entire training process.}
	\label{fig:case2-1}
	\vspace{-2mm}
\end{figure}
This scenario shows how to discover patterns in neuron weights via the Layer View (\textbf{R1}, \textbf{R2}).
%explored different statistical values with Layer View.%direction1: explore img view first to identify the period you are interested -> find what happened during this period in network in third view -> explain and validation if possible!%direction2: find interesting period by checking third view -> check how the results changed during this time%The experts also%\textbf{Layer-level exploration}.%As there are many types of statistical values that can be explored to help the experts debug the network or programming, here we only take several of them as examples.%The layer statistical information can help experts know whether the training process is on the right track.
First, the experts choose to show the sd (standard deviation) of the weights at the layer-level using horizontal graphs (Fig.~\ref{fig:case2-1}).
As the experts expected, all the trends show a similar pattern of slow decrease, indicating the weights in the entire model is converging over iterations.
Besides, the experts also find that deeper layers (closer to the loss layer) tend to have smaller sd values.
\dy{In particular, by tuning the band number (finally to 3) of the horizon graphs, they found the sd values of a CONV module are usually twice as large as those of the one below it (a, b, and c in Fig.~\ref{fig:case2-1}).
Given that we apply Xavier initialization\footnoteref{note7} and for ResNet-50, the input sizes of layers in a CONV module are twice as large as the ones in the layers of its previous CONV module, the observed result is not beyond the experts' expectation. This suggests that there is no problem exist on the initialization approach.
}%where the hyper-parameter sd depends on its size of inputs from the previous CONV layer and .%The experts  the weights in a CONV layer are initialized according to the size of inputs from the previous CONV layer (i.e., Xavier initialization~\cite{glorot2010understanding}). %the numbers of neurons in the layer.%Since layers from neighboring big CONV layers often have very different numbers of neurons, the weights may also different values.%Since neurons are generally doubled between big CONV layers, we%To compare their trends, the experts normalize them individually.%Initially, each horizon graph has its own scale (i.e., min value and max value are computed each layer) to facilitate the individual layer trend analysis (\textbf{R1}).%Fig.~\ref{fig:layer_view} shows the std values of layers at different levels of hierarchies. Initially, each horizon graph has its own scale (i.e., min value and max value are computed each layer) to facilitate the individual layer trend analysis (\textbf{R1}). As observed by the experts, the std values have very similar evolving patterns for each layer and become gradually smaller and smaller over the training, indicating the weights of model converge over training.%To make comparison among them(\textbf{R2}), they switched the scale of each horizon graph to the same max and min (computed globally), finding that the deeper layer has smaller std. In particular, by tuning the band number of horizon graph, they found the std values of the previous big CONV layer are nearly twice as much as the next big CONV layer (Fig.~\ref{fig:layer_view}).%However, there is no clear difference when comparing the layers that belong to the same big CONV. This is what the experts expected, because the experts adopted different initialization settings for different layers. Specifically, the layers with more number of neurons (i.e., the number of learnable weights) should be initialized with a smaller std. Basically, the layers in the next big CONV layer have twice number of learnable weights than current big CONV and there is no big difference of the number of weights for the layers belonging to the same big CONV layer. Thus the experts deemed that the training goes on a right direction regarding initialization methods.

Analogously, the experts find that the weight means of each layer become negative quickly (from green to blue instantly, Fig.~\ref{fig:case2-2}a) except for the FC layer (Fig.~\ref{fig:case2-2}b).
At first, the pattern looks strange to the experts.
Then, the experts realize that it is reasonable to have more negative weights than positive ones, since negative values are often used to filter out trivial features owing to the use of ReLU activations.
The increase of negative weights suggests that the network is trained to extract useful information from the original image layer by layer, and then finally remain the most relevant features.
\dy{As for the FC layer, it plays a function of shaping the extracted useful features into feature vectors of given dimension for further classification. One strange phenomenon intrigues the experts, that is, the FC layer weight means are always positive in many-times training ResNet-50 (with different batch sizes and learning rates) on ImageNet Dataset, whereas becoming negative when training ResNet-164 on Cifar Dataset~\cite{krizhevsky2009learning}. This finding is worth a further investigation.}%As for the FC layer, it plays a function of shaping the extracted useful features into a given dimension feature vector.  The experts }%Every neuron plays as a small classification function detecting certain kind of feature instead of merely the FC layer. It is still confusing why other layers have more negative weights while FC layers have more positive weights. Actually, Weights in a CNN form feature detectors, so that a certain pattern in a image is connected to strong weights, but the rest of the image pixels should not cause any activations in the next layer neurons. Only a small fraction of neurons in a layer is activated every time an image is shown, and a small fraction of weights is needed to be large to activate (or suppress) any particular neuron. Moreover, the number of patterns a network needs to detect is fairly small, especially in the early layers. Therefore, overall connectivity for the network is usually very sparse. The distribution of FC layer (pos more than neg) is still unknown.})%(\dy{every resnet model, final layer has more postive values. Cifar is different - always negative})%The experts never notice this and later they explained that it is reasonable that the negative values are more than positive value, as the function of negative values is to filter the trivial features. The more negative values for CONV layers suggest they are extracting useful information from the original image layer by layer and then finally remain the most relevant features for classification. Since the FC layer function as a classification function, it also normal that its mean is not negative.%\textbf{Filter level exploration}.
Apart from layer-level values, the experts also explore the filter-level information (\textbf{R1}).
In our system, two different ways (i.e., filter-based or iteration-based) are used to normalize weight changes at the filter-level.
For filter-based normalization, changes are grouped and normalized by filters, which aims to help experts see the change distribution over iterations for individual filters.
Similarly, iteration-based normalization allows experts to examine the distribution over filters for individual iterations.
%By clicking on the layer rectangle on the left graph network, the experts are allowed to flip the corresponding layer chart to pixel chart to see the filter-level information.
For example, Fig.~\ref{fig:case2-1}d visualizes the filter changes in one of the CONV layer belonging to the second CONV module using filter-based normalization.
%In this case, the pixel value represents the cosine similarity between the weight vector of one filter at previous dumped iteration and current dumped iteration. The sequence color from white to blue is utilized and the more white the color is, the more large distance (huge variation) between the weight vectors.%For a layer, there are two types of .
The experts find that the changes are drastic in stage $s1$ and become relatively small in the later stages because of the decrease in learning rate and the convergence of the model.
However, the experts also identify two strange filters among 64 filters in the first CONV layer that have a constant deep blue color (Fig.~\ref{fig:case2-1}e).
By further checking, the experts find that the weights of these two filters never change during the entire training process.
%This is a total surprise, and the experts believe there must be some problems in the programming (e.g., initialization problem), or that is a redundant filter in the layer (\dy{might be dying relu, when sometimes activation become 0, then always be 0. A "dead" ReLU always outputs the same value (zero as it happens, but that is not important) for any input. Probably this is arrived at by learning a large negative bias term for its weights. In turn, that means that it takes no role in discriminating between inputs. For classification, you could visualise this as a decision plane outside of all possible input data. Once a ReLU ends up in this state, it is unlikely to recover, because the function gradient at 0 is also 0, so gradient descent learning will not alter the weights.}).\begin{figure}[t]
	\centering
	\includegraphics[width=0.98\textwidth]{resources/case2-2}
	\caption{(a, b) The means of weights in each CONV layer become negative quickly (from green to blue) except for the FC layer. (c) Three filters are always more actively changed than the other filters in the later part of training progress.}
	\label{fig:case2-2}
	\vspace{-4mm}
\end{figure}\dy{This is a total surprise to the experts. Excluding programming bugs, the most likely reason should be due to the dying-ReLU problem, namely, these two filters are inactive for essentially all inputs and no gradients flow backward through the neurons of the two filters.  The experts suspect the dying-ReLU problem results from the high learning rate in the beginning of train. In fact, the experts usually follow a rule of thumb to set the hyper-parameter learning rate, that is, multiply the learning rate by k if the batch size is multiplied by k. This rule is currently formally introduced in a recent work~\cite{goyal2017accurate}.
In this experiment, we use 32 times larger batch size GPUs (32 GPUs) than the mini-batch size 32 for one GPU to train the model with the corresponding size of learning rate, dying-ReLU problem still occurs. This reminds the experts that the rule may not so accurate for extremely large batch size sometimes, but the problem can be solved by carrying out a warmup strategy (i.e., using lower learning rate at the start of training~\cite{he2016deep}), which the experts haven't done in previous trainings. One further interesting finding is that by inactivating these two "dead" filters (i.e., set their weights as 0 so that they are inactive for any inputs), the experts find the overall performance not affected at all, whereas if we inactivate other random-picked filters in the first CONV layer of the model, the number of mislabeled images in $D_v$ would increase few thousands. 
Thus, the experts finally modified the network configure and eliminated these two filters, so that the model can run faster while costing less memory.
%It suggests these two filters are needless for the model and these two channels (the output volume of the first CONV layer have 64 channels) are not fully taken advantages. To further improve the overall performance, the experts consider it possible to initialize the weights of these two filters and fix others, then fine tune the model accordingly.
}

Fig.~\ref{fig:case2-2}c visualizes the weight changes in one middle layer using iteration-based normalization.
The experts find that a small number of filters are always more actively changed than the other filters (long deep blue lines in Fig.~\ref{fig:case2-2}c) in the later part of iterations.
This pattern implies that the updates inside a layer may be highly divergent.
\dy{In the later part of the training, where the learning rate is getting smaller and the model is converging, only a couple of filters are still continually actively updated for every iteration. 
We have tried to inactivate these identified filters, the result showing that the overall performance is not affected.
It is not beyond the experts' expectation due to the ResNet's ensemble-like behavior~\cite{veit2016residual} (even several entire layers can be removed without impacting performance). In the end, the experts still cannot fully explain the behavior of these continually updating filters. One possible reason could be that these special filters are not trained well (not converge) to extract some specific features, thus reacting violently for every iteration even in the later stages of the training.}%It is strange because with the reduction of learning rate and the convergence of the model, the filter update r%The experts suspect that it may be a hint to reduce the amount of neurons in the layer (e.g., network compression~\cite{wei2016network}) (\dy{with the reduction of lr, update ratio should be very small, these three filters very strange! set them to 0 to see what happen}).%\dy{Multiple other important reasons could cause this phenomenon. For example, the reduction of learning rates, which influences the update step size per iteration, is highly likely the most important reason causing this result. Simply reducing neurons based on this hint is not reliable.}%Besides, with the vertical scale, the experts discovered that for some layers in the middle part of network, there are always few filters that change very hugely compared with the other filters at the same iteration (Fig.~\ref{fig:layer_view2}). This is never known by the experts. Accordingly, the experts considered that these filters are much more important than other inactive ones in the same layer, as they respond strongly for every fed images during training (just as the theory of use and disuse). This finding is significant for them to reduce the amount of parameters of a well trained CNN network (also known as network compression~\cite{wei2016network}).%(just as the theory of use and disuse, in the book ``on the origin of species''). This findings are significant for them to reduce the amount of parameters of a well trained CNN network (i.e., network compression~\cite{}, one of the hottest directions in AI filed).%Then, the experts used similar method to explore the mean magnitude (averaged sum of absolute value) of weights of layers, finding that the mean magnitude of each layer gradually converge to a small value and no exploded values occurred. These meet what the experts expected, suggesting there is no bugs in programming%To begin with, the experts indicated that different initialization methods are used to initialize weights on different layers. Basically, for the layers with more number of neurons (i.e., the number of learnable weights, equaling to filter width $\times$ filter height $\times$ current layer filter number $\times$ previous layer filter number), the initial std value should be smaller (more convergent).%To verify whether this initialization strategy take effects as their expecting, they turned to the layer view for help.%They were firstly shown with the std values of five big CONV layers plus a FC layer. Notice that each horizon graph has its own scale initially (i.e., min value and max value are computed each layer) to facilitate the individual layer trend analysis.%As observed by the experts, with the training, the stds of each layer has very similar evolving pattern and generally become smaller and smaller (\textbf{R2}), indicating the weights of model converge over training.%To make comparison among them(\textbf{R2}), they switched the scale of each horizon graph to the same max and min (computed globally), finding that the the deeper the layer is, the smaller the std is. In particular, the std values of current big $CONV_i$ layer are twice as much as next deep layer $CONV_{i+1}$.%They opened up CONV2 and one of the bottle-neck structure (3 elementary CONV layer) to further explore the difference of std for the layers belonging to the same big CONV. They found that there are no clear difference among these layers.%They explained that for the layers in the same big CONV layer, the number of neurons are almost at same scale while the next big CONV layer has at least two times of neuron number compared with current one. This well explains why the std value becomes smaller for deeper layer and remain same scale for the layers in the same big CONV layer.%Then, the experts used similar method to explore the mean magnitude (averaged sum of absolute value) of weights of layers, finding that the mean magnitude of each layer gradually converge to a small value and no exploded values occurred. These meet what the experts expected, suggesting there is no bugs in programming regarding to this two types of statistical value. The converging std and mean magnitude of weights can be also verified from the boxplot chart, where the values of min, 1/4 quarter, mean, 3/4 quarter, and max are shown each iteration. As shown in Fig., The five values tend to converge over training.%Similar exploration methods were used and the experts knew the weights tend to converge to mean of each layer with smaller std. Thus, they desired to see more about the mean of weights. From the fig. x, they found the means of each layer are becoming negative over training (blue encode negative value) except for the FC layer. The experts never notice this and later they explained that it is reasonable that the negative values are more than positive value, as the function of negative values is to filter the trivial features. The more negative values for CONV layers suggest they are extracting useful information from the original image layer by layer and then finally remain the most relevant features for classification. Since the FC layer function as a classification function, it also normal that its mean is not negative.%Besides, Std -> small (fig.), mean magnitude -> small. Also seen in boxplot view, show (conv1 boxplot). The experts told that for there is a strategy to initialize. Mean (fig. ).%\textbf{Model comparison}. We also trained resnet-164 whose structures are similar to resnet-50 but has 164 layers on cifar-10 dataset. Compare. Purpose.%Like the human brain, the areas that used most often will used most\subsection{Exploring Filter-Image Correlations}
In this scenario, we demonstrate how the experts use the Correlation View to explore correlations between images and filters.

\begin{figure}[htb]
	\centering
	\includegraphics[width=1\columnwidth]{resources/n-teaser}
	\vspace{-4mm}
	\caption{
		A cube-style visualization that fuses three coordinated views together to reveal the rich dynamics in a CNN training process:
		(top) the Validation View shows the error rate changes of validation classes; (front) the Layer View shows the weight changes in CNN
		filters; (right) the Correlation View shows the potential relationships between filters and validation classes.
	}
	\label{fig:teaser}
	\vspace{0mm}
\end{figure}%In this case, the experts attempted to explore the correlation between validation images and neuron weights (\textbf{R6}).%There are two manners to explore such correlations.%For the first manner, the Validation View and Layer View are connected by sharing the same timeline. The experts can mark the iterations of interests in the Validation View. Then the vertical dashed lines running through both views will show up to help find abnormal changes regarding some statistic values. For example, at the anomaly iteration $i_1$ mentioned in Case 1, the experts found an exploded std value and max value occurred (with line charts) in the second CONV layer (the right side one with connection to CONV1 layer, Fig.~\ref{fig:layer_view2}). By further checking on the pixel chart, the experts identified two filters that change dramatically. Considering filters in shallow layers learn very fundamental visual features. Therefore, the experts inferred that the big changes of the two filters in the second CONV layer result in a huge impacts on lots of classes, leading to the form of the peak at $i_1$.%%For the first manner, the major purpose is to find how the layer statistical values correlate the error rates of classes. As the validation view and layer view are sharing the same timeline, the experts are allowed to mark the iterations of interests with vertical dashed lines running through both views and then conduct analysis accordingly.%%For example, the experts marked the abnormal iteration $i_1$, at which many classes detect outliers, and then switched to layer view with line charts (line charts are more good at conducing local tasks such as identifying the value at one iteration). They found the first basic CONV layer in the first bottleneck block of big CONV2 (i.e., the basic CONV layer after the CONV1 layer) has an exploded std value and max value with respect to the gradient at $i_1$.%%This indicates there should be some filters in this layer whose weights change hugely compared with others. By further checking filter-level pixel chart with vertical scale, they identified two dramatically changed filters, both changes very little in the previous many iterations. This suggests the features the two filters learned may have critical impacts on the classes that detect outliers at $i_1$, thereby leading to a peak of validation error rate curve.\textbf{Shallow-layer filters vs. deep-layer filters}.
%The second manner leveraging the cube visualization to integrate three coordinated views (validation view, layer view, and correlation view) allows the experts to more efficiently examine the correlations among layers/filters and classes.%(A for front, B for right, C for top).%At first, for each vertical line (i.e., one anomaly iteration for one class) in Correlation View, it lists top ten dramatically changed filters (anomaly filters).%By checking the highlighted bars (layers) in network graph and the heights of each layer in Layer View, the experts found fewer deep layer bars are highlighted (i.e., detect anomaly filters in this layer), whereas the highlighted deep layers have more anomaly filters than shallow layers.\ti{At first, the experts choose to only show the top $k$ ($100$ in this case) changing filters in the layer view. By checking the network structure visualization, the experts find that the activated shallow layers (the layers close to data input layer) are more than the activated deep layers, and most activated layers are the last basic CONV layers of bottlenecks for deep CONV modules.
Besides, Fig.~\ref{fig:correlation_view}a shows that deep CONV modules tend to contain more anomaly filters (especially for the CONV modules 4). The experts think that this kind of knowledge is of great importance for network compression~\cite{han2015deep}.
Then, the experts go to the complicated version to examine the more detailed correlation information.
They filter the mini-sets with very few appearing times, finding that anomaly filters in shallow layers are generally shared by more anomaly classes (columns) and iterations (vertical lines in one column) than those in deep layers (Fig.~\ref{fig:teaser}a).
The experts think that this pattern may relate to the fact~\cite{veit2016residual} that shallow-layer filters are more likely to capture basic visual features than deep ones, thereby the huge change of these filters affecting more classes of images (e.g., the long and opaque lines marked by b in Fig.~\ref{fig:teaser}).
By contrast, a deep filter tends to learn higher-level features, thus only relating to specific classes of images.}%Thus, the experts filter the Correlation View to show the filters that are related to more than one anomaly iteration (.}%Since the experts are more interested in co-occurring filters, they filter the Correlation View to show the filters that are related to %more than one anomaly iteration (Fig.~\ref{fig:teaser}c).%At the beginning, in the correlation view of Fig. X, each vertical line in one column (i.e., one abnormal iteration for the class this column corresponds to) lists top ten filters that changed most hugely (denoted as anomaly filters) at the detected abnormal iteration, where different anomaly iterations may share anomaly filters.%At first, by checking the network graph and the heights of each layer, they found there .%Since the experts paid more attention to the filters that co-occur in many abnormal iterations, they filtered the mini-sets that have few appearing times and contain few filters (if one mini-set's appearing times $\times$ containing number of filters is less than pre-defined threshold, then it is filtered).%The overall filter distribution shows that, although deep layers have much more filters than shallow layers, our algorithm detects more anomaly filters (i.e., the filters with largest changes at the detected anomaly iterations) in shallow layers.%In addition, anomaly filters in shallow layers are generally shared by more anomaly classes (columns) and iterations (vertical lines in one column) than those in deep layers.%Thereafter, just as shown in Fig.~\ref{fig:teaser}A, the experts discovered that although deep layers have multiple times of number of filters than shallow layers indeed, there are fewer deep layer bars are highlighted (i.e., have anomaly filters detected in this layer) than shallow layers. Besides, the height (number of anomaly filters) of deep layers (the interval distance between small circles in the right end of linking edges) seem to has no large difference compared with the shallow layers'. Both visual facts show that the filters in shallow layers have higher correlation degrees than the deep ones. In other words, the filters of shallow layers may learn some basic features that have impacts on many classes, whereas the features learned by the deep layers' filters may be more high-level and specific to very few classes. This conforms to the findings in prior work.%the height of deep layers decrease dramatically and some deep layer bars in the network graph are deactivated,%suggesting that a large number of mini-sets in the deep layers are filtered but few mini-sets in shallow layers are filtered.%Finally, as shown in Fig.~\ref{fig:teaser}A,%there are more shallow layer bars are highlighted (i.e., have anomaly filters in this layer) than deep layers and the height (number of anomaly filters) .%This suggests that the filters in deep layers learned more advanced features specific to one class and the filters in low layers (i.e., the layers close to CONV1 layer) are shared by many classes, which conforms with the prior knowledge.

To further explore the correlations,
%To further explore the correlation, the experts explored the Correlation View (Fig.~\ref{fig:teaser}B). From this view, the experts identified there are more long horizontal lines with less opacity (Fig.~\ref{fig:teaser}B xx, xx, xx, etc.) on the top area (shallow layers) compared to the bottom area (shallow layers), which further verify that the filters in shallow layers have impacts on more classes.
the experts select two mini-sets (b1 and b2 in Fig.~\ref{fig:teaser}), for comparison. Both the horizontal lines of b1 and b2 are opaque and thick.
By tracking them in the Layer View and the Validation View, the experts can see that b1 is in the first CONV layer, and related to many classes.
The experts open these classes and discover that many images in them have a common feature, i.e., a large background of blue sky or ocean (b1 in Fig.~\ref{fig:teaser}).
This discovery suggests that these filters in E1 may target the basic pattern to help identify images that contain large blue areas.
By contrast, b2 is located at the fifth \dy{CONV module} and related to only three classes.
Interestingly, the images in the three classes also share a more concrete feature, i.e., objects in a bush (b2 in Fig.~\ref{fig:teaser}).
\dy{In short, this case confirms that we are on the right track to reveal how the model weight changes relate to the classification result changes.}%For B1, it is in the first CONV1 layer and occurs in many classes. These classes share common feature, namely, having natural scene as background either the blue sky or the blue ocean. This suggests these filters may learn some basic features (e.g., blue color) to help identify the images that have large blue area. However, for B2, it is in a very deep layer in big CONV5 and contains 7 filters that co-occur in three classes. Interestingly, these the images in the three classes share a very clear common concrete features, that is, flowers, pandas, and leopards in the bushes (Fig.~\ref{fig:teaser}C, xx). In particular, there are even some pandas found in the classes of leopards. The previous a series of explorations further showed the difference between filters in shallow layers and deep layers, that is, the filters in shallow layers tend to learn fundamental visual features and have higher correlation degrees (impacts on many classes), while the filters in the deep layers are on the contrary.%First, from the Validation View on the top face, the experts found For the images%and large rectangle height (3 filters).%This mini-set is shared by many classes and is in the CONV1 layer. By checking its relevant classes, the experts found all of these classes have one common feature, that is, having natural scene as background either the blue sky or the blue ocean, indicating the three filters may learned some basic features (e.g., blue color) to help identify the images that have blue sky or blue ocean as background.\textbf{Important filters for a class}.
To find stronger correlations between filters and classes, the expert focus on anomaly filters that appear more than once in a cell for a specific class.
%The experts desired to find is the anomaly filters that appear more than one iterations for a given class, as the co-occurrence of these filters illustrate their importance for the class.
For example, the experts find two appearances of the same mini-set (containing two anomaly filters) for the class of ``gong'' (c1 in Fig.~\ref{fig:teaser}).
Tracking horizontally (along with the pink-highlighted area), the experts find that the mini-set does not appear in other anomaly iterations, which also implies a strong correlation between filters in the mini-set and the class.
Then, the experts click on these two rectangular glyphs to highlight the corresponding iterations on the timeline (c2 in Fig.~\ref{fig:teaser}) and the filter locations in the Layer View (c3 in Fig.~\ref{fig:teaser}).
It is clear that the gong class is not a well trained class as it has a very large yellow area (indicate a relatively high error rate) in the Validation View.
However, the experts also find a period in the middle when this class has a relatively good performance (c4 in Fig.~\ref{fig:teaser}), which happens to contain the highlighted anomaly iterations.
Meanwhile, the Layer View shows that the highlighted filters are also updated dramatically during the period of good performance (c3 in Fig.~\ref{fig:teaser}).
Considering these patterns, the experts speculate that the filters in the mini-set have a strong impact on the classification of gong images. 
As expected, we conduct experiments to inactivate these two filters, finding the overall performance and the performance on ``gong'' class are not impacted (see the reason in the last paragraph in Sec.~\ref{sec:case2}). Nevertheless, it provides the experts with a new manner to investigate the functions of filters co-working together for classifying one class of images. That is, increase the threshold to find anomaly filters as many as possible, find the mini-sets containing many filters to some classes from multiple layers, and then inactivate them all to validate corresponding impacts.
% in Fig.~\ref{fig:teaser}B, the experts found that the mini-set appear twice in the cell (Bx1 mark) and another mini-set in the cell (Bx2 mark) in the same column (correspond to gong class). The experts deemed the importance of the filters contained in these two mini-sets due to their low correlation with other classes (appear very few times in other classes).%The Validation View (xx mark) shows this class performs badly in the stage $s1$, becomes relatively good in the stage since the first anomaly iteration, and turns bad again after the third anomaly iteration. The first two anomaly iterations are the sibling anomaly iterations (described in Case 1) corresponding to the identified mini-sets (Bx1 and Bx2). From Fig.~\ref{fig:teaser}A x1 and x2, the experts confirmed that the change of the performance of this class mainly results from the changes of the filters in the two mini-sets (Bx1 and Bx2). At the first big performance (to good) change time, the filters in Bx1 change hugely (continuous deep blue color) but the filters in Bx2 change mildly, leading to the decease of error rates of this class (color strip turn to green). At the second big performance change (to bad again) time, the filters in Bx2 change dramatically while the filters in Bx1 change slightly, leading to the increase of error rates of this class (color strip turn to yellow). Thus, the experts concluded that the filters in Bx1 are positive for classifying the gong class while the filters in Bx2, instead, have negative effect on identifying the gong class. Knowing this information may help the experts learn how to treat this class specially and increase the CNN performance on this class.%it is found that the corresponding class (i.e., gong) has relatively high error rates than others and has three anomaly iterations in total due to the three triangles exist (also can be seen from the number of vertical lines in the corresponding column in correlation view).%Since the horizon positions of rectangles are sorted according to their iterations, the two sibling rectangles correspond to the first top triangle and its sibling bottom triangle.%Besides, from the layer view, the experts know the two filters contained in the miniset are in the middle location of the network structure. Thus, they inferred that both filters may learn some specific middle-level features tailored for identifying this class (i.e., gong class, one of the very special class in the validation dataset).\textbf{Abnormal anomaly filters}.
The experts are also attracted by two mini-sets (d1 and e1 in Fig.~\ref{fig:teaser}), because of their abnormal color patterns.
The filters in these two mini-sets exhibit large changes all the time in the latter part of the training, which are very different from the other anomaly filters.
%In Fig.~\ref{fig:teaser}A, the experts easily identified two mini-sets (A1 and A2) whose containing filters that always change hugely since stage $s3$ compared with the filters in the same layer at the same iteration, one in CONV2 (A1) and the other one in CONV3 (A2).
Thus, the experts are interested in these filters and further check their correlated classes in the Correlation View (right).
Interestingly, each abnormal mini-set only appears with two classes (d2 and e2 in Fig.~\ref{fig:teaser}), and each pair of classes have very similar performances displayed in the Validation View (d3 and e3 in Fig.~\ref{fig:teaser}).
By checking the detailed images of these classes, the experts discover some common patterns.
For example, for mini-set e1, the corresponding classes are about mushrooms growing on grass and dogs playing on grass (e3 in Fig.~\ref{fig:teaser}).
For mini-set d1, the corresponding classes are related to curved shapes, such as parachutes and round textures (d3 in Fig.~\ref{fig:teaser}).
Although the experts are still unclear about why these two mini-sets have such a special behavior, they believe that these filters are likely to play important roles in identifying middle-level features such as grass and curved shapes.
We also conduct further experiments to validate the impact of inactivating these filters and the results are similar to the previous case (i.e., important filters for a class).
%Each two classes have very similar performance evolving patterns due to their close position (MDS algorithm lays the classes of similar patterns close), which can be also verified from the Validation View Fig.~\ref{fig:teaser}C on the top.%By checking the detailed images contained in the corresponding classes, common features were discovered by the experts. For A in the big CONV2 layer, two image classes are mushrooms growing in grasses and dogs playing in grasses. For B in the big CONV3 layer, both classes are related to curve-like objects (i.e., parachutes and curve textures). This indicates the filters containe d in the two mini-sets have learned some middle-level features (grass background or curve shape).%However, it was still not clear for the experts to understand why these filters always change so hugely in the later stages while having such low correlation degrees. Nevertheless, the experts all agreed that these filters must play critically important roles.%Thus, they checked one of this anomaly filters (the one in third bottleneck block of big CONV2 layer) in the correlation view, finding the corresponding classes. They found all the corresponding layers are showing an object (flower, panda, leopard, etc.) in jungles or forests.%It is still not clear for the experts that why there are several filters always change hugely in the later training stages and happen to related to image classes with very similar visual features.%Fig. 7 shows the standard deviations (std) of the layer responses. The responses are the outputs of each 3×3 layer, after BN and before other nonlinearity (ReLU/addition). For ResNets, this analysis reveals the response strength of the residual functions. Fig. 7 shows that ResNets have generally smaller responses than their plain counterparts. These results support our ba- sic motivation (Sec.3.1) that the residual functions might be generally closer to zero than the non-residual functions. We also notice that the deeper ResNet has smaller magni- tudes of responses, as evidenced by the comparisons among ResNet-20, 56, and 110 in Fig. 7. When there are more layers, an individual layer of ResNets tends to modify the signal less.%!!! important%VGG 验证线性可分， 说明最后HIGH LEVEL的FEATURE层， 某些KERNEL对结果影响很大 ， 浅层的多数是共同作用。%LARGE NET可能得去掉好几个。\section{Expert Feedback}\textbf{Usability}\dy{\name is built upon a close collaboration with three domain experts, who constantly underscore their requirements and provide suggestions during the implementation process.
After several iterations of refinement, the experts were happy with the current version. They all praised our way of effectively exploring such extreme large-scale training log via a hierarchical manner. 
\ea and \eb mentioned that the well-designed validation and layer views were very intuitive and helped them greatly. For example, the layer view allowing the experts to effectively observe and compare layer-related information (e.g., weight/gradient distribution) can help them diagnose network structures. The detecting of dying-ReLU problem in the early stage of a training is useful for tuning the hyper-parameters (e.g., learning rate). This kind of knowledge can also be leveraged to conduct model compression~\cite{han2015deep}, so as to improve the model in respect to computing speed and memory cost. Although the experts still cannot figure out the exact reason that some filters are always more actively updated in the later training stages, they believe the insight that would be obtained from the future investigation will be helpful in diagnosing and improving network structures. Besides, the divergent evolving patterns of classes and the numerous anomaly iterations found in validation view provide the experts with a new promising direction to train a better model.
Both \ea and \ec were particularly fond of the cube-style visualization and deemed it as a new perspective to observe the training of CNNs for them. 
They both have found many interesting patterns with the cube visualization, some of which were reasonable or could be explained after thinking for a while.
However, the experts also failed to figure out some other patterns, notwithstanding they conducted several testing experiments. 
Nevertheless, they were still excited that our system can help them identify potential subjects for further study.}%it was a pleasant surprise and useful for examining the complex relationships between neuron weights and class performance. He was excited to %and it is really a new perspective to supervise a CNN training process.%using \name, some of which were reasonable or could be explained after thinking for a while. %These patterns are of great value for debugging and optimizing the network. In particular, .%However, some other patterns were quite unexpected, and the experts failed to understand or even form hypotheses for them. Nevertheless, they they were still excited that our system can help them identify potential subjects to further study.%Although the experts wished \name could help them more with these unexpected patterns, they were still excited that our system can help them identify potential subjects to further study. %In general, all the three experts confirmed the effectiveness of \name to facilitate them in debugging and optimizing a CNN during the training process. In particular, \ea thought that the system had great potential in the direction of model compression~\cite{han2015deep} a large CNN.%\td{TODO: add more details - zhuangjiabeishu}%Nevertheless, they still provide several suggestions, for example, \eb thought that it would be better to allow hiding unrelated layers in validation view by interacting with the network graph. \ec suggested to combine some feature oriented visualization methods to enable the exploration of identified anomaly filters from other perspectives.\textbf{Generality} During the implementation, we were concerned about the generality of \name, that is, whether the design was biased to the specific requirements from these three experts.
Therefore, to check how our system is accepted by broader expert communities, we presented our system in a workshop, which involved about 20 experts in the machine learning and visualization fields.
In addition, we also interviewed another group of twelve experts, who worked on a large project about using CNNs to improve image search quality.
We presented the latest version of \name to the experts, encouraged them to experiment with the system, and collected their feedback in the process.
Exceeding our expectation, \name was well accepted by these experts.
Although they proposed several new requirements, the experts shared many major interests with our three collaborators, such as tracking class level performance, filter-level information, and the relationships between them.
After introducing our system, they immediately understood the purposes of each view and all appreciated this novel, intuitive, and expressive way to watch training processes.
Although the demo was performed on our experiment datasets, the experts saw its potential in their project and immediately asked for collaboration with us, so that they could plug in and analyze their own datasets.
%As a simple example, many of the experts never realized before that validation classes could demonstrate such divergent behaviors, and believed that those behavior patterns provide important clues for improving the overall performance of CNNs.%\dy{Yuxiao: a new perspective to look at the training process; jinkai: not with equal interval dump manner, for abnormal interval, dump more iterations for fine-grained analysis}\textbf{Improvement} Apart from this positive feedback, the experts also made several interesting suggestions to further improve \name.
For example, two experts suggested that our current system only differentiates correct or incorrect classifications for validation images (i.e., 1 and 0).
However, the exact incorrect labels should also be presented because such information can help identify confusing or similar classes.
One expert mentioned that he showed strong interest on what happens before the anomaly iteration and suggested dump data of every iteration at that abnormal interval for fine-grained analysis.
Another expert suggested that our system shoud be integrated with online dashboards, as visualizing the training log on the fly can allow them to terminate the training early and save time if the visualization shows anything undesired.
%Unlike our current implementation only supporting off-line analysis, visualizing the training log on the fly can allow them to terminate the training early and save time if the visualization shows anything undesired.%There are also some suggestions regarding visualization. %We collected the feedback from cooperative experts by conducing one-on-one interviews. Moreover, we presented the demo on Microsoft Annual Workshop on Deep Learning and gained much more feedback from the experts taking part in the workshop.%!TEX root = ../deeptracker.tex% !TeX spellcheck = en_US\section{Discussion}\label{sec:discussion}%\textbf{Lessons learned}% Although intuitive and familiar visual metaphors play crucial roles . easy accepted .%\textbf{Limitation}%Although \name cannot help much for those unexpected patterns, the experts still consider it as a big step forward since it %For those unexpected patterns, \name cannot help much, and the experts may need to conduct other experiments to understand them.%However, compared with the existing tools, they think \name opens a new %\dy{Suggesions from vis experts: 1. Another concern with the cube-style visualization comes from the scrollbar. It seems that the order of classes and layers of CNN is fixed in the visualization. Thus, when there are two classes far apart that could not be shown simultaneously, it would be difficult to find the relationship between the classes. Such design is also not suitable to provide an overview, as part of the data is hidden from the screen; 2. With a default configuration, each view is shown in a single column. Since the paper is dealing with deep CNNs, larger number of layers and larger number of classes could lead to longer visualization results, and the proposed single column layout might bring larger number of scrolls. As this visual analytics system tries to support exploratory data analysis, such layout might not be suitable for exhaustive exploration. Thus, the authors might want to discuss such issues or revise the layout.}%\dy{Important to claim that this study only focus on the parameters, not related to the instance output/activation.}\name is our first step to open the ``black box'' of CNN training.
Although the experts have high expectations of this tool, we all agree to start with two fundamental pieces of information: neuron weights and validation results.
Considering our target users and the large scale of datasets, we try to avoid using sophisticated visual encodings to ensure a fluent exploration experience.
Unsurprisingly, our bare-to-metal visualizations are preferred by the experts, and they use it to find many patterns easily, either expected or unexpected.
However, we still have several limitations.

First and foremost, although our system can effectively help experts identify strange or interesting patterns, there is still a gap between finding patterns and accelerating CNN training.
The experts still have to reason about and understand what these patterns mean or how to use them to accelerate model training in future.
We think it is not a problem faced just by our system, but by all CNN visualizations in general.
%zCNNs are highly nonlinear and complex, thus there is no perfect visualization to help experts fully understand how they work.
Like previous work, \name may only peel a hole in the box and reveal limited information.
But we hope that, by peeling enough holes, all these strange patterns will start to connect and make sense by themselves, thus providing a clear picture of CNNs.
%Although our evaluation demonstrates the effectiveness of \name, there is still space for improvement.%The other issues mainly lay in the following aspects:%these parameters should be carefully chosen to achieve a better effect, that is, detecting the important iterations while controlling the limited number of anomalies. One potential method to solve this problem is to pre-process on the training data, .%\dy{Third, despite the explicit advantages of cube visualization discussed in Sec.~\ref{sec:cubeview}, the space of each face is limited, thereby requiring experts to scroll horizontally or vertically. Although this manner help experts navigate to the content of interest, it lose the overview information. For example, a long horizontal line in correlation view may not be displayed completely. This may increase the memory burden of analyzers. To address this issue, focus plus context techniques are worthy of exploring and leveraging in the next version of \name.}%and then the appropriate parameters can be used for predicting abnormal iterations. %\textbf{Scalability}%First, the system has difficulty in visualizing the CNNs with extremely large number of layers (many hundreds or thousands of layers).\ti{Second, we have adopted many space-efficient visualizations and interaction techniques (e.g., hierarchy, filtering, and aggregation) to address the scalability issue.
Our current design can well support showing dozens of layers and classes in the same time. The correlation view shares all the filter strategies with the other two views, and vice versa.
Thus, our system can perform well in most cases.
Nevertheless, the worst scenario still requires to display hundreds or thousands of small multiples at the same time. 
A possible solution is to employ task-specific aggregation or filtering methods to show the data of interests.}%\dy{It would be great to see some more numbers regarding the time required for logging and preprocessing when applying the presented solution. In addition, it would be helpful to include a brief discussion of how the different views are affected if more data was included and to which extent the visual representations can scale.}

Third, we propose a rule-based anomaly detection method that requires experts to manually pick a reasonable window size $k$ and set the threshold for filtering. The number and patterns of anomalies are sensitive to these settings. One potential solution to this problem is to develop an automatic method to enumerate all potential parameter settings and identify those can detect a reasonable amount of significant anomalies and provide these settings to the experts as guidance.

%\textbf{Generality}
Finally, we only conduct experiments on ResNet-50~\cite{he2016deep}, but our method can also be applied to other state-of-the-art deep CNN models, which often have similar hierarchical structures (e.g., ``inception block'' in google-inception-v4~\cite{szegedy2016inception}).
%Besides, despite that \name is tailored for characterizing the CNN training process, %\ti{%most parts of our approach can be directly applied to the other deep neural network models, such as recurrent neural networks (RNNs).%One special thing is that %distinguish difference should be the validation view, %As many RNNs transform sequence to sequence and often use numeric metric (e.g., mean squared error) to measure the transformation accuracy, we have to consider how to encode numeric value rather than . %}%For network parameters, . For valiadation result, sequence to one is exactly the same as our scenario. sequence to sequence, metric like mean square error or cross-entropy error for each pair. Unfold RNN to a deep feedforward network. Y. LeCun, Y. Bengio, deep learning, Nature.%some visual components can be easily adapted for other use cases.%For example, the correlation view is a novel grid-based visualization designed to explore set relations among grids. %one major advantage of which is that it directly shows the the pairwise (cite set vis).\ti{
Besides, the cube visualization is a general technique, which can be used to explore multiple heterogeneous time series data and their complex correlations.
However, to further generalize it, a strict user study has to be conducted to find the best manner to use it, such as the axis skew degree, and the minimum height/width for each row/column in the three faces.
}%However, we only provide a general idea to present such complex relationships via 2.5D cube. If we want to apply this idea to a general scenarios, a strict user study has to be carried out to find the best way to use it. For example, the axis skew degree, the minimum height for each row in three faces, etc.}%Furthermore, the interaction methodology used in hierarchical small multiples (i.e., validation view) can also be adopted to solve the visual clutter problem occurred when there are too many small multiples.%\textbf{Usability}%\dy{consider real time use}%\textbf{Future work}. Apart from the aforementioned future work, %As \name is good at tracking important iterations and filters,%another promising direction to the future work can be integrating more feature-oriented visualization techniques. For example, feature visualizations can provide insights on what features a filter in a given snapshot of CNN has learned~\cite{girshick2014rich, zeiler2014visualizing, liu2017towards}. Our system can help track critical iterations to take snapshots for a CNN over training, and then use the feature visualization techniques to analyze the learned features evolving patterns for the detected important filters.%Apart from visualizing more detailed image label information and supporting online analysis (Sec. 8.2), %one more significant work remaining to be completed is to combine \name with some feature-oriented visualization techniques (Sec. 3.1), as \name is complementary for those techniques. In other words, feature-oriented visualization techniques provide .%\name is good at identifying critical training iterations and critical filters and . Thus, the feature visualization techniques can provide auxiliary information.%which focus on disclosing how a given CNN behaves on the input images to understand what features are learned by the CNN. used to disclose how a given CNN behave(Sec.3.1), Because the  There are several directions for future work.  one direction: 1. combine filter activation; 2. image maximally activation - verification%!TEX root = ../deeptracker.tex% !TeX spellcheck = en_US\section{Conclusion}\label{sec:conclusion}

We propose a novel visual analytics solution to disclose the rich dynamics of CNN training processes. Knowing such information can help machine learning experts better understand, debug, and optimize CNNs. We develop a comprehensive system that mainly comprises the validation, layer, and correlation views to facilitate an interactive exploration of the evolution of image classification results, network parameters, and the correlation between them.
% over training and the examining of the correlation between both types of data. %It mainly consists of three coordinated views characterizing the training process from different perspectives and at different levels of detail.%In particular, we propose two types of small multiples xxx.
We conduct experiments by training a very deep CNN (ResNet-50) on ImageNet, one of the largest labeled image datasets that is commonly used in practice, to demonstrate the applicability of our system. The positive feedback from our collaborating experts and the experts from an internal workshop validates the usefulness and effectiveness of our system.

%The presented visualization concepts are tailored to the three process levels in stochastic simulation%any other networks use residual connection?

Future studies may integrate some feature-oriented visualization techniques, which typically require recording the activation information for input instances. Feature visualizations can provide insights on what features a filter in a given snapshot of CNN has learned. Our system can track critical iterations to take snapshots for a CNN over training, and then use feature visualization techniques to analyze the learned features evolving patterns for the detected important filters. The other urgent need is to deploy the system in a real-time environment. To this end, we have to consider some new design and interaction requirements to fill the gap between finding patterns and accelerating CNN training.%\begin{acks}%%The authors would like to thank Dr. Maura Turolla of Telecom%Italia for providing specifications about the application scenario.%%The work is supported by the \grantsponsor{GS501100001809}{National%  Natural Science Foundation of%  China}{http://dx.doi.org/10.13039/501100001809} under Grant%No.:~\grantnum{GS501100001809}{61273304\_a}%and~\grantnum[http://www.nnsf.cn/youngscientsts]{GS501100001809}{Young%  Scientsts' Support Program}.%%%\end{acks}

\begin{acks}
	
	The authors would like to thank Kai Yan for providing support in editing the relevant media materials.
	
	The work is supported by the National Basic Research Program of China (973 program) under Grant No. 2014CB340304
	and ITC Grant with No. UIT/138.
	
	
\end{acks}

% Bibliography
\bibliographystyle{ACM-Reference-Format}
%\bibliography{sample-bibliography}
\bibliography{reference}
%\thanks{This work is supported by the National Science Foundation,
%	under grant CNS-0435060, grant CCR-0325197 and grant EN-CS-0329609.}

\end{document}
